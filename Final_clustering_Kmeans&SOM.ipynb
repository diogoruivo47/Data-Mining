{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPlO5ErsD79ELM1Nq1jTnob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diogoruivo47/Data-Mining/blob/main/Final_clustering_Kmeans%26SOM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score, r2_score\n",
        "from sklearn.model_selection import ParameterSampler\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "nYanJt86V9PU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optuna was installed for grid search via bayesian probability"
      ],
      "metadata": {
        "id": "g_w-L3h9ClsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install optuna"
      ],
      "metadata": {
        "id": "HHE2jxOG6pb9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# current plan to merge the data\n",
        "\n",
        "each DF should include cluster labels (C1 + C2.... etc)\n",
        "a unique Identifier\n",
        "\n",
        "Centroids of cluster\n",
        "\n",
        "formate data for aligbments mean or median of clusters and variability/STDV\n",
        "\n",
        "compare pairwise similary,\n",
        "  check numerical w euclidian cosine similary to see represent directionality\n",
        "    present in a distance matrix with each row and column corresponding to clusters\n",
        "\n",
        "after score silhouette etc and R2 for totaldataset\n",
        "use T-sne\n",
        "\n",
        "start grunt work for report, use labs if needed\n",
        "--------------------------------------------------\n",
        "\n",
        "mathematically speaking the merge via hierarchical works via the profile describing a cluster, meaning, the centroids, the distribution of statistics and cluster proportions.\n",
        "\n",
        "combining these will create your final DF merged non refull clustered blablablabla, so follow steps above.\n"
      ],
      "metadata": {
        "id": "ueK3IdHCzoxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------\n",
        "plan when improving data for clustering in NOV:\n",
        "\n",
        "split numericals from categoricals,\n",
        "\n",
        "reduce feature amounts in preferences and shopping,\n",
        "\n",
        "improve silhouette overall and find ideal model"
      ],
      "metadata": {
        "id": "iCQjgM-nWuwD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r9nNOls0Vg7l"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data_clean2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "df = df.drop(columns=['Unnamed: 0'])\n"
      ],
      "metadata": {
        "id": "_JGTfDOnWRVX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uvc1RV2rEeR3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0lRPUp9oDnm3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy = df.copy()\n",
        "categorical_cols = ['last_promo', 'payment_method', 'customer_region_0', 'customer_region_1', 'customer_region_2', 'customer_region_3']\n",
        "cat_df = df_copy[categorical_cols].copy()\n",
        "numerical_cols = df_copy.columns.difference(categorical_cols)\n",
        "num_df = df_copy[numerical_cols].copy()"
      ],
      "metadata": {
        "id": "fBjJ8n_wWVfn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "def scale_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Scale features with QUANTUM-PRECISE type handling.\n",
        "    CRITICAL: Convert categorical types before statistical operations!\n",
        "    \"\"\"\n",
        "    # FUNDAMENTAL STEP: Convert DataFrame to float64 with EXTREME PRECISION\n",
        "    df = df.copy()\n",
        "\n",
        "    # CRITICAL TYPE CONVERSION WITH VERIFICATION\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype.name == 'category':\n",
        "            df[column] = df[column].astype('float64')\n",
        "\n",
        "    scaled_df = pd.DataFrame(index=df.index)\n",
        "\n",
        "    # 1. Binary features\n",
        "    binary_cols = ['DOW_0', 'DOW_1', 'DOW_2', 'DOW_3', 'DOW_4', 'DOW_5', 'DOW_6',\n",
        "                    'CLV_Score', 'RFM_Score' , 'Loyalty']\n",
        "    for col in binary_cols:\n",
        "        scaled_df[col] = df[col]\n",
        "\n",
        "    # 2. CUI features\n",
        "    cui_cols = [col for col in df.columns if col.startswith('CUI_')]\n",
        "    for col in cui_cols:\n",
        "        nonzero_mask = df[col] != 0\n",
        "        scaled = np.zeros(len(df))\n",
        "        if nonzero_mask.any():\n",
        "            nonzero_values = df.loc[nonzero_mask, col].values.reshape(-1, 1)\n",
        "            scaled[nonzero_mask] = StandardScaler().fit_transform(nonzero_values).ravel()\n",
        "        scaled_df[col] = scaled\n",
        "\n",
        "    # 3. Ordinal features\n",
        "    ordinal_cols = ['is_chain','Orders_Night', \t'Orders_Dawn',\t'Orders_Morning',\t'Orders_Afternoon'\t,'Orders_Evening'\t,'Orders_Dusk', 'Age_Group']\n",
        "    for col in ordinal_cols:\n",
        "        values = df[col].values.reshape(-1, 1)\n",
        "        scaled_df[col] = MinMaxScaler().fit_transform(values).ravel()\n",
        "\n",
        "    # 4. Continuous features\n",
        "    continuous_cols = ['vendor_count', 'product_count', 'Total_Orders_Per_Client',\n",
        "                      'mnt', 'mnt_Per_Order', 'Items_Per_Order', 'frq', 'rcn',\n",
        "                      'activity']\n",
        "\n",
        "    for col in continuous_cols:\n",
        "        values = df[col].values\n",
        "        if np.std(values) == 0:\n",
        "            scaled_df[col] = values\n",
        "            continue\n",
        "\n",
        "        # MATHEMATICALLY PRECISE skewness handling\n",
        "        if pd.Series(values, dtype='float64').skew() > 1:\n",
        "            min_val = values.min()\n",
        "            if min_val < 0:\n",
        "                values = values - min_val + 1e-10\n",
        "            values = np.log1p(values)\n",
        "\n",
        "        num_df[col] = StandardScaler().fit_transform(values.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # QUANTUM VALIDATION\n",
        "    missing_cols = set(df.columns) - set(num_df.columns)\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"VIOLATION OF CONSERVATION OF FEATURES: Missing columns: {missing_cols}\")\n",
        "\n",
        "    return num_df\n",
        "\n",
        "# Execute with SUPERNOVA PRECISION\n",
        "num_df = scale_features(num_df)\n",
        "\n",
        "# VALIDATE WITH HADRON COLLIDER PRECISION\n",
        "print(\"\\nQUANTUM FEATURE VERIFICATION:\")\n",
        "print(f\"Input shape: {df.shape}\")\n",
        "print(f\"Output shape: {num_df.shape}\")\n",
        "print(\"\\nFEATURE CONSERVATION CHECK:\")\n",
        "print(\"All features preserved:\", set(df.columns) == set(num_df.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvdVKt3cFVP6",
        "outputId": "f5831f67-b6ab-4e6c-83fd-1dd5cc985291"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "QUANTUM FEATURE VERIFICATION:\n",
            "Input shape: (31737, 48)\n",
            "Output shape: (31737, 42)\n",
            "\n",
            "FEATURE CONSERVATION CHECK:\n",
            "All features preserved: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "dp-CXE5uXQjZ",
        "outputId": "7661e53b-31cb-4e7e-ce7c-492165ff8c24"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       DOW_0  DOW_1  DOW_2  DOW_3  DOW_4  DOW_5  DOW_6  CLV_Score  RFM_Score  \\\n",
              "0          1      0      0      0      0      0      1   0.092846   0.097455   \n",
              "1          1      0      0      0      0      0      1   0.090596   0.095409   \n",
              "2          1      0      0      0      0      0      1   0.088267   0.093292   \n",
              "3          0      1      0      0      0      0      1   0.066010   0.068898   \n",
              "4          0      1      0      0      0      0      1   0.071566   0.073949   \n",
              "...      ...    ...    ...    ...    ...    ...    ...        ...        ...   \n",
              "31732      0      0      0      0      0      0      1   0.186393   0.176038   \n",
              "31733      0      0      0      0      0      0      1   0.186393   0.176038   \n",
              "31734      0      0      0      0      0      0      1   0.186393   0.175985   \n",
              "31735      0      0      0      0      0      0      1   0.186393   0.174767   \n",
              "31736      0      0      0      0      0      0      1   0.186393   0.173895   \n",
              "\n",
              "       Loyalty  CUI_American  CUI_Asian  CUI_Beverages  CUI_Cafe  \\\n",
              "0          0.0      0.000000   0.000000       0.000000       0.0   \n",
              "1          0.0     -0.097755  -0.628572       0.000000       0.0   \n",
              "2          0.5     -0.320803   0.000000       0.000000       0.0   \n",
              "3          0.0      0.000000  -0.402056       0.000000       0.0   \n",
              "4          0.0      0.010072   0.439863       0.000000       0.0   \n",
              "...        ...           ...        ...            ...       ...   \n",
              "31732      0.0      0.000000   0.000000       0.276647       0.0   \n",
              "31733      0.0      0.223878   0.000000       0.000000       0.0   \n",
              "31734      0.0      0.000000   0.000000       0.000000       0.0   \n",
              "31735      0.0      0.000000  -0.453805       0.000000       0.0   \n",
              "31736      0.0      0.000000   0.000000       0.000000       0.0   \n",
              "\n",
              "       CUI_Chicken_Dishes  CUI_Chinese  CUI_Desserts  CUI_Healthy  CUI_Indian  \\\n",
              "0                     0.0          0.0      0.000000          0.0    0.784253   \n",
              "1                     0.0          0.0      0.000000          0.0    0.000000   \n",
              "2                     0.0          0.0      0.000000          0.0    0.000000   \n",
              "3                     0.0          0.0      0.000000          0.0    0.157745   \n",
              "4                     0.0          0.0      0.000000          0.0    0.000000   \n",
              "...                   ...          ...           ...          ...         ...   \n",
              "31732                 0.0          0.0      0.000000          0.0    0.000000   \n",
              "31733                 0.0          0.0      0.000000          0.0    0.000000   \n",
              "31734                 0.0          0.0      0.238402          0.0    0.000000   \n",
              "31735                 0.0          0.0      0.000000          0.0    0.000000   \n",
              "31736                 0.0          0.0      0.000000          0.0    0.000000   \n",
              "\n",
              "       CUI_Italian  CUI_Japanese  CUI_Noodle_Dishes  CUI_OTHER  \\\n",
              "0          0.00000           0.0                0.0        0.0   \n",
              "1          0.00000           0.0                0.0        0.0   \n",
              "2          0.00000           0.0                0.0        0.0   \n",
              "3          0.00000           0.0                0.0        0.0   \n",
              "4          0.00000           0.0                0.0        0.0   \n",
              "...            ...           ...                ...        ...   \n",
              "31732      0.00000           0.0                0.0        0.0   \n",
              "31733      0.00000           0.0                0.0        0.0   \n",
              "31734      0.00000           0.0                0.0        0.0   \n",
              "31735      0.00000           0.0                0.0        0.0   \n",
              "31736     -0.39351           0.0                0.0        0.0   \n",
              "\n",
              "       CUI_Street_Food/Snacks  CUI_Thai  is_chain  Orders_Night  Orders_Dawn  \\\n",
              "0                         0.0       0.0  0.166667           0.0     0.000000   \n",
              "1                         0.0       0.0  0.333333           0.0     0.000000   \n",
              "2                         0.0       0.0  0.333333           0.0     0.000000   \n",
              "3                         0.0       0.0  0.166667           0.0     0.000000   \n",
              "4                         0.0       0.0  0.000000           0.0     0.000000   \n",
              "...                       ...       ...       ...           ...          ...   \n",
              "31732                     0.0       0.0  0.166667           0.0     0.000000   \n",
              "31733                     0.0       0.0  0.000000           0.0     0.000000   \n",
              "31734                     0.0       0.0  0.166667           0.0     0.047619   \n",
              "31735                     0.0       0.0  0.000000           0.0     0.000000   \n",
              "31736                     0.0       0.0  0.000000           0.0     0.000000   \n",
              "\n",
              "       Orders_Morning  Orders_Afternoon  Orders_Evening  Orders_Dusk  \\\n",
              "0            0.000000           0.00000        0.040816          0.0   \n",
              "1            0.034483           0.00000        0.000000          0.0   \n",
              "2            0.034483           0.00000        0.000000          0.0   \n",
              "3            0.017241           0.02381        0.000000          0.0   \n",
              "4            0.034483           0.00000        0.000000          0.0   \n",
              "...               ...               ...             ...          ...   \n",
              "31732        0.000000           0.02381        0.000000          0.0   \n",
              "31733        0.000000           0.00000        0.020408          0.0   \n",
              "31734        0.000000           0.00000        0.000000          0.0   \n",
              "31735        0.017241           0.00000        0.000000          0.0   \n",
              "31736        0.000000           0.00000        0.020408          0.0   \n",
              "\n",
              "       Age_Group  vendor_count  product_count  Total_Orders_Per_Client  \\\n",
              "0            0.2     -0.317483       0.336961                -0.645712   \n",
              "1            0.0     -0.317483      -0.782596                -0.645712   \n",
              "2            0.6     -1.177017      -0.782596                -0.645712   \n",
              "3            0.4     -0.317483      -0.317938                -0.645712   \n",
              "4            0.2     -0.317483       0.336961                -0.645712   \n",
              "...          ...           ...            ...                      ...   \n",
              "31732        0.4     -1.177017      -1.437495                -1.028486   \n",
              "31733        0.4     -1.177017      -1.437495                -1.028486   \n",
              "31734        0.2     -1.177017      -1.437495                -1.028486   \n",
              "31735        0.4     -1.177017      -1.437495                -1.028486   \n",
              "31736        0.4     -1.177017      -1.437495                -1.028486   \n",
              "\n",
              "            mnt  mnt_Per_Order  Items_Per_Order       frq       rcn  activity  \n",
              "0      0.217004       0.738578         2.542052  1.663218  2.748987 -1.171450  \n",
              "1     -0.248614      -0.039259        -0.850231  1.663218  2.748987 -1.171450  \n",
              "2     -1.062873      -0.842810        -0.850231  1.663218  2.748987 -1.171450  \n",
              "3      0.319289       0.953930         0.708892  0.959366  2.705393 -1.137446  \n",
              "4      0.974342       2.386661         2.542052  0.959366  2.705393 -1.137446  \n",
              "...         ...            ...              ...       ...       ...       ...  \n",
              "31732 -0.319628       1.317135        -0.850231  1.663218 -1.174464 -1.205454  \n",
              "31733 -0.319628       1.317135        -0.850231  1.663218 -1.174464 -1.205454  \n",
              "31734 -0.335367       1.276957        -0.850231  1.663218 -1.174464 -1.205454  \n",
              "31735 -0.771285       0.351267        -0.850231  1.663218 -1.174464 -1.205454  \n",
              "31736 -1.223886      -0.310859        -0.850231  1.663218 -1.174464 -1.205454  \n",
              "\n",
              "[31737 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-329e0042-d663-4d40-8836-b6c4f5f23606\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DOW_0</th>\n",
              "      <th>DOW_1</th>\n",
              "      <th>DOW_2</th>\n",
              "      <th>DOW_3</th>\n",
              "      <th>DOW_4</th>\n",
              "      <th>DOW_5</th>\n",
              "      <th>DOW_6</th>\n",
              "      <th>CLV_Score</th>\n",
              "      <th>RFM_Score</th>\n",
              "      <th>Loyalty</th>\n",
              "      <th>CUI_American</th>\n",
              "      <th>CUI_Asian</th>\n",
              "      <th>CUI_Beverages</th>\n",
              "      <th>CUI_Cafe</th>\n",
              "      <th>CUI_Chicken_Dishes</th>\n",
              "      <th>CUI_Chinese</th>\n",
              "      <th>CUI_Desserts</th>\n",
              "      <th>CUI_Healthy</th>\n",
              "      <th>CUI_Indian</th>\n",
              "      <th>CUI_Italian</th>\n",
              "      <th>CUI_Japanese</th>\n",
              "      <th>CUI_Noodle_Dishes</th>\n",
              "      <th>CUI_OTHER</th>\n",
              "      <th>CUI_Street_Food/Snacks</th>\n",
              "      <th>CUI_Thai</th>\n",
              "      <th>is_chain</th>\n",
              "      <th>Orders_Night</th>\n",
              "      <th>Orders_Dawn</th>\n",
              "      <th>Orders_Morning</th>\n",
              "      <th>Orders_Afternoon</th>\n",
              "      <th>Orders_Evening</th>\n",
              "      <th>Orders_Dusk</th>\n",
              "      <th>Age_Group</th>\n",
              "      <th>vendor_count</th>\n",
              "      <th>product_count</th>\n",
              "      <th>Total_Orders_Per_Client</th>\n",
              "      <th>mnt</th>\n",
              "      <th>mnt_Per_Order</th>\n",
              "      <th>Items_Per_Order</th>\n",
              "      <th>frq</th>\n",
              "      <th>rcn</th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.092846</td>\n",
              "      <td>0.097455</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.784253</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.040816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.317483</td>\n",
              "      <td>0.336961</td>\n",
              "      <td>-0.645712</td>\n",
              "      <td>0.217004</td>\n",
              "      <td>0.738578</td>\n",
              "      <td>2.542052</td>\n",
              "      <td>1.663218</td>\n",
              "      <td>2.748987</td>\n",
              "      <td>-1.171450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.090596</td>\n",
              "      <td>0.095409</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.097755</td>\n",
              "      <td>-0.628572</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.317483</td>\n",
              "      <td>-0.782596</td>\n",
              "      <td>-0.645712</td>\n",
              "      <td>-0.248614</td>\n",
              "      <td>-0.039259</td>\n",
              "      <td>-0.850231</td>\n",
              "      <td>1.663218</td>\n",
              "      <td>2.748987</td>\n",
              "      <td>-1.171450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.088267</td>\n",
              "      <td>0.093292</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.320803</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-1.177017</td>\n",
              "      <td>-0.782596</td>\n",
              "      <td>-0.645712</td>\n",
              "      <td>-1.062873</td>\n",
              "      <td>-0.842810</td>\n",
              "      <td>-0.850231</td>\n",
              "      <td>1.663218</td>\n",
              "      <td>2.748987</td>\n",
              "      <td>-1.171450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.066010</td>\n",
              "      <td>0.068898</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.402056</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157745</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017241</td>\n",
              "      <td>0.02381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.317483</td>\n",
              "      <td>-0.317938</td>\n",
              "      <td>-0.645712</td>\n",
              "      <td>0.319289</td>\n",
              "      <td>0.953930</td>\n",
              "      <td>0.708892</td>\n",
              "      <td>0.959366</td>\n",
              "      <td>2.705393</td>\n",
              "      <td>-1.137446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.071566</td>\n",
              "      <td>0.073949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010072</td>\n",
              "      <td>0.439863</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.317483</td>\n",
              "      <td>0.336961</td>\n",
              "      <td>-0.645712</td>\n",
              "      <td>0.974342</td>\n",
              "      <td>2.386661</td>\n",
              "      <td>2.542052</td>\n",
              "      <td>0.959366</td>\n",
              "      <td>2.705393</td>\n",
              "      <td>-1.137446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31732</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.186393</td>\n",
              "      <td>0.176038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.276647</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-1.177017</td>\n",
              "      <td>-1.437495</td>\n",
              "      <td>-1.028486</td>\n",
              "      <td>-0.319628</td>\n",
              "      <td>1.317135</td>\n",
              "      <td>-0.850231</td>\n",
              "      <td>1.663218</td>\n",
              "      <td>-1.174464</td>\n",
              "      <td>-1.205454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31733</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.186393</td>\n",
              "      <td>0.176038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.223878</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-1.177017</td>\n",
              "      <td>-1.437495</td>\n",
              "      <td>-1.028486</td>\n",
              "      <td>-0.319628</td>\n",
              "      <td>1.317135</td>\n",
              "      <td>-0.850231</td>\n",
              "      <td>1.663218</td>\n",
              "      <td>-1.174464</td>\n",
              "      <td>-1.205454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31734</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.186393</td>\n",
              "      <td>0.175985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.238402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-1.177017</td>\n",
              "      <td>-1.437495</td>\n",
              "      <td>-1.028486</td>\n",
              "      <td>-0.335367</td>\n",
              "      <td>1.276957</td>\n",
              "      <td>-0.850231</td>\n",
              "      <td>1.663218</td>\n",
              "      <td>-1.174464</td>\n",
              "      <td>-1.205454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31735</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.186393</td>\n",
              "      <td>0.174767</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.453805</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017241</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-1.177017</td>\n",
              "      <td>-1.437495</td>\n",
              "      <td>-1.028486</td>\n",
              "      <td>-0.771285</td>\n",
              "      <td>0.351267</td>\n",
              "      <td>-0.850231</td>\n",
              "      <td>1.663218</td>\n",
              "      <td>-1.174464</td>\n",
              "      <td>-1.205454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31736</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.186393</td>\n",
              "      <td>0.173895</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.39351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-1.177017</td>\n",
              "      <td>-1.437495</td>\n",
              "      <td>-1.028486</td>\n",
              "      <td>-1.223886</td>\n",
              "      <td>-0.310859</td>\n",
              "      <td>-0.850231</td>\n",
              "      <td>1.663218</td>\n",
              "      <td>-1.174464</td>\n",
              "      <td>-1.205454</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31737 rows Ã— 42 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-329e0042-d663-4d40-8836-b6c4f5f23606')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-329e0042-d663-4d40-8836-b6c4f5f23606 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-329e0042-d663-4d40-8836-b6c4f5f23606');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0413748d-3ff5-420e-ab41-ea875ea82111\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0413748d-3ff5-420e-ab41-ea875ea82111')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0413748d-3ff5-420e-ab41-ea875ea82111 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6d9761ba-afb7-4be4-9ee0-8ab27c852323\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('num_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6d9761ba-afb7-4be4-9ee0-8ab27c852323 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('num_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "num_df"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Spearman correlation matrix\n",
        "spearman_corr = num_df.corr(method='spearman')\n",
        "\n",
        "# Display the correlation matrix\n",
        "spearman_corr\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9jMo2ePFXg4R",
        "outputId": "1a4ef131-bfe6-4ecc-8ac6-0a7d9d3c2275"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            DOW_0     DOW_1     DOW_2     DOW_3     DOW_4  \\\n",
              "DOW_0                    1.000000  0.239451  0.234692  0.225882  0.176707   \n",
              "DOW_1                    0.239451  1.000000  0.248535  0.235444  0.185994   \n",
              "DOW_2                    0.234692  0.248535  1.000000  0.242585  0.197536   \n",
              "DOW_3                    0.225882  0.235444  0.242585  1.000000  0.204534   \n",
              "DOW_4                    0.176707  0.185994  0.197536  0.204534  1.000000   \n",
              "DOW_5                    0.130844  0.122919  0.120607  0.131171  0.139216   \n",
              "DOW_6                    0.144047  0.123414  0.135044  0.128172  0.126009   \n",
              "CLV_Score                0.041674  0.052926  0.063361  0.094587  0.100607   \n",
              "RFM_Score                0.015459  0.025526  0.036966  0.066596  0.055575   \n",
              "Loyalty                  0.309971  0.320087  0.336971  0.339671  0.334988   \n",
              "CUI_American            -0.007948  0.004187 -0.002909 -0.000416 -0.005596   \n",
              "CUI_Asian                0.031864  0.017901  0.008809  0.021530  0.018773   \n",
              "CUI_Beverages           -0.023641 -0.018165 -0.019424 -0.016312 -0.014867   \n",
              "CUI_Cafe                -0.009666 -0.005425 -0.005220 -0.010115 -0.003749   \n",
              "CUI_Chicken_Dishes       0.003849  0.006780  0.007988 -0.000787 -0.004226   \n",
              "CUI_Chinese             -0.012840 -0.014745 -0.007617 -0.000660 -0.006766   \n",
              "CUI_Desserts            -0.020678 -0.013502 -0.030035 -0.025462 -0.014771   \n",
              "CUI_Healthy             -0.009510 -0.016770 -0.022447 -0.029278 -0.009122   \n",
              "CUI_Indian              -0.021093 -0.022564 -0.012624 -0.014567 -0.013820   \n",
              "CUI_Italian              0.006957  0.007983  0.014201 -0.000934 -0.003563   \n",
              "CUI_Japanese            -0.032283 -0.029118 -0.019137 -0.026389 -0.015573   \n",
              "CUI_Noodle_Dishes       -0.020294 -0.014173 -0.030887 -0.014357 -0.009558   \n",
              "CUI_OTHER                0.014130  0.022086  0.029338  0.008195  0.020205   \n",
              "CUI_Street_Food/Snacks  -0.016510 -0.017793 -0.013291 -0.008626 -0.007211   \n",
              "CUI_Thai                -0.011773 -0.010852 -0.016498 -0.015371 -0.007092   \n",
              "is_chain                 0.380964  0.381061  0.384234  0.382928  0.364731   \n",
              "Orders_Night             0.117614  0.092907  0.089564  0.078979  0.051334   \n",
              "Orders_Dawn              0.112148  0.101717  0.097099  0.087339  0.053484   \n",
              "Orders_Morning           0.289692  0.271741  0.286622  0.273337  0.248499   \n",
              "Orders_Afternoon         0.270555  0.274315  0.278179  0.290232  0.274976   \n",
              "Orders_Evening           0.209825  0.222328  0.238674  0.260003  0.296619   \n",
              "Orders_Dusk              0.166647  0.172557  0.163488  0.160200  0.166407   \n",
              "Age_Group                0.014155  0.002188  0.002543  0.008337 -0.002040   \n",
              "vendor_count             0.444394  0.441420  0.449241  0.450414  0.429584   \n",
              "product_count            0.467621  0.467889  0.486109  0.485919  0.470255   \n",
              "Total_Orders_Per_Client  0.487078  0.488111  0.505805  0.506955  0.489599   \n",
              "mnt                      0.367186  0.361109  0.377148  0.372713  0.359802   \n",
              "mnt_Per_Order           -0.095872 -0.106459 -0.101740 -0.113150 -0.107482   \n",
              "Items_Per_Order          0.090421  0.090598  0.099674  0.095464  0.095874   \n",
              "frq                     -0.078086 -0.072986 -0.087117 -0.088083 -0.091739   \n",
              "rcn                     -0.241139 -0.251493 -0.273226 -0.299676 -0.302244   \n",
              "activity                 0.398360  0.397150  0.417149  0.421766  0.404916   \n",
              "\n",
              "                            DOW_5     DOW_6  CLV_Score  RFM_Score   Loyalty  \\\n",
              "DOW_0                    0.130844  0.144047   0.041674   0.015459  0.309971   \n",
              "DOW_1                    0.122919  0.123414   0.052926   0.025526  0.320087   \n",
              "DOW_2                    0.120607  0.135044   0.063361   0.036966  0.336971   \n",
              "DOW_3                    0.131171  0.128172   0.094587   0.066596  0.339671   \n",
              "DOW_4                    0.139216  0.126009   0.100607   0.055575  0.334988   \n",
              "DOW_5                    1.000000  0.190266   0.016857  -0.007242  0.271503   \n",
              "DOW_6                    0.190266  1.000000  -0.004533  -0.029825  0.284548   \n",
              "CLV_Score                0.016857 -0.004533   1.000000   0.989184 -0.019965   \n",
              "RFM_Score               -0.007242 -0.029825   0.989184   1.000000 -0.053272   \n",
              "Loyalty                  0.271503  0.284548  -0.019965  -0.053272  1.000000   \n",
              "CUI_American            -0.008867 -0.016091   0.109149   0.105438  0.100623   \n",
              "CUI_Asian                0.019214  0.008614   0.082841   0.067619  0.088698   \n",
              "CUI_Beverages           -0.036072 -0.028407   0.078898   0.077297  0.068987   \n",
              "CUI_Cafe                -0.011699 -0.015837   0.024169   0.021920  0.022231   \n",
              "CUI_Chicken_Dishes      -0.001307 -0.004361   0.068521   0.067819  0.045568   \n",
              "CUI_Chinese             -0.020450 -0.014939   0.073655   0.071444  0.043057   \n",
              "CUI_Desserts            -0.026734 -0.022278   0.042226   0.038678  0.025652   \n",
              "CUI_Healthy             -0.011719 -0.023250   0.039968   0.038424  0.037066   \n",
              "CUI_Indian              -0.006826 -0.016172   0.053582   0.052040  0.046649   \n",
              "CUI_Italian             -0.002263 -0.005741   0.051527   0.046542  0.100662   \n",
              "CUI_Japanese            -0.011149 -0.019905   0.067097   0.063801  0.057946   \n",
              "CUI_Noodle_Dishes       -0.019269 -0.018516   0.045779   0.045087  0.025661   \n",
              "CUI_OTHER                0.018507  0.016055   0.111758   0.107312  0.078312   \n",
              "CUI_Street_Food/Snacks  -0.022651 -0.013440   0.055347   0.045112  0.021250   \n",
              "CUI_Thai                -0.011761 -0.012242   0.028161   0.027352  0.048223   \n",
              "is_chain                 0.335270  0.347896  -0.086399  -0.124700  0.384554   \n",
              "Orders_Night             0.072311  0.057427   0.036009   0.015206  0.013339   \n",
              "Orders_Dawn              0.079144  0.069818   0.043632   0.020149  0.001447   \n",
              "Orders_Morning           0.224566  0.238807   0.050462   0.021244  0.254087   \n",
              "Orders_Afternoon         0.261760  0.300375   0.008237  -0.016595  0.335086   \n",
              "Orders_Evening           0.264613  0.267745  -0.041549  -0.058072  0.360599   \n",
              "Orders_Dusk              0.169846  0.163296  -0.022636  -0.031836  0.128033   \n",
              "Age_Group               -0.002210  0.003904   0.008029   0.006676  0.009922   \n",
              "vendor_count             0.409335  0.417778  -0.107176  -0.162246  0.238197   \n",
              "product_count            0.427865  0.445346  -0.043445  -0.101710  0.581853   \n",
              "Total_Orders_Per_Client  0.441399  0.457593  -0.106557  -0.165023  0.616230   \n",
              "mnt                      0.328541  0.332949   0.119324   0.069739  0.418518   \n",
              "mnt_Per_Order           -0.091810 -0.102645   0.223013   0.214071 -0.158522   \n",
              "Items_Per_Order          0.099923  0.110594   0.125428   0.102301  0.084251   \n",
              "frq                     -0.076712 -0.103022   0.574515   0.620062 -0.171074   \n",
              "rcn                     -0.206894 -0.220279  -0.406842  -0.364907 -0.305183   \n",
              "activity                 0.356761  0.386163  -0.183989  -0.247917  0.495155   \n",
              "\n",
              "                         CUI_American  CUI_Asian  CUI_Beverages  CUI_Cafe  \\\n",
              "DOW_0                       -0.007948   0.031864      -0.023641 -0.009666   \n",
              "DOW_1                        0.004187   0.017901      -0.018165 -0.005425   \n",
              "DOW_2                       -0.002909   0.008809      -0.019424 -0.005220   \n",
              "DOW_3                       -0.000416   0.021530      -0.016312 -0.010115   \n",
              "DOW_4                       -0.005596   0.018773      -0.014867 -0.003749   \n",
              "DOW_5                       -0.008867   0.019214      -0.036072 -0.011699   \n",
              "DOW_6                       -0.016091   0.008614      -0.028407 -0.015837   \n",
              "CLV_Score                    0.109149   0.082841       0.078898  0.024169   \n",
              "RFM_Score                    0.105438   0.067619       0.077297  0.021920   \n",
              "Loyalty                      0.100623   0.088698       0.068987  0.022231   \n",
              "CUI_American                 1.000000   0.044933       0.067861  0.019177   \n",
              "CUI_Asian                    0.044933   1.000000       0.027021  0.018364   \n",
              "CUI_Beverages                0.067861   0.027021       1.000000 -0.003504   \n",
              "CUI_Cafe                     0.019177   0.018364      -0.003504  1.000000   \n",
              "CUI_Chicken_Dishes           0.042542   0.012362       0.037096  0.002464   \n",
              "CUI_Chinese                  0.045970   0.021255       0.040950  0.003713   \n",
              "CUI_Desserts                 0.033984   0.023807       0.037508  0.011776   \n",
              "CUI_Healthy                  0.023113   0.016458       0.013354  0.030000   \n",
              "CUI_Indian                   0.049893   0.032392       0.027950  0.004777   \n",
              "CUI_Italian                  0.049653   0.020247       0.022779  0.047521   \n",
              "CUI_Japanese                 0.044878   0.036830       0.044909  0.013547   \n",
              "CUI_Noodle_Dishes            0.039889   0.022214       0.038532  0.002304   \n",
              "CUI_OTHER                    0.067226   0.017991       0.060692  0.023686   \n",
              "CUI_Street_Food/Snacks       0.011723   0.030551       0.013640 -0.001544   \n",
              "CUI_Thai                     0.030616   0.018244       0.023358  0.015465   \n",
              "is_chain                    -0.095541  -0.013505      -0.122599 -0.033732   \n",
              "Orders_Night                 0.062320   0.124434       0.014400  0.035755   \n",
              "Orders_Dawn                  0.059124   0.084652       0.050755  0.026209   \n",
              "Orders_Morning              -0.004908   0.005080      -0.016675 -0.023953   \n",
              "Orders_Afternoon            -0.037705  -0.024523      -0.063277 -0.019539   \n",
              "Orders_Evening              -0.063659  -0.078138      -0.055467 -0.047638   \n",
              "Orders_Dusk                 -0.098646  -0.024145      -0.104413 -0.006549   \n",
              "Age_Group                    0.009693   0.011969      -0.005341 -0.003634   \n",
              "vendor_count                -0.111250  -0.025968      -0.115958 -0.050680   \n",
              "product_count                0.005921   0.087398      -0.034609 -0.019424   \n",
              "Total_Orders_Per_Client     -0.044018   0.026927      -0.066371 -0.030914   \n",
              "mnt                          0.151092   0.134996       0.103059  0.006832   \n",
              "mnt_Per_Order                0.259137   0.173878       0.217276  0.052662   \n",
              "Items_Per_Order              0.139976   0.198714       0.074321  0.025960   \n",
              "frq                          0.074937   0.027655       0.056381  0.022728   \n",
              "rcn                         -0.001536  -0.014886       0.010748  0.010790   \n",
              "activity                    -0.047178   0.009899      -0.061953 -0.025276   \n",
              "\n",
              "                         CUI_Chicken_Dishes  CUI_Chinese  CUI_Desserts  \\\n",
              "DOW_0                              0.003849    -0.012840     -0.020678   \n",
              "DOW_1                              0.006780    -0.014745     -0.013502   \n",
              "DOW_2                              0.007988    -0.007617     -0.030035   \n",
              "DOW_3                             -0.000787    -0.000660     -0.025462   \n",
              "DOW_4                             -0.004226    -0.006766     -0.014771   \n",
              "DOW_5                             -0.001307    -0.020450     -0.026734   \n",
              "DOW_6                             -0.004361    -0.014939     -0.022278   \n",
              "CLV_Score                          0.068521     0.073655      0.042226   \n",
              "RFM_Score                          0.067819     0.071444      0.038678   \n",
              "Loyalty                            0.045568     0.043057      0.025652   \n",
              "CUI_American                       0.042542     0.045970      0.033984   \n",
              "CUI_Asian                          0.012362     0.021255      0.023807   \n",
              "CUI_Beverages                      0.037096     0.040950      0.037508   \n",
              "CUI_Cafe                           0.002464     0.003713      0.011776   \n",
              "CUI_Chicken_Dishes                 1.000000     0.038158      0.015061   \n",
              "CUI_Chinese                        0.038158     1.000000      0.007524   \n",
              "CUI_Desserts                       0.015061     0.007524      1.000000   \n",
              "CUI_Healthy                        0.014262     0.010143      0.010363   \n",
              "CUI_Indian                         0.017962     0.028586      0.014390   \n",
              "CUI_Italian                        0.007127     0.021004      0.011883   \n",
              "CUI_Japanese                       0.028855     0.032553      0.023153   \n",
              "CUI_Noodle_Dishes                  0.025071     0.045482      0.009643   \n",
              "CUI_OTHER                          0.059971     0.074387      0.028446   \n",
              "CUI_Street_Food/Snacks             0.004111     0.018343      0.031545   \n",
              "CUI_Thai                           0.016097     0.011702      0.006628   \n",
              "is_chain                          -0.074565    -0.092873     -0.070229   \n",
              "Orders_Night                       0.027999     0.021352      0.002119   \n",
              "Orders_Dawn                        0.047501     0.029808      0.014950   \n",
              "Orders_Morning                     0.014607     0.009509     -0.013392   \n",
              "Orders_Afternoon                  -0.028598    -0.037329     -0.038499   \n",
              "Orders_Evening                    -0.034149    -0.049854     -0.039750   \n",
              "Orders_Dusk                       -0.064339    -0.078869     -0.047355   \n",
              "Age_Group                         -0.002565    -0.004241      0.002856   \n",
              "vendor_count                      -0.056442    -0.080605     -0.075052   \n",
              "product_count                     -0.000743    -0.021622     -0.028531   \n",
              "Total_Orders_Per_Client           -0.026319    -0.048720     -0.049974   \n",
              "mnt                                0.116664     0.106115      0.034422   \n",
              "mnt_Per_Order                      0.173162     0.189395      0.113834   \n",
              "Items_Per_Order                    0.078059     0.071722      0.051868   \n",
              "frq                                0.039513     0.033248      0.034559   \n",
              "rcn                               -0.010467    -0.005776      0.014500   \n",
              "activity                          -0.025297    -0.028910     -0.045942   \n",
              "\n",
              "                         CUI_Healthy  CUI_Indian  CUI_Italian  CUI_Japanese  \\\n",
              "DOW_0                      -0.009510   -0.021093     0.006957     -0.032283   \n",
              "DOW_1                      -0.016770   -0.022564     0.007983     -0.029118   \n",
              "DOW_2                      -0.022447   -0.012624     0.014201     -0.019137   \n",
              "DOW_3                      -0.029278   -0.014567    -0.000934     -0.026389   \n",
              "DOW_4                      -0.009122   -0.013820    -0.003563     -0.015573   \n",
              "DOW_5                      -0.011719   -0.006826    -0.002263     -0.011149   \n",
              "DOW_6                      -0.023250   -0.016172    -0.005741     -0.019905   \n",
              "CLV_Score                   0.039968    0.053582     0.051527      0.067097   \n",
              "RFM_Score                   0.038424    0.052040     0.046542      0.063801   \n",
              "Loyalty                     0.037066    0.046649     0.100662      0.057946   \n",
              "CUI_American                0.023113    0.049893     0.049653      0.044878   \n",
              "CUI_Asian                   0.016458    0.032392     0.020247      0.036830   \n",
              "CUI_Beverages               0.013354    0.027950     0.022779      0.044909   \n",
              "CUI_Cafe                    0.030000    0.004777     0.047521      0.013547   \n",
              "CUI_Chicken_Dishes          0.014262    0.017962     0.007127      0.028855   \n",
              "CUI_Chinese                 0.010143    0.028586     0.021004      0.032553   \n",
              "CUI_Desserts                0.010363    0.014390     0.011883      0.023153   \n",
              "CUI_Healthy                 1.000000    0.010665     0.017604      0.018552   \n",
              "CUI_Indian                  0.010665    1.000000     0.040446      0.016559   \n",
              "CUI_Italian                 0.017604    0.040446     1.000000      0.026348   \n",
              "CUI_Japanese                0.018552    0.016559     0.026348      1.000000   \n",
              "CUI_Noodle_Dishes           0.008778    0.023799     0.017226      0.024674   \n",
              "CUI_OTHER                   0.024644    0.057851     0.028960      0.044269   \n",
              "CUI_Street_Food/Snacks     -0.000496    0.019705     0.008926      0.014532   \n",
              "CUI_Thai                    0.003271    0.025443     0.011422      0.028720   \n",
              "is_chain                   -0.063150   -0.091053    -0.074735     -0.088860   \n",
              "Orders_Night                0.025375    0.002744     0.051014      0.012773   \n",
              "Orders_Dawn                 0.008207    0.033242     0.064033      0.035261   \n",
              "Orders_Morning             -0.022495    0.006460     0.023730     -0.018262   \n",
              "Orders_Afternoon           -0.036976   -0.030659    -0.010916     -0.052705   \n",
              "Orders_Evening             -0.041040   -0.037663    -0.073522     -0.061768   \n",
              "Orders_Dusk                -0.026871   -0.106213    -0.069623     -0.058590   \n",
              "Age_Group                  -0.010762    0.005715    -0.009614      0.005911   \n",
              "vendor_count               -0.076371   -0.075448    -0.069048     -0.108646   \n",
              "product_count              -0.023637   -0.011355     0.038050     -0.024791   \n",
              "Total_Orders_Per_Client    -0.043395   -0.040390     0.000771     -0.062809   \n",
              "mnt                         0.033129    0.102434     0.133291      0.081742   \n",
              "mnt_Per_Order               0.097381    0.185433     0.188213      0.187344   \n",
              "Items_Per_Order             0.043988    0.080411     0.121660      0.099722   \n",
              "frq                         0.037996    0.029767     0.019594      0.055034   \n",
              "rcn                         0.015912    0.010372    -0.004616      0.027812   \n",
              "activity                   -0.042946   -0.034492    -0.003151     -0.059256   \n",
              "\n",
              "                         CUI_Noodle_Dishes  CUI_OTHER  CUI_Street_Food/Snacks  \\\n",
              "DOW_0                            -0.020294   0.014130               -0.016510   \n",
              "DOW_1                            -0.014173   0.022086               -0.017793   \n",
              "DOW_2                            -0.030887   0.029338               -0.013291   \n",
              "DOW_3                            -0.014357   0.008195               -0.008626   \n",
              "DOW_4                            -0.009558   0.020205               -0.007211   \n",
              "DOW_5                            -0.019269   0.018507               -0.022651   \n",
              "DOW_6                            -0.018516   0.016055               -0.013440   \n",
              "CLV_Score                         0.045779   0.111758                0.055347   \n",
              "RFM_Score                         0.045087   0.107312                0.045112   \n",
              "Loyalty                           0.025661   0.078312                0.021250   \n",
              "CUI_American                      0.039889   0.067226                0.011723   \n",
              "CUI_Asian                         0.022214   0.017991                0.030551   \n",
              "CUI_Beverages                     0.038532   0.060692                0.013640   \n",
              "CUI_Cafe                          0.002304   0.023686               -0.001544   \n",
              "CUI_Chicken_Dishes                0.025071   0.059971                0.004111   \n",
              "CUI_Chinese                       0.045482   0.074387                0.018343   \n",
              "CUI_Desserts                      0.009643   0.028446                0.031545   \n",
              "CUI_Healthy                       0.008778   0.024644               -0.000496   \n",
              "CUI_Indian                        0.023799   0.057851                0.019705   \n",
              "CUI_Italian                       0.017226   0.028960                0.008926   \n",
              "CUI_Japanese                      0.024674   0.044269                0.014532   \n",
              "CUI_Noodle_Dishes                 1.000000   0.049150                0.014787   \n",
              "CUI_OTHER                         0.049150   1.000000                0.000692   \n",
              "CUI_Street_Food/Snacks            0.014787   0.000692                1.000000   \n",
              "CUI_Thai                          0.025630   0.034475                0.008138   \n",
              "is_chain                         -0.083204  -0.100366               -0.032380   \n",
              "Orders_Night                      0.013677   0.039770                0.001561   \n",
              "Orders_Dawn                       0.039217   0.076726                0.012194   \n",
              "Orders_Morning                   -0.011507   0.034570               -0.009778   \n",
              "Orders_Afternoon                 -0.023583  -0.021786               -0.009926   \n",
              "Orders_Evening                   -0.054367  -0.040180               -0.034443   \n",
              "Orders_Dusk                      -0.071455  -0.090372               -0.046950   \n",
              "Age_Group                        -0.006460   0.004447               -0.000392   \n",
              "vendor_count                     -0.075103  -0.066252               -0.046854   \n",
              "product_count                    -0.017732   0.019656                0.032351   \n",
              "Total_Orders_Per_Client          -0.049222  -0.022687               -0.026559   \n",
              "mnt                               0.091998   0.199450                0.075274   \n",
              "mnt_Per_Order                     0.175486   0.271743                0.133339   \n",
              "Items_Per_Order                   0.072472   0.126142                0.147282   \n",
              "frq                               0.031145   0.060305                0.018881   \n",
              "rcn                               0.014812  -0.019620                0.007585   \n",
              "activity                         -0.043722  -0.014624               -0.026195   \n",
              "\n",
              "                         CUI_Thai  is_chain  Orders_Night  Orders_Dawn  \\\n",
              "DOW_0                   -0.011773  0.380964      0.117614     0.112148   \n",
              "DOW_1                   -0.010852  0.381061      0.092907     0.101717   \n",
              "DOW_2                   -0.016498  0.384234      0.089564     0.097099   \n",
              "DOW_3                   -0.015371  0.382928      0.078979     0.087339   \n",
              "DOW_4                   -0.007092  0.364731      0.051334     0.053484   \n",
              "DOW_5                   -0.011761  0.335270      0.072311     0.079144   \n",
              "DOW_6                   -0.012242  0.347896      0.057427     0.069818   \n",
              "CLV_Score                0.028161 -0.086399      0.036009     0.043632   \n",
              "RFM_Score                0.027352 -0.124700      0.015206     0.020149   \n",
              "Loyalty                  0.048223  0.384554      0.013339     0.001447   \n",
              "CUI_American             0.030616 -0.095541      0.062320     0.059124   \n",
              "CUI_Asian                0.018244 -0.013505      0.124434     0.084652   \n",
              "CUI_Beverages            0.023358 -0.122599      0.014400     0.050755   \n",
              "CUI_Cafe                 0.015465 -0.033732      0.035755     0.026209   \n",
              "CUI_Chicken_Dishes       0.016097 -0.074565      0.027999     0.047501   \n",
              "CUI_Chinese              0.011702 -0.092873      0.021352     0.029808   \n",
              "CUI_Desserts             0.006628 -0.070229      0.002119     0.014950   \n",
              "CUI_Healthy              0.003271 -0.063150      0.025375     0.008207   \n",
              "CUI_Indian               0.025443 -0.091053      0.002744     0.033242   \n",
              "CUI_Italian              0.011422 -0.074735      0.051014     0.064033   \n",
              "CUI_Japanese             0.028720 -0.088860      0.012773     0.035261   \n",
              "CUI_Noodle_Dishes        0.025630 -0.083204      0.013677     0.039217   \n",
              "CUI_OTHER                0.034475 -0.100366      0.039770     0.076726   \n",
              "CUI_Street_Food/Snacks   0.008138 -0.032380      0.001561     0.012194   \n",
              "CUI_Thai                 1.000000 -0.048794      0.022438     0.034811   \n",
              "is_chain                -0.048794  1.000000      0.068228     0.083559   \n",
              "Orders_Night             0.022438  0.068228      1.000000     0.261559   \n",
              "Orders_Dawn              0.034811  0.083559      0.261559     1.000000   \n",
              "Orders_Morning          -0.011085  0.373017      0.019263     0.104039   \n",
              "Orders_Afternoon        -0.030789  0.391147     -0.114402    -0.097039   \n",
              "Orders_Evening          -0.041215  0.367363     -0.261940    -0.289791   \n",
              "Orders_Dusk             -0.058503  0.288315      0.026949    -0.086220   \n",
              "Age_Group               -0.009655  0.004309      0.000482    -0.002274   \n",
              "vendor_count            -0.063870  0.704662      0.186750     0.205403   \n",
              "product_count           -0.011918  0.675685      0.169706     0.168363   \n",
              "Total_Orders_Per_Client -0.030759  0.727238      0.156379     0.166701   \n",
              "mnt                      0.051600  0.359597      0.266130     0.310476   \n",
              "mnt_Per_Order            0.113304 -0.355419      0.206395     0.260687   \n",
              "Items_Per_Order          0.051293  0.084938      0.102970     0.074402   \n",
              "frq                      0.015079 -0.239551     -0.059586    -0.073573   \n",
              "rcn                      0.011523 -0.333840     -0.086558    -0.104074   \n",
              "activity                -0.020498  0.601557      0.127563     0.146064   \n",
              "\n",
              "                         Orders_Morning  Orders_Afternoon  Orders_Evening  \\\n",
              "DOW_0                          0.289692          0.270555        0.209825   \n",
              "DOW_1                          0.271741          0.274315        0.222328   \n",
              "DOW_2                          0.286622          0.278179        0.238674   \n",
              "DOW_3                          0.273337          0.290232        0.260003   \n",
              "DOW_4                          0.248499          0.274976        0.296619   \n",
              "DOW_5                          0.224566          0.261760        0.264613   \n",
              "DOW_6                          0.238807          0.300375        0.267745   \n",
              "CLV_Score                      0.050462          0.008237       -0.041549   \n",
              "RFM_Score                      0.021244         -0.016595       -0.058072   \n",
              "Loyalty                        0.254087          0.335086        0.360599   \n",
              "CUI_American                  -0.004908         -0.037705       -0.063659   \n",
              "CUI_Asian                      0.005080         -0.024523       -0.078138   \n",
              "CUI_Beverages                 -0.016675         -0.063277       -0.055467   \n",
              "CUI_Cafe                      -0.023953         -0.019539       -0.047638   \n",
              "CUI_Chicken_Dishes             0.014607         -0.028598       -0.034149   \n",
              "CUI_Chinese                    0.009509         -0.037329       -0.049854   \n",
              "CUI_Desserts                  -0.013392         -0.038499       -0.039750   \n",
              "CUI_Healthy                   -0.022495         -0.036976       -0.041040   \n",
              "CUI_Indian                     0.006460         -0.030659       -0.037663   \n",
              "CUI_Italian                    0.023730         -0.010916       -0.073522   \n",
              "CUI_Japanese                  -0.018262         -0.052705       -0.061768   \n",
              "CUI_Noodle_Dishes             -0.011507         -0.023583       -0.054367   \n",
              "CUI_OTHER                      0.034570         -0.021786       -0.040180   \n",
              "CUI_Street_Food/Snacks        -0.009778         -0.009926       -0.034443   \n",
              "CUI_Thai                      -0.011085         -0.030789       -0.041215   \n",
              "is_chain                       0.373017          0.391147        0.367363   \n",
              "Orders_Night                   0.019263         -0.114402       -0.261940   \n",
              "Orders_Dawn                    0.104039         -0.097039       -0.289791   \n",
              "Orders_Morning                 1.000000          0.111179       -0.042219   \n",
              "Orders_Afternoon               0.111179          1.000000        0.194082   \n",
              "Orders_Evening                -0.042219          0.194082        1.000000   \n",
              "Orders_Dusk                   -0.002455          0.100161        0.150858   \n",
              "Age_Group                     -0.001494          0.006926        0.001311   \n",
              "vendor_count                   0.453062          0.441676        0.378383   \n",
              "product_count                  0.455766          0.481191        0.422329   \n",
              "Total_Orders_Per_Client        0.471672          0.502094        0.457202   \n",
              "mnt                            0.409676          0.307815        0.174555   \n",
              "mnt_Per_Order                 -0.010273         -0.196626       -0.334636   \n",
              "Items_Per_Order                0.104077          0.092326        0.040564   \n",
              "frq                           -0.104287         -0.124388       -0.118235   \n",
              "rcn                           -0.260038         -0.269009       -0.216990   \n",
              "activity                       0.388502          0.422268        0.385903   \n",
              "\n",
              "                         Orders_Dusk  Age_Group  vendor_count  product_count  \\\n",
              "DOW_0                       0.166647   0.014155      0.444394       0.467621   \n",
              "DOW_1                       0.172557   0.002188      0.441420       0.467889   \n",
              "DOW_2                       0.163488   0.002543      0.449241       0.486109   \n",
              "DOW_3                       0.160200   0.008337      0.450414       0.485919   \n",
              "DOW_4                       0.166407  -0.002040      0.429584       0.470255   \n",
              "DOW_5                       0.169846  -0.002210      0.409335       0.427865   \n",
              "DOW_6                       0.163296   0.003904      0.417778       0.445346   \n",
              "CLV_Score                  -0.022636   0.008029     -0.107176      -0.043445   \n",
              "RFM_Score                  -0.031836   0.006676     -0.162246      -0.101710   \n",
              "Loyalty                     0.128033   0.009922      0.238197       0.581853   \n",
              "CUI_American               -0.098646   0.009693     -0.111250       0.005921   \n",
              "CUI_Asian                  -0.024145   0.011969     -0.025968       0.087398   \n",
              "CUI_Beverages              -0.104413  -0.005341     -0.115958      -0.034609   \n",
              "CUI_Cafe                   -0.006549  -0.003634     -0.050680      -0.019424   \n",
              "CUI_Chicken_Dishes         -0.064339  -0.002565     -0.056442      -0.000743   \n",
              "CUI_Chinese                -0.078869  -0.004241     -0.080605      -0.021622   \n",
              "CUI_Desserts               -0.047355   0.002856     -0.075052      -0.028531   \n",
              "CUI_Healthy                -0.026871  -0.010762     -0.076371      -0.023637   \n",
              "CUI_Indian                 -0.106213   0.005715     -0.075448      -0.011355   \n",
              "CUI_Italian                -0.069623  -0.009614     -0.069048       0.038050   \n",
              "CUI_Japanese               -0.058590   0.005911     -0.108646      -0.024791   \n",
              "CUI_Noodle_Dishes          -0.071455  -0.006460     -0.075103      -0.017732   \n",
              "CUI_OTHER                  -0.090372   0.004447     -0.066252       0.019656   \n",
              "CUI_Street_Food/Snacks     -0.046950  -0.000392     -0.046854       0.032351   \n",
              "CUI_Thai                   -0.058503  -0.009655     -0.063870      -0.011918   \n",
              "is_chain                    0.288315   0.004309      0.704662       0.675685   \n",
              "Orders_Night                0.026949   0.000482      0.186750       0.169706   \n",
              "Orders_Dawn                -0.086220  -0.002274      0.205403       0.168363   \n",
              "Orders_Morning             -0.002455  -0.001494      0.453062       0.455766   \n",
              "Orders_Afternoon            0.100161   0.006926      0.441676       0.481191   \n",
              "Orders_Evening              0.150858   0.001311      0.378383       0.422329   \n",
              "Orders_Dusk                 1.000000   0.001361      0.285205       0.257246   \n",
              "Age_Group                   0.001361   1.000000      0.003960       0.008210   \n",
              "vendor_count                0.285205   0.003960      1.000000       0.842378   \n",
              "product_count               0.257246   0.008210      0.842378       1.000000   \n",
              "Total_Orders_Per_Client     0.275351   0.008039      0.886126       0.946879   \n",
              "mnt                         0.045480   0.007902      0.613952       0.795042   \n",
              "mnt_Per_Order              -0.287962   0.002042     -0.184805      -0.033330   \n",
              "Items_Per_Order             0.029254   0.003364      0.178186       0.465396   \n",
              "frq                        -0.037365  -0.003050     -0.367862      -0.339693   \n",
              "rcn                        -0.114656  -0.012532     -0.442191      -0.468386   \n",
              "activity                    0.218687   0.006400      0.755993       0.784038   \n",
              "\n",
              "                         Total_Orders_Per_Client       mnt  mnt_Per_Order  \\\n",
              "DOW_0                                   0.487078  0.367186      -0.095872   \n",
              "DOW_1                                   0.488111  0.361109      -0.106459   \n",
              "DOW_2                                   0.505805  0.377148      -0.101740   \n",
              "DOW_3                                   0.506955  0.372713      -0.113150   \n",
              "DOW_4                                   0.489599  0.359802      -0.107482   \n",
              "DOW_5                                   0.441399  0.328541      -0.091810   \n",
              "DOW_6                                   0.457593  0.332949      -0.102645   \n",
              "CLV_Score                              -0.106557  0.119324       0.223013   \n",
              "RFM_Score                              -0.165023  0.069739       0.214071   \n",
              "Loyalty                                 0.616230  0.418518      -0.158522   \n",
              "CUI_American                           -0.044018  0.151092       0.259137   \n",
              "CUI_Asian                               0.026927  0.134996       0.173878   \n",
              "CUI_Beverages                          -0.066371  0.103059       0.217276   \n",
              "CUI_Cafe                               -0.030914  0.006832       0.052662   \n",
              "CUI_Chicken_Dishes                     -0.026319  0.116664       0.173162   \n",
              "CUI_Chinese                            -0.048720  0.106115       0.189395   \n",
              "CUI_Desserts                           -0.049974  0.034422       0.113834   \n",
              "CUI_Healthy                            -0.043395  0.033129       0.097381   \n",
              "CUI_Indian                             -0.040390  0.102434       0.185433   \n",
              "CUI_Italian                             0.000771  0.133291       0.188213   \n",
              "CUI_Japanese                           -0.062809  0.081742       0.187344   \n",
              "CUI_Noodle_Dishes                      -0.049222  0.091998       0.175486   \n",
              "CUI_OTHER                              -0.022687  0.199450       0.271743   \n",
              "CUI_Street_Food/Snacks                 -0.026559  0.075274       0.133339   \n",
              "CUI_Thai                               -0.030759  0.051600       0.113304   \n",
              "is_chain                                0.727238  0.359597      -0.355419   \n",
              "Orders_Night                            0.156379  0.266130       0.206395   \n",
              "Orders_Dawn                             0.166701  0.310476       0.260687   \n",
              "Orders_Morning                          0.471672  0.409676      -0.010273   \n",
              "Orders_Afternoon                        0.502094  0.307815      -0.196626   \n",
              "Orders_Evening                          0.457202  0.174555      -0.334636   \n",
              "Orders_Dusk                             0.275351  0.045480      -0.287962   \n",
              "Age_Group                               0.008039  0.007902       0.002042   \n",
              "vendor_count                            0.886126  0.613952      -0.184805   \n",
              "product_count                           0.946879  0.795042      -0.033330   \n",
              "Total_Orders_Per_Client                 1.000000  0.682539      -0.218448   \n",
              "mnt                                     0.682539  1.000000       0.512704   \n",
              "mnt_Per_Order                          -0.218448  0.512704       1.000000   \n",
              "Items_Per_Order                         0.181313  0.565664       0.521619   \n",
              "frq                                    -0.386786 -0.197222       0.110296   \n",
              "rcn                                    -0.491767 -0.378727       0.063692   \n",
              "activity                                0.832197  0.566966      -0.186461   \n",
              "\n",
              "                         Items_Per_Order       frq       rcn  activity  \n",
              "DOW_0                           0.090421 -0.078086 -0.241139  0.398360  \n",
              "DOW_1                           0.090598 -0.072986 -0.251493  0.397150  \n",
              "DOW_2                           0.099674 -0.087117 -0.273226  0.417149  \n",
              "DOW_3                           0.095464 -0.088083 -0.299676  0.421766  \n",
              "DOW_4                           0.095874 -0.091739 -0.302244  0.404916  \n",
              "DOW_5                           0.099923 -0.076712 -0.206894  0.356761  \n",
              "DOW_6                           0.110594 -0.103022 -0.220279  0.386163  \n",
              "CLV_Score                       0.125428  0.574515 -0.406842 -0.183989  \n",
              "RFM_Score                       0.102301  0.620062 -0.364907 -0.247917  \n",
              "Loyalty                         0.084251 -0.171074 -0.305183  0.495155  \n",
              "CUI_American                    0.139976  0.074937 -0.001536 -0.047178  \n",
              "CUI_Asian                       0.198714  0.027655 -0.014886  0.009899  \n",
              "CUI_Beverages                   0.074321  0.056381  0.010748 -0.061953  \n",
              "CUI_Cafe                        0.025960  0.022728  0.010790 -0.025276  \n",
              "CUI_Chicken_Dishes              0.078059  0.039513 -0.010467 -0.025297  \n",
              "CUI_Chinese                     0.071722  0.033248 -0.005776 -0.028910  \n",
              "CUI_Desserts                    0.051868  0.034559  0.014500 -0.045942  \n",
              "CUI_Healthy                     0.043988  0.037996  0.015912 -0.042946  \n",
              "CUI_Indian                      0.080411  0.029767  0.010372 -0.034492  \n",
              "CUI_Italian                     0.121660  0.019594 -0.004616 -0.003151  \n",
              "CUI_Japanese                    0.099722  0.055034  0.027812 -0.059256  \n",
              "CUI_Noodle_Dishes               0.072472  0.031145  0.014812 -0.043722  \n",
              "CUI_OTHER                       0.126142  0.060305 -0.019620 -0.014624  \n",
              "CUI_Street_Food/Snacks          0.147282  0.018881  0.007585 -0.026195  \n",
              "CUI_Thai                        0.051293  0.015079  0.011523 -0.020498  \n",
              "is_chain                        0.084938 -0.239551 -0.333840  0.601557  \n",
              "Orders_Night                    0.102970 -0.059586 -0.086558  0.127563  \n",
              "Orders_Dawn                     0.074402 -0.073573 -0.104074  0.146064  \n",
              "Orders_Morning                  0.104077 -0.104287 -0.260038  0.388502  \n",
              "Orders_Afternoon                0.092326 -0.124388 -0.269009  0.422268  \n",
              "Orders_Evening                  0.040564 -0.118235 -0.216990  0.385903  \n",
              "Orders_Dusk                     0.029254 -0.037365 -0.114656  0.218687  \n",
              "Age_Group                       0.003364 -0.003050 -0.012532  0.006400  \n",
              "vendor_count                    0.178186 -0.367862 -0.442191  0.755993  \n",
              "product_count                   0.465396 -0.339693 -0.468386  0.784038  \n",
              "Total_Orders_Per_Client         0.181313 -0.386786 -0.491767  0.832197  \n",
              "mnt                             0.565664 -0.197222 -0.378727  0.566966  \n",
              "mnt_Per_Order                   0.521619  0.110296  0.063692 -0.186461  \n",
              "Items_Per_Order                 1.000000 -0.019855 -0.092306  0.140074  \n",
              "frq                            -0.019855  1.000000  0.337825 -0.718351  \n",
              "rcn                            -0.092306  0.337825  1.000000 -0.590171  \n",
              "activity                        0.140074 -0.718351 -0.590171  1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1da074db-c7f5-4ad8-99b8-4a234817cba7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DOW_0</th>\n",
              "      <th>DOW_1</th>\n",
              "      <th>DOW_2</th>\n",
              "      <th>DOW_3</th>\n",
              "      <th>DOW_4</th>\n",
              "      <th>DOW_5</th>\n",
              "      <th>DOW_6</th>\n",
              "      <th>CLV_Score</th>\n",
              "      <th>RFM_Score</th>\n",
              "      <th>Loyalty</th>\n",
              "      <th>CUI_American</th>\n",
              "      <th>CUI_Asian</th>\n",
              "      <th>CUI_Beverages</th>\n",
              "      <th>CUI_Cafe</th>\n",
              "      <th>CUI_Chicken_Dishes</th>\n",
              "      <th>CUI_Chinese</th>\n",
              "      <th>CUI_Desserts</th>\n",
              "      <th>CUI_Healthy</th>\n",
              "      <th>CUI_Indian</th>\n",
              "      <th>CUI_Italian</th>\n",
              "      <th>CUI_Japanese</th>\n",
              "      <th>CUI_Noodle_Dishes</th>\n",
              "      <th>CUI_OTHER</th>\n",
              "      <th>CUI_Street_Food/Snacks</th>\n",
              "      <th>CUI_Thai</th>\n",
              "      <th>is_chain</th>\n",
              "      <th>Orders_Night</th>\n",
              "      <th>Orders_Dawn</th>\n",
              "      <th>Orders_Morning</th>\n",
              "      <th>Orders_Afternoon</th>\n",
              "      <th>Orders_Evening</th>\n",
              "      <th>Orders_Dusk</th>\n",
              "      <th>Age_Group</th>\n",
              "      <th>vendor_count</th>\n",
              "      <th>product_count</th>\n",
              "      <th>Total_Orders_Per_Client</th>\n",
              "      <th>mnt</th>\n",
              "      <th>mnt_Per_Order</th>\n",
              "      <th>Items_Per_Order</th>\n",
              "      <th>frq</th>\n",
              "      <th>rcn</th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DOW_0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.239451</td>\n",
              "      <td>0.234692</td>\n",
              "      <td>0.225882</td>\n",
              "      <td>0.176707</td>\n",
              "      <td>0.130844</td>\n",
              "      <td>0.144047</td>\n",
              "      <td>0.041674</td>\n",
              "      <td>0.015459</td>\n",
              "      <td>0.309971</td>\n",
              "      <td>-0.007948</td>\n",
              "      <td>0.031864</td>\n",
              "      <td>-0.023641</td>\n",
              "      <td>-0.009666</td>\n",
              "      <td>0.003849</td>\n",
              "      <td>-0.012840</td>\n",
              "      <td>-0.020678</td>\n",
              "      <td>-0.009510</td>\n",
              "      <td>-0.021093</td>\n",
              "      <td>0.006957</td>\n",
              "      <td>-0.032283</td>\n",
              "      <td>-0.020294</td>\n",
              "      <td>0.014130</td>\n",
              "      <td>-0.016510</td>\n",
              "      <td>-0.011773</td>\n",
              "      <td>0.380964</td>\n",
              "      <td>0.117614</td>\n",
              "      <td>0.112148</td>\n",
              "      <td>0.289692</td>\n",
              "      <td>0.270555</td>\n",
              "      <td>0.209825</td>\n",
              "      <td>0.166647</td>\n",
              "      <td>0.014155</td>\n",
              "      <td>0.444394</td>\n",
              "      <td>0.467621</td>\n",
              "      <td>0.487078</td>\n",
              "      <td>0.367186</td>\n",
              "      <td>-0.095872</td>\n",
              "      <td>0.090421</td>\n",
              "      <td>-0.078086</td>\n",
              "      <td>-0.241139</td>\n",
              "      <td>0.398360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DOW_1</th>\n",
              "      <td>0.239451</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.248535</td>\n",
              "      <td>0.235444</td>\n",
              "      <td>0.185994</td>\n",
              "      <td>0.122919</td>\n",
              "      <td>0.123414</td>\n",
              "      <td>0.052926</td>\n",
              "      <td>0.025526</td>\n",
              "      <td>0.320087</td>\n",
              "      <td>0.004187</td>\n",
              "      <td>0.017901</td>\n",
              "      <td>-0.018165</td>\n",
              "      <td>-0.005425</td>\n",
              "      <td>0.006780</td>\n",
              "      <td>-0.014745</td>\n",
              "      <td>-0.013502</td>\n",
              "      <td>-0.016770</td>\n",
              "      <td>-0.022564</td>\n",
              "      <td>0.007983</td>\n",
              "      <td>-0.029118</td>\n",
              "      <td>-0.014173</td>\n",
              "      <td>0.022086</td>\n",
              "      <td>-0.017793</td>\n",
              "      <td>-0.010852</td>\n",
              "      <td>0.381061</td>\n",
              "      <td>0.092907</td>\n",
              "      <td>0.101717</td>\n",
              "      <td>0.271741</td>\n",
              "      <td>0.274315</td>\n",
              "      <td>0.222328</td>\n",
              "      <td>0.172557</td>\n",
              "      <td>0.002188</td>\n",
              "      <td>0.441420</td>\n",
              "      <td>0.467889</td>\n",
              "      <td>0.488111</td>\n",
              "      <td>0.361109</td>\n",
              "      <td>-0.106459</td>\n",
              "      <td>0.090598</td>\n",
              "      <td>-0.072986</td>\n",
              "      <td>-0.251493</td>\n",
              "      <td>0.397150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DOW_2</th>\n",
              "      <td>0.234692</td>\n",
              "      <td>0.248535</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.242585</td>\n",
              "      <td>0.197536</td>\n",
              "      <td>0.120607</td>\n",
              "      <td>0.135044</td>\n",
              "      <td>0.063361</td>\n",
              "      <td>0.036966</td>\n",
              "      <td>0.336971</td>\n",
              "      <td>-0.002909</td>\n",
              "      <td>0.008809</td>\n",
              "      <td>-0.019424</td>\n",
              "      <td>-0.005220</td>\n",
              "      <td>0.007988</td>\n",
              "      <td>-0.007617</td>\n",
              "      <td>-0.030035</td>\n",
              "      <td>-0.022447</td>\n",
              "      <td>-0.012624</td>\n",
              "      <td>0.014201</td>\n",
              "      <td>-0.019137</td>\n",
              "      <td>-0.030887</td>\n",
              "      <td>0.029338</td>\n",
              "      <td>-0.013291</td>\n",
              "      <td>-0.016498</td>\n",
              "      <td>0.384234</td>\n",
              "      <td>0.089564</td>\n",
              "      <td>0.097099</td>\n",
              "      <td>0.286622</td>\n",
              "      <td>0.278179</td>\n",
              "      <td>0.238674</td>\n",
              "      <td>0.163488</td>\n",
              "      <td>0.002543</td>\n",
              "      <td>0.449241</td>\n",
              "      <td>0.486109</td>\n",
              "      <td>0.505805</td>\n",
              "      <td>0.377148</td>\n",
              "      <td>-0.101740</td>\n",
              "      <td>0.099674</td>\n",
              "      <td>-0.087117</td>\n",
              "      <td>-0.273226</td>\n",
              "      <td>0.417149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DOW_3</th>\n",
              "      <td>0.225882</td>\n",
              "      <td>0.235444</td>\n",
              "      <td>0.242585</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.204534</td>\n",
              "      <td>0.131171</td>\n",
              "      <td>0.128172</td>\n",
              "      <td>0.094587</td>\n",
              "      <td>0.066596</td>\n",
              "      <td>0.339671</td>\n",
              "      <td>-0.000416</td>\n",
              "      <td>0.021530</td>\n",
              "      <td>-0.016312</td>\n",
              "      <td>-0.010115</td>\n",
              "      <td>-0.000787</td>\n",
              "      <td>-0.000660</td>\n",
              "      <td>-0.025462</td>\n",
              "      <td>-0.029278</td>\n",
              "      <td>-0.014567</td>\n",
              "      <td>-0.000934</td>\n",
              "      <td>-0.026389</td>\n",
              "      <td>-0.014357</td>\n",
              "      <td>0.008195</td>\n",
              "      <td>-0.008626</td>\n",
              "      <td>-0.015371</td>\n",
              "      <td>0.382928</td>\n",
              "      <td>0.078979</td>\n",
              "      <td>0.087339</td>\n",
              "      <td>0.273337</td>\n",
              "      <td>0.290232</td>\n",
              "      <td>0.260003</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.008337</td>\n",
              "      <td>0.450414</td>\n",
              "      <td>0.485919</td>\n",
              "      <td>0.506955</td>\n",
              "      <td>0.372713</td>\n",
              "      <td>-0.113150</td>\n",
              "      <td>0.095464</td>\n",
              "      <td>-0.088083</td>\n",
              "      <td>-0.299676</td>\n",
              "      <td>0.421766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DOW_4</th>\n",
              "      <td>0.176707</td>\n",
              "      <td>0.185994</td>\n",
              "      <td>0.197536</td>\n",
              "      <td>0.204534</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.139216</td>\n",
              "      <td>0.126009</td>\n",
              "      <td>0.100607</td>\n",
              "      <td>0.055575</td>\n",
              "      <td>0.334988</td>\n",
              "      <td>-0.005596</td>\n",
              "      <td>0.018773</td>\n",
              "      <td>-0.014867</td>\n",
              "      <td>-0.003749</td>\n",
              "      <td>-0.004226</td>\n",
              "      <td>-0.006766</td>\n",
              "      <td>-0.014771</td>\n",
              "      <td>-0.009122</td>\n",
              "      <td>-0.013820</td>\n",
              "      <td>-0.003563</td>\n",
              "      <td>-0.015573</td>\n",
              "      <td>-0.009558</td>\n",
              "      <td>0.020205</td>\n",
              "      <td>-0.007211</td>\n",
              "      <td>-0.007092</td>\n",
              "      <td>0.364731</td>\n",
              "      <td>0.051334</td>\n",
              "      <td>0.053484</td>\n",
              "      <td>0.248499</td>\n",
              "      <td>0.274976</td>\n",
              "      <td>0.296619</td>\n",
              "      <td>0.166407</td>\n",
              "      <td>-0.002040</td>\n",
              "      <td>0.429584</td>\n",
              "      <td>0.470255</td>\n",
              "      <td>0.489599</td>\n",
              "      <td>0.359802</td>\n",
              "      <td>-0.107482</td>\n",
              "      <td>0.095874</td>\n",
              "      <td>-0.091739</td>\n",
              "      <td>-0.302244</td>\n",
              "      <td>0.404916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DOW_5</th>\n",
              "      <td>0.130844</td>\n",
              "      <td>0.122919</td>\n",
              "      <td>0.120607</td>\n",
              "      <td>0.131171</td>\n",
              "      <td>0.139216</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.190266</td>\n",
              "      <td>0.016857</td>\n",
              "      <td>-0.007242</td>\n",
              "      <td>0.271503</td>\n",
              "      <td>-0.008867</td>\n",
              "      <td>0.019214</td>\n",
              "      <td>-0.036072</td>\n",
              "      <td>-0.011699</td>\n",
              "      <td>-0.001307</td>\n",
              "      <td>-0.020450</td>\n",
              "      <td>-0.026734</td>\n",
              "      <td>-0.011719</td>\n",
              "      <td>-0.006826</td>\n",
              "      <td>-0.002263</td>\n",
              "      <td>-0.011149</td>\n",
              "      <td>-0.019269</td>\n",
              "      <td>0.018507</td>\n",
              "      <td>-0.022651</td>\n",
              "      <td>-0.011761</td>\n",
              "      <td>0.335270</td>\n",
              "      <td>0.072311</td>\n",
              "      <td>0.079144</td>\n",
              "      <td>0.224566</td>\n",
              "      <td>0.261760</td>\n",
              "      <td>0.264613</td>\n",
              "      <td>0.169846</td>\n",
              "      <td>-0.002210</td>\n",
              "      <td>0.409335</td>\n",
              "      <td>0.427865</td>\n",
              "      <td>0.441399</td>\n",
              "      <td>0.328541</td>\n",
              "      <td>-0.091810</td>\n",
              "      <td>0.099923</td>\n",
              "      <td>-0.076712</td>\n",
              "      <td>-0.206894</td>\n",
              "      <td>0.356761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DOW_6</th>\n",
              "      <td>0.144047</td>\n",
              "      <td>0.123414</td>\n",
              "      <td>0.135044</td>\n",
              "      <td>0.128172</td>\n",
              "      <td>0.126009</td>\n",
              "      <td>0.190266</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.004533</td>\n",
              "      <td>-0.029825</td>\n",
              "      <td>0.284548</td>\n",
              "      <td>-0.016091</td>\n",
              "      <td>0.008614</td>\n",
              "      <td>-0.028407</td>\n",
              "      <td>-0.015837</td>\n",
              "      <td>-0.004361</td>\n",
              "      <td>-0.014939</td>\n",
              "      <td>-0.022278</td>\n",
              "      <td>-0.023250</td>\n",
              "      <td>-0.016172</td>\n",
              "      <td>-0.005741</td>\n",
              "      <td>-0.019905</td>\n",
              "      <td>-0.018516</td>\n",
              "      <td>0.016055</td>\n",
              "      <td>-0.013440</td>\n",
              "      <td>-0.012242</td>\n",
              "      <td>0.347896</td>\n",
              "      <td>0.057427</td>\n",
              "      <td>0.069818</td>\n",
              "      <td>0.238807</td>\n",
              "      <td>0.300375</td>\n",
              "      <td>0.267745</td>\n",
              "      <td>0.163296</td>\n",
              "      <td>0.003904</td>\n",
              "      <td>0.417778</td>\n",
              "      <td>0.445346</td>\n",
              "      <td>0.457593</td>\n",
              "      <td>0.332949</td>\n",
              "      <td>-0.102645</td>\n",
              "      <td>0.110594</td>\n",
              "      <td>-0.103022</td>\n",
              "      <td>-0.220279</td>\n",
              "      <td>0.386163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLV_Score</th>\n",
              "      <td>0.041674</td>\n",
              "      <td>0.052926</td>\n",
              "      <td>0.063361</td>\n",
              "      <td>0.094587</td>\n",
              "      <td>0.100607</td>\n",
              "      <td>0.016857</td>\n",
              "      <td>-0.004533</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989184</td>\n",
              "      <td>-0.019965</td>\n",
              "      <td>0.109149</td>\n",
              "      <td>0.082841</td>\n",
              "      <td>0.078898</td>\n",
              "      <td>0.024169</td>\n",
              "      <td>0.068521</td>\n",
              "      <td>0.073655</td>\n",
              "      <td>0.042226</td>\n",
              "      <td>0.039968</td>\n",
              "      <td>0.053582</td>\n",
              "      <td>0.051527</td>\n",
              "      <td>0.067097</td>\n",
              "      <td>0.045779</td>\n",
              "      <td>0.111758</td>\n",
              "      <td>0.055347</td>\n",
              "      <td>0.028161</td>\n",
              "      <td>-0.086399</td>\n",
              "      <td>0.036009</td>\n",
              "      <td>0.043632</td>\n",
              "      <td>0.050462</td>\n",
              "      <td>0.008237</td>\n",
              "      <td>-0.041549</td>\n",
              "      <td>-0.022636</td>\n",
              "      <td>0.008029</td>\n",
              "      <td>-0.107176</td>\n",
              "      <td>-0.043445</td>\n",
              "      <td>-0.106557</td>\n",
              "      <td>0.119324</td>\n",
              "      <td>0.223013</td>\n",
              "      <td>0.125428</td>\n",
              "      <td>0.574515</td>\n",
              "      <td>-0.406842</td>\n",
              "      <td>-0.183989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RFM_Score</th>\n",
              "      <td>0.015459</td>\n",
              "      <td>0.025526</td>\n",
              "      <td>0.036966</td>\n",
              "      <td>0.066596</td>\n",
              "      <td>0.055575</td>\n",
              "      <td>-0.007242</td>\n",
              "      <td>-0.029825</td>\n",
              "      <td>0.989184</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.053272</td>\n",
              "      <td>0.105438</td>\n",
              "      <td>0.067619</td>\n",
              "      <td>0.077297</td>\n",
              "      <td>0.021920</td>\n",
              "      <td>0.067819</td>\n",
              "      <td>0.071444</td>\n",
              "      <td>0.038678</td>\n",
              "      <td>0.038424</td>\n",
              "      <td>0.052040</td>\n",
              "      <td>0.046542</td>\n",
              "      <td>0.063801</td>\n",
              "      <td>0.045087</td>\n",
              "      <td>0.107312</td>\n",
              "      <td>0.045112</td>\n",
              "      <td>0.027352</td>\n",
              "      <td>-0.124700</td>\n",
              "      <td>0.015206</td>\n",
              "      <td>0.020149</td>\n",
              "      <td>0.021244</td>\n",
              "      <td>-0.016595</td>\n",
              "      <td>-0.058072</td>\n",
              "      <td>-0.031836</td>\n",
              "      <td>0.006676</td>\n",
              "      <td>-0.162246</td>\n",
              "      <td>-0.101710</td>\n",
              "      <td>-0.165023</td>\n",
              "      <td>0.069739</td>\n",
              "      <td>0.214071</td>\n",
              "      <td>0.102301</td>\n",
              "      <td>0.620062</td>\n",
              "      <td>-0.364907</td>\n",
              "      <td>-0.247917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loyalty</th>\n",
              "      <td>0.309971</td>\n",
              "      <td>0.320087</td>\n",
              "      <td>0.336971</td>\n",
              "      <td>0.339671</td>\n",
              "      <td>0.334988</td>\n",
              "      <td>0.271503</td>\n",
              "      <td>0.284548</td>\n",
              "      <td>-0.019965</td>\n",
              "      <td>-0.053272</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100623</td>\n",
              "      <td>0.088698</td>\n",
              "      <td>0.068987</td>\n",
              "      <td>0.022231</td>\n",
              "      <td>0.045568</td>\n",
              "      <td>0.043057</td>\n",
              "      <td>0.025652</td>\n",
              "      <td>0.037066</td>\n",
              "      <td>0.046649</td>\n",
              "      <td>0.100662</td>\n",
              "      <td>0.057946</td>\n",
              "      <td>0.025661</td>\n",
              "      <td>0.078312</td>\n",
              "      <td>0.021250</td>\n",
              "      <td>0.048223</td>\n",
              "      <td>0.384554</td>\n",
              "      <td>0.013339</td>\n",
              "      <td>0.001447</td>\n",
              "      <td>0.254087</td>\n",
              "      <td>0.335086</td>\n",
              "      <td>0.360599</td>\n",
              "      <td>0.128033</td>\n",
              "      <td>0.009922</td>\n",
              "      <td>0.238197</td>\n",
              "      <td>0.581853</td>\n",
              "      <td>0.616230</td>\n",
              "      <td>0.418518</td>\n",
              "      <td>-0.158522</td>\n",
              "      <td>0.084251</td>\n",
              "      <td>-0.171074</td>\n",
              "      <td>-0.305183</td>\n",
              "      <td>0.495155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_American</th>\n",
              "      <td>-0.007948</td>\n",
              "      <td>0.004187</td>\n",
              "      <td>-0.002909</td>\n",
              "      <td>-0.000416</td>\n",
              "      <td>-0.005596</td>\n",
              "      <td>-0.008867</td>\n",
              "      <td>-0.016091</td>\n",
              "      <td>0.109149</td>\n",
              "      <td>0.105438</td>\n",
              "      <td>0.100623</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.044933</td>\n",
              "      <td>0.067861</td>\n",
              "      <td>0.019177</td>\n",
              "      <td>0.042542</td>\n",
              "      <td>0.045970</td>\n",
              "      <td>0.033984</td>\n",
              "      <td>0.023113</td>\n",
              "      <td>0.049893</td>\n",
              "      <td>0.049653</td>\n",
              "      <td>0.044878</td>\n",
              "      <td>0.039889</td>\n",
              "      <td>0.067226</td>\n",
              "      <td>0.011723</td>\n",
              "      <td>0.030616</td>\n",
              "      <td>-0.095541</td>\n",
              "      <td>0.062320</td>\n",
              "      <td>0.059124</td>\n",
              "      <td>-0.004908</td>\n",
              "      <td>-0.037705</td>\n",
              "      <td>-0.063659</td>\n",
              "      <td>-0.098646</td>\n",
              "      <td>0.009693</td>\n",
              "      <td>-0.111250</td>\n",
              "      <td>0.005921</td>\n",
              "      <td>-0.044018</td>\n",
              "      <td>0.151092</td>\n",
              "      <td>0.259137</td>\n",
              "      <td>0.139976</td>\n",
              "      <td>0.074937</td>\n",
              "      <td>-0.001536</td>\n",
              "      <td>-0.047178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Asian</th>\n",
              "      <td>0.031864</td>\n",
              "      <td>0.017901</td>\n",
              "      <td>0.008809</td>\n",
              "      <td>0.021530</td>\n",
              "      <td>0.018773</td>\n",
              "      <td>0.019214</td>\n",
              "      <td>0.008614</td>\n",
              "      <td>0.082841</td>\n",
              "      <td>0.067619</td>\n",
              "      <td>0.088698</td>\n",
              "      <td>0.044933</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.027021</td>\n",
              "      <td>0.018364</td>\n",
              "      <td>0.012362</td>\n",
              "      <td>0.021255</td>\n",
              "      <td>0.023807</td>\n",
              "      <td>0.016458</td>\n",
              "      <td>0.032392</td>\n",
              "      <td>0.020247</td>\n",
              "      <td>0.036830</td>\n",
              "      <td>0.022214</td>\n",
              "      <td>0.017991</td>\n",
              "      <td>0.030551</td>\n",
              "      <td>0.018244</td>\n",
              "      <td>-0.013505</td>\n",
              "      <td>0.124434</td>\n",
              "      <td>0.084652</td>\n",
              "      <td>0.005080</td>\n",
              "      <td>-0.024523</td>\n",
              "      <td>-0.078138</td>\n",
              "      <td>-0.024145</td>\n",
              "      <td>0.011969</td>\n",
              "      <td>-0.025968</td>\n",
              "      <td>0.087398</td>\n",
              "      <td>0.026927</td>\n",
              "      <td>0.134996</td>\n",
              "      <td>0.173878</td>\n",
              "      <td>0.198714</td>\n",
              "      <td>0.027655</td>\n",
              "      <td>-0.014886</td>\n",
              "      <td>0.009899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Beverages</th>\n",
              "      <td>-0.023641</td>\n",
              "      <td>-0.018165</td>\n",
              "      <td>-0.019424</td>\n",
              "      <td>-0.016312</td>\n",
              "      <td>-0.014867</td>\n",
              "      <td>-0.036072</td>\n",
              "      <td>-0.028407</td>\n",
              "      <td>0.078898</td>\n",
              "      <td>0.077297</td>\n",
              "      <td>0.068987</td>\n",
              "      <td>0.067861</td>\n",
              "      <td>0.027021</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.003504</td>\n",
              "      <td>0.037096</td>\n",
              "      <td>0.040950</td>\n",
              "      <td>0.037508</td>\n",
              "      <td>0.013354</td>\n",
              "      <td>0.027950</td>\n",
              "      <td>0.022779</td>\n",
              "      <td>0.044909</td>\n",
              "      <td>0.038532</td>\n",
              "      <td>0.060692</td>\n",
              "      <td>0.013640</td>\n",
              "      <td>0.023358</td>\n",
              "      <td>-0.122599</td>\n",
              "      <td>0.014400</td>\n",
              "      <td>0.050755</td>\n",
              "      <td>-0.016675</td>\n",
              "      <td>-0.063277</td>\n",
              "      <td>-0.055467</td>\n",
              "      <td>-0.104413</td>\n",
              "      <td>-0.005341</td>\n",
              "      <td>-0.115958</td>\n",
              "      <td>-0.034609</td>\n",
              "      <td>-0.066371</td>\n",
              "      <td>0.103059</td>\n",
              "      <td>0.217276</td>\n",
              "      <td>0.074321</td>\n",
              "      <td>0.056381</td>\n",
              "      <td>0.010748</td>\n",
              "      <td>-0.061953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Cafe</th>\n",
              "      <td>-0.009666</td>\n",
              "      <td>-0.005425</td>\n",
              "      <td>-0.005220</td>\n",
              "      <td>-0.010115</td>\n",
              "      <td>-0.003749</td>\n",
              "      <td>-0.011699</td>\n",
              "      <td>-0.015837</td>\n",
              "      <td>0.024169</td>\n",
              "      <td>0.021920</td>\n",
              "      <td>0.022231</td>\n",
              "      <td>0.019177</td>\n",
              "      <td>0.018364</td>\n",
              "      <td>-0.003504</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002464</td>\n",
              "      <td>0.003713</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.004777</td>\n",
              "      <td>0.047521</td>\n",
              "      <td>0.013547</td>\n",
              "      <td>0.002304</td>\n",
              "      <td>0.023686</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>0.015465</td>\n",
              "      <td>-0.033732</td>\n",
              "      <td>0.035755</td>\n",
              "      <td>0.026209</td>\n",
              "      <td>-0.023953</td>\n",
              "      <td>-0.019539</td>\n",
              "      <td>-0.047638</td>\n",
              "      <td>-0.006549</td>\n",
              "      <td>-0.003634</td>\n",
              "      <td>-0.050680</td>\n",
              "      <td>-0.019424</td>\n",
              "      <td>-0.030914</td>\n",
              "      <td>0.006832</td>\n",
              "      <td>0.052662</td>\n",
              "      <td>0.025960</td>\n",
              "      <td>0.022728</td>\n",
              "      <td>0.010790</td>\n",
              "      <td>-0.025276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Chicken_Dishes</th>\n",
              "      <td>0.003849</td>\n",
              "      <td>0.006780</td>\n",
              "      <td>0.007988</td>\n",
              "      <td>-0.000787</td>\n",
              "      <td>-0.004226</td>\n",
              "      <td>-0.001307</td>\n",
              "      <td>-0.004361</td>\n",
              "      <td>0.068521</td>\n",
              "      <td>0.067819</td>\n",
              "      <td>0.045568</td>\n",
              "      <td>0.042542</td>\n",
              "      <td>0.012362</td>\n",
              "      <td>0.037096</td>\n",
              "      <td>0.002464</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.038158</td>\n",
              "      <td>0.015061</td>\n",
              "      <td>0.014262</td>\n",
              "      <td>0.017962</td>\n",
              "      <td>0.007127</td>\n",
              "      <td>0.028855</td>\n",
              "      <td>0.025071</td>\n",
              "      <td>0.059971</td>\n",
              "      <td>0.004111</td>\n",
              "      <td>0.016097</td>\n",
              "      <td>-0.074565</td>\n",
              "      <td>0.027999</td>\n",
              "      <td>0.047501</td>\n",
              "      <td>0.014607</td>\n",
              "      <td>-0.028598</td>\n",
              "      <td>-0.034149</td>\n",
              "      <td>-0.064339</td>\n",
              "      <td>-0.002565</td>\n",
              "      <td>-0.056442</td>\n",
              "      <td>-0.000743</td>\n",
              "      <td>-0.026319</td>\n",
              "      <td>0.116664</td>\n",
              "      <td>0.173162</td>\n",
              "      <td>0.078059</td>\n",
              "      <td>0.039513</td>\n",
              "      <td>-0.010467</td>\n",
              "      <td>-0.025297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Chinese</th>\n",
              "      <td>-0.012840</td>\n",
              "      <td>-0.014745</td>\n",
              "      <td>-0.007617</td>\n",
              "      <td>-0.000660</td>\n",
              "      <td>-0.006766</td>\n",
              "      <td>-0.020450</td>\n",
              "      <td>-0.014939</td>\n",
              "      <td>0.073655</td>\n",
              "      <td>0.071444</td>\n",
              "      <td>0.043057</td>\n",
              "      <td>0.045970</td>\n",
              "      <td>0.021255</td>\n",
              "      <td>0.040950</td>\n",
              "      <td>0.003713</td>\n",
              "      <td>0.038158</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007524</td>\n",
              "      <td>0.010143</td>\n",
              "      <td>0.028586</td>\n",
              "      <td>0.021004</td>\n",
              "      <td>0.032553</td>\n",
              "      <td>0.045482</td>\n",
              "      <td>0.074387</td>\n",
              "      <td>0.018343</td>\n",
              "      <td>0.011702</td>\n",
              "      <td>-0.092873</td>\n",
              "      <td>0.021352</td>\n",
              "      <td>0.029808</td>\n",
              "      <td>0.009509</td>\n",
              "      <td>-0.037329</td>\n",
              "      <td>-0.049854</td>\n",
              "      <td>-0.078869</td>\n",
              "      <td>-0.004241</td>\n",
              "      <td>-0.080605</td>\n",
              "      <td>-0.021622</td>\n",
              "      <td>-0.048720</td>\n",
              "      <td>0.106115</td>\n",
              "      <td>0.189395</td>\n",
              "      <td>0.071722</td>\n",
              "      <td>0.033248</td>\n",
              "      <td>-0.005776</td>\n",
              "      <td>-0.028910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Desserts</th>\n",
              "      <td>-0.020678</td>\n",
              "      <td>-0.013502</td>\n",
              "      <td>-0.030035</td>\n",
              "      <td>-0.025462</td>\n",
              "      <td>-0.014771</td>\n",
              "      <td>-0.026734</td>\n",
              "      <td>-0.022278</td>\n",
              "      <td>0.042226</td>\n",
              "      <td>0.038678</td>\n",
              "      <td>0.025652</td>\n",
              "      <td>0.033984</td>\n",
              "      <td>0.023807</td>\n",
              "      <td>0.037508</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.015061</td>\n",
              "      <td>0.007524</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010363</td>\n",
              "      <td>0.014390</td>\n",
              "      <td>0.011883</td>\n",
              "      <td>0.023153</td>\n",
              "      <td>0.009643</td>\n",
              "      <td>0.028446</td>\n",
              "      <td>0.031545</td>\n",
              "      <td>0.006628</td>\n",
              "      <td>-0.070229</td>\n",
              "      <td>0.002119</td>\n",
              "      <td>0.014950</td>\n",
              "      <td>-0.013392</td>\n",
              "      <td>-0.038499</td>\n",
              "      <td>-0.039750</td>\n",
              "      <td>-0.047355</td>\n",
              "      <td>0.002856</td>\n",
              "      <td>-0.075052</td>\n",
              "      <td>-0.028531</td>\n",
              "      <td>-0.049974</td>\n",
              "      <td>0.034422</td>\n",
              "      <td>0.113834</td>\n",
              "      <td>0.051868</td>\n",
              "      <td>0.034559</td>\n",
              "      <td>0.014500</td>\n",
              "      <td>-0.045942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Healthy</th>\n",
              "      <td>-0.009510</td>\n",
              "      <td>-0.016770</td>\n",
              "      <td>-0.022447</td>\n",
              "      <td>-0.029278</td>\n",
              "      <td>-0.009122</td>\n",
              "      <td>-0.011719</td>\n",
              "      <td>-0.023250</td>\n",
              "      <td>0.039968</td>\n",
              "      <td>0.038424</td>\n",
              "      <td>0.037066</td>\n",
              "      <td>0.023113</td>\n",
              "      <td>0.016458</td>\n",
              "      <td>0.013354</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.014262</td>\n",
              "      <td>0.010143</td>\n",
              "      <td>0.010363</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010665</td>\n",
              "      <td>0.017604</td>\n",
              "      <td>0.018552</td>\n",
              "      <td>0.008778</td>\n",
              "      <td>0.024644</td>\n",
              "      <td>-0.000496</td>\n",
              "      <td>0.003271</td>\n",
              "      <td>-0.063150</td>\n",
              "      <td>0.025375</td>\n",
              "      <td>0.008207</td>\n",
              "      <td>-0.022495</td>\n",
              "      <td>-0.036976</td>\n",
              "      <td>-0.041040</td>\n",
              "      <td>-0.026871</td>\n",
              "      <td>-0.010762</td>\n",
              "      <td>-0.076371</td>\n",
              "      <td>-0.023637</td>\n",
              "      <td>-0.043395</td>\n",
              "      <td>0.033129</td>\n",
              "      <td>0.097381</td>\n",
              "      <td>0.043988</td>\n",
              "      <td>0.037996</td>\n",
              "      <td>0.015912</td>\n",
              "      <td>-0.042946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Indian</th>\n",
              "      <td>-0.021093</td>\n",
              "      <td>-0.022564</td>\n",
              "      <td>-0.012624</td>\n",
              "      <td>-0.014567</td>\n",
              "      <td>-0.013820</td>\n",
              "      <td>-0.006826</td>\n",
              "      <td>-0.016172</td>\n",
              "      <td>0.053582</td>\n",
              "      <td>0.052040</td>\n",
              "      <td>0.046649</td>\n",
              "      <td>0.049893</td>\n",
              "      <td>0.032392</td>\n",
              "      <td>0.027950</td>\n",
              "      <td>0.004777</td>\n",
              "      <td>0.017962</td>\n",
              "      <td>0.028586</td>\n",
              "      <td>0.014390</td>\n",
              "      <td>0.010665</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.040446</td>\n",
              "      <td>0.016559</td>\n",
              "      <td>0.023799</td>\n",
              "      <td>0.057851</td>\n",
              "      <td>0.019705</td>\n",
              "      <td>0.025443</td>\n",
              "      <td>-0.091053</td>\n",
              "      <td>0.002744</td>\n",
              "      <td>0.033242</td>\n",
              "      <td>0.006460</td>\n",
              "      <td>-0.030659</td>\n",
              "      <td>-0.037663</td>\n",
              "      <td>-0.106213</td>\n",
              "      <td>0.005715</td>\n",
              "      <td>-0.075448</td>\n",
              "      <td>-0.011355</td>\n",
              "      <td>-0.040390</td>\n",
              "      <td>0.102434</td>\n",
              "      <td>0.185433</td>\n",
              "      <td>0.080411</td>\n",
              "      <td>0.029767</td>\n",
              "      <td>0.010372</td>\n",
              "      <td>-0.034492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Italian</th>\n",
              "      <td>0.006957</td>\n",
              "      <td>0.007983</td>\n",
              "      <td>0.014201</td>\n",
              "      <td>-0.000934</td>\n",
              "      <td>-0.003563</td>\n",
              "      <td>-0.002263</td>\n",
              "      <td>-0.005741</td>\n",
              "      <td>0.051527</td>\n",
              "      <td>0.046542</td>\n",
              "      <td>0.100662</td>\n",
              "      <td>0.049653</td>\n",
              "      <td>0.020247</td>\n",
              "      <td>0.022779</td>\n",
              "      <td>0.047521</td>\n",
              "      <td>0.007127</td>\n",
              "      <td>0.021004</td>\n",
              "      <td>0.011883</td>\n",
              "      <td>0.017604</td>\n",
              "      <td>0.040446</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.026348</td>\n",
              "      <td>0.017226</td>\n",
              "      <td>0.028960</td>\n",
              "      <td>0.008926</td>\n",
              "      <td>0.011422</td>\n",
              "      <td>-0.074735</td>\n",
              "      <td>0.051014</td>\n",
              "      <td>0.064033</td>\n",
              "      <td>0.023730</td>\n",
              "      <td>-0.010916</td>\n",
              "      <td>-0.073522</td>\n",
              "      <td>-0.069623</td>\n",
              "      <td>-0.009614</td>\n",
              "      <td>-0.069048</td>\n",
              "      <td>0.038050</td>\n",
              "      <td>0.000771</td>\n",
              "      <td>0.133291</td>\n",
              "      <td>0.188213</td>\n",
              "      <td>0.121660</td>\n",
              "      <td>0.019594</td>\n",
              "      <td>-0.004616</td>\n",
              "      <td>-0.003151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Japanese</th>\n",
              "      <td>-0.032283</td>\n",
              "      <td>-0.029118</td>\n",
              "      <td>-0.019137</td>\n",
              "      <td>-0.026389</td>\n",
              "      <td>-0.015573</td>\n",
              "      <td>-0.011149</td>\n",
              "      <td>-0.019905</td>\n",
              "      <td>0.067097</td>\n",
              "      <td>0.063801</td>\n",
              "      <td>0.057946</td>\n",
              "      <td>0.044878</td>\n",
              "      <td>0.036830</td>\n",
              "      <td>0.044909</td>\n",
              "      <td>0.013547</td>\n",
              "      <td>0.028855</td>\n",
              "      <td>0.032553</td>\n",
              "      <td>0.023153</td>\n",
              "      <td>0.018552</td>\n",
              "      <td>0.016559</td>\n",
              "      <td>0.026348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.024674</td>\n",
              "      <td>0.044269</td>\n",
              "      <td>0.014532</td>\n",
              "      <td>0.028720</td>\n",
              "      <td>-0.088860</td>\n",
              "      <td>0.012773</td>\n",
              "      <td>0.035261</td>\n",
              "      <td>-0.018262</td>\n",
              "      <td>-0.052705</td>\n",
              "      <td>-0.061768</td>\n",
              "      <td>-0.058590</td>\n",
              "      <td>0.005911</td>\n",
              "      <td>-0.108646</td>\n",
              "      <td>-0.024791</td>\n",
              "      <td>-0.062809</td>\n",
              "      <td>0.081742</td>\n",
              "      <td>0.187344</td>\n",
              "      <td>0.099722</td>\n",
              "      <td>0.055034</td>\n",
              "      <td>0.027812</td>\n",
              "      <td>-0.059256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Noodle_Dishes</th>\n",
              "      <td>-0.020294</td>\n",
              "      <td>-0.014173</td>\n",
              "      <td>-0.030887</td>\n",
              "      <td>-0.014357</td>\n",
              "      <td>-0.009558</td>\n",
              "      <td>-0.019269</td>\n",
              "      <td>-0.018516</td>\n",
              "      <td>0.045779</td>\n",
              "      <td>0.045087</td>\n",
              "      <td>0.025661</td>\n",
              "      <td>0.039889</td>\n",
              "      <td>0.022214</td>\n",
              "      <td>0.038532</td>\n",
              "      <td>0.002304</td>\n",
              "      <td>0.025071</td>\n",
              "      <td>0.045482</td>\n",
              "      <td>0.009643</td>\n",
              "      <td>0.008778</td>\n",
              "      <td>0.023799</td>\n",
              "      <td>0.017226</td>\n",
              "      <td>0.024674</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.049150</td>\n",
              "      <td>0.014787</td>\n",
              "      <td>0.025630</td>\n",
              "      <td>-0.083204</td>\n",
              "      <td>0.013677</td>\n",
              "      <td>0.039217</td>\n",
              "      <td>-0.011507</td>\n",
              "      <td>-0.023583</td>\n",
              "      <td>-0.054367</td>\n",
              "      <td>-0.071455</td>\n",
              "      <td>-0.006460</td>\n",
              "      <td>-0.075103</td>\n",
              "      <td>-0.017732</td>\n",
              "      <td>-0.049222</td>\n",
              "      <td>0.091998</td>\n",
              "      <td>0.175486</td>\n",
              "      <td>0.072472</td>\n",
              "      <td>0.031145</td>\n",
              "      <td>0.014812</td>\n",
              "      <td>-0.043722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_OTHER</th>\n",
              "      <td>0.014130</td>\n",
              "      <td>0.022086</td>\n",
              "      <td>0.029338</td>\n",
              "      <td>0.008195</td>\n",
              "      <td>0.020205</td>\n",
              "      <td>0.018507</td>\n",
              "      <td>0.016055</td>\n",
              "      <td>0.111758</td>\n",
              "      <td>0.107312</td>\n",
              "      <td>0.078312</td>\n",
              "      <td>0.067226</td>\n",
              "      <td>0.017991</td>\n",
              "      <td>0.060692</td>\n",
              "      <td>0.023686</td>\n",
              "      <td>0.059971</td>\n",
              "      <td>0.074387</td>\n",
              "      <td>0.028446</td>\n",
              "      <td>0.024644</td>\n",
              "      <td>0.057851</td>\n",
              "      <td>0.028960</td>\n",
              "      <td>0.044269</td>\n",
              "      <td>0.049150</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000692</td>\n",
              "      <td>0.034475</td>\n",
              "      <td>-0.100366</td>\n",
              "      <td>0.039770</td>\n",
              "      <td>0.076726</td>\n",
              "      <td>0.034570</td>\n",
              "      <td>-0.021786</td>\n",
              "      <td>-0.040180</td>\n",
              "      <td>-0.090372</td>\n",
              "      <td>0.004447</td>\n",
              "      <td>-0.066252</td>\n",
              "      <td>0.019656</td>\n",
              "      <td>-0.022687</td>\n",
              "      <td>0.199450</td>\n",
              "      <td>0.271743</td>\n",
              "      <td>0.126142</td>\n",
              "      <td>0.060305</td>\n",
              "      <td>-0.019620</td>\n",
              "      <td>-0.014624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Street_Food/Snacks</th>\n",
              "      <td>-0.016510</td>\n",
              "      <td>-0.017793</td>\n",
              "      <td>-0.013291</td>\n",
              "      <td>-0.008626</td>\n",
              "      <td>-0.007211</td>\n",
              "      <td>-0.022651</td>\n",
              "      <td>-0.013440</td>\n",
              "      <td>0.055347</td>\n",
              "      <td>0.045112</td>\n",
              "      <td>0.021250</td>\n",
              "      <td>0.011723</td>\n",
              "      <td>0.030551</td>\n",
              "      <td>0.013640</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>0.004111</td>\n",
              "      <td>0.018343</td>\n",
              "      <td>0.031545</td>\n",
              "      <td>-0.000496</td>\n",
              "      <td>0.019705</td>\n",
              "      <td>0.008926</td>\n",
              "      <td>0.014532</td>\n",
              "      <td>0.014787</td>\n",
              "      <td>0.000692</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008138</td>\n",
              "      <td>-0.032380</td>\n",
              "      <td>0.001561</td>\n",
              "      <td>0.012194</td>\n",
              "      <td>-0.009778</td>\n",
              "      <td>-0.009926</td>\n",
              "      <td>-0.034443</td>\n",
              "      <td>-0.046950</td>\n",
              "      <td>-0.000392</td>\n",
              "      <td>-0.046854</td>\n",
              "      <td>0.032351</td>\n",
              "      <td>-0.026559</td>\n",
              "      <td>0.075274</td>\n",
              "      <td>0.133339</td>\n",
              "      <td>0.147282</td>\n",
              "      <td>0.018881</td>\n",
              "      <td>0.007585</td>\n",
              "      <td>-0.026195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUI_Thai</th>\n",
              "      <td>-0.011773</td>\n",
              "      <td>-0.010852</td>\n",
              "      <td>-0.016498</td>\n",
              "      <td>-0.015371</td>\n",
              "      <td>-0.007092</td>\n",
              "      <td>-0.011761</td>\n",
              "      <td>-0.012242</td>\n",
              "      <td>0.028161</td>\n",
              "      <td>0.027352</td>\n",
              "      <td>0.048223</td>\n",
              "      <td>0.030616</td>\n",
              "      <td>0.018244</td>\n",
              "      <td>0.023358</td>\n",
              "      <td>0.015465</td>\n",
              "      <td>0.016097</td>\n",
              "      <td>0.011702</td>\n",
              "      <td>0.006628</td>\n",
              "      <td>0.003271</td>\n",
              "      <td>0.025443</td>\n",
              "      <td>0.011422</td>\n",
              "      <td>0.028720</td>\n",
              "      <td>0.025630</td>\n",
              "      <td>0.034475</td>\n",
              "      <td>0.008138</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.048794</td>\n",
              "      <td>0.022438</td>\n",
              "      <td>0.034811</td>\n",
              "      <td>-0.011085</td>\n",
              "      <td>-0.030789</td>\n",
              "      <td>-0.041215</td>\n",
              "      <td>-0.058503</td>\n",
              "      <td>-0.009655</td>\n",
              "      <td>-0.063870</td>\n",
              "      <td>-0.011918</td>\n",
              "      <td>-0.030759</td>\n",
              "      <td>0.051600</td>\n",
              "      <td>0.113304</td>\n",
              "      <td>0.051293</td>\n",
              "      <td>0.015079</td>\n",
              "      <td>0.011523</td>\n",
              "      <td>-0.020498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_chain</th>\n",
              "      <td>0.380964</td>\n",
              "      <td>0.381061</td>\n",
              "      <td>0.384234</td>\n",
              "      <td>0.382928</td>\n",
              "      <td>0.364731</td>\n",
              "      <td>0.335270</td>\n",
              "      <td>0.347896</td>\n",
              "      <td>-0.086399</td>\n",
              "      <td>-0.124700</td>\n",
              "      <td>0.384554</td>\n",
              "      <td>-0.095541</td>\n",
              "      <td>-0.013505</td>\n",
              "      <td>-0.122599</td>\n",
              "      <td>-0.033732</td>\n",
              "      <td>-0.074565</td>\n",
              "      <td>-0.092873</td>\n",
              "      <td>-0.070229</td>\n",
              "      <td>-0.063150</td>\n",
              "      <td>-0.091053</td>\n",
              "      <td>-0.074735</td>\n",
              "      <td>-0.088860</td>\n",
              "      <td>-0.083204</td>\n",
              "      <td>-0.100366</td>\n",
              "      <td>-0.032380</td>\n",
              "      <td>-0.048794</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.068228</td>\n",
              "      <td>0.083559</td>\n",
              "      <td>0.373017</td>\n",
              "      <td>0.391147</td>\n",
              "      <td>0.367363</td>\n",
              "      <td>0.288315</td>\n",
              "      <td>0.004309</td>\n",
              "      <td>0.704662</td>\n",
              "      <td>0.675685</td>\n",
              "      <td>0.727238</td>\n",
              "      <td>0.359597</td>\n",
              "      <td>-0.355419</td>\n",
              "      <td>0.084938</td>\n",
              "      <td>-0.239551</td>\n",
              "      <td>-0.333840</td>\n",
              "      <td>0.601557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orders_Night</th>\n",
              "      <td>0.117614</td>\n",
              "      <td>0.092907</td>\n",
              "      <td>0.089564</td>\n",
              "      <td>0.078979</td>\n",
              "      <td>0.051334</td>\n",
              "      <td>0.072311</td>\n",
              "      <td>0.057427</td>\n",
              "      <td>0.036009</td>\n",
              "      <td>0.015206</td>\n",
              "      <td>0.013339</td>\n",
              "      <td>0.062320</td>\n",
              "      <td>0.124434</td>\n",
              "      <td>0.014400</td>\n",
              "      <td>0.035755</td>\n",
              "      <td>0.027999</td>\n",
              "      <td>0.021352</td>\n",
              "      <td>0.002119</td>\n",
              "      <td>0.025375</td>\n",
              "      <td>0.002744</td>\n",
              "      <td>0.051014</td>\n",
              "      <td>0.012773</td>\n",
              "      <td>0.013677</td>\n",
              "      <td>0.039770</td>\n",
              "      <td>0.001561</td>\n",
              "      <td>0.022438</td>\n",
              "      <td>0.068228</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.261559</td>\n",
              "      <td>0.019263</td>\n",
              "      <td>-0.114402</td>\n",
              "      <td>-0.261940</td>\n",
              "      <td>0.026949</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>0.186750</td>\n",
              "      <td>0.169706</td>\n",
              "      <td>0.156379</td>\n",
              "      <td>0.266130</td>\n",
              "      <td>0.206395</td>\n",
              "      <td>0.102970</td>\n",
              "      <td>-0.059586</td>\n",
              "      <td>-0.086558</td>\n",
              "      <td>0.127563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orders_Dawn</th>\n",
              "      <td>0.112148</td>\n",
              "      <td>0.101717</td>\n",
              "      <td>0.097099</td>\n",
              "      <td>0.087339</td>\n",
              "      <td>0.053484</td>\n",
              "      <td>0.079144</td>\n",
              "      <td>0.069818</td>\n",
              "      <td>0.043632</td>\n",
              "      <td>0.020149</td>\n",
              "      <td>0.001447</td>\n",
              "      <td>0.059124</td>\n",
              "      <td>0.084652</td>\n",
              "      <td>0.050755</td>\n",
              "      <td>0.026209</td>\n",
              "      <td>0.047501</td>\n",
              "      <td>0.029808</td>\n",
              "      <td>0.014950</td>\n",
              "      <td>0.008207</td>\n",
              "      <td>0.033242</td>\n",
              "      <td>0.064033</td>\n",
              "      <td>0.035261</td>\n",
              "      <td>0.039217</td>\n",
              "      <td>0.076726</td>\n",
              "      <td>0.012194</td>\n",
              "      <td>0.034811</td>\n",
              "      <td>0.083559</td>\n",
              "      <td>0.261559</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.104039</td>\n",
              "      <td>-0.097039</td>\n",
              "      <td>-0.289791</td>\n",
              "      <td>-0.086220</td>\n",
              "      <td>-0.002274</td>\n",
              "      <td>0.205403</td>\n",
              "      <td>0.168363</td>\n",
              "      <td>0.166701</td>\n",
              "      <td>0.310476</td>\n",
              "      <td>0.260687</td>\n",
              "      <td>0.074402</td>\n",
              "      <td>-0.073573</td>\n",
              "      <td>-0.104074</td>\n",
              "      <td>0.146064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orders_Morning</th>\n",
              "      <td>0.289692</td>\n",
              "      <td>0.271741</td>\n",
              "      <td>0.286622</td>\n",
              "      <td>0.273337</td>\n",
              "      <td>0.248499</td>\n",
              "      <td>0.224566</td>\n",
              "      <td>0.238807</td>\n",
              "      <td>0.050462</td>\n",
              "      <td>0.021244</td>\n",
              "      <td>0.254087</td>\n",
              "      <td>-0.004908</td>\n",
              "      <td>0.005080</td>\n",
              "      <td>-0.016675</td>\n",
              "      <td>-0.023953</td>\n",
              "      <td>0.014607</td>\n",
              "      <td>0.009509</td>\n",
              "      <td>-0.013392</td>\n",
              "      <td>-0.022495</td>\n",
              "      <td>0.006460</td>\n",
              "      <td>0.023730</td>\n",
              "      <td>-0.018262</td>\n",
              "      <td>-0.011507</td>\n",
              "      <td>0.034570</td>\n",
              "      <td>-0.009778</td>\n",
              "      <td>-0.011085</td>\n",
              "      <td>0.373017</td>\n",
              "      <td>0.019263</td>\n",
              "      <td>0.104039</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.111179</td>\n",
              "      <td>-0.042219</td>\n",
              "      <td>-0.002455</td>\n",
              "      <td>-0.001494</td>\n",
              "      <td>0.453062</td>\n",
              "      <td>0.455766</td>\n",
              "      <td>0.471672</td>\n",
              "      <td>0.409676</td>\n",
              "      <td>-0.010273</td>\n",
              "      <td>0.104077</td>\n",
              "      <td>-0.104287</td>\n",
              "      <td>-0.260038</td>\n",
              "      <td>0.388502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orders_Afternoon</th>\n",
              "      <td>0.270555</td>\n",
              "      <td>0.274315</td>\n",
              "      <td>0.278179</td>\n",
              "      <td>0.290232</td>\n",
              "      <td>0.274976</td>\n",
              "      <td>0.261760</td>\n",
              "      <td>0.300375</td>\n",
              "      <td>0.008237</td>\n",
              "      <td>-0.016595</td>\n",
              "      <td>0.335086</td>\n",
              "      <td>-0.037705</td>\n",
              "      <td>-0.024523</td>\n",
              "      <td>-0.063277</td>\n",
              "      <td>-0.019539</td>\n",
              "      <td>-0.028598</td>\n",
              "      <td>-0.037329</td>\n",
              "      <td>-0.038499</td>\n",
              "      <td>-0.036976</td>\n",
              "      <td>-0.030659</td>\n",
              "      <td>-0.010916</td>\n",
              "      <td>-0.052705</td>\n",
              "      <td>-0.023583</td>\n",
              "      <td>-0.021786</td>\n",
              "      <td>-0.009926</td>\n",
              "      <td>-0.030789</td>\n",
              "      <td>0.391147</td>\n",
              "      <td>-0.114402</td>\n",
              "      <td>-0.097039</td>\n",
              "      <td>0.111179</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.194082</td>\n",
              "      <td>0.100161</td>\n",
              "      <td>0.006926</td>\n",
              "      <td>0.441676</td>\n",
              "      <td>0.481191</td>\n",
              "      <td>0.502094</td>\n",
              "      <td>0.307815</td>\n",
              "      <td>-0.196626</td>\n",
              "      <td>0.092326</td>\n",
              "      <td>-0.124388</td>\n",
              "      <td>-0.269009</td>\n",
              "      <td>0.422268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orders_Evening</th>\n",
              "      <td>0.209825</td>\n",
              "      <td>0.222328</td>\n",
              "      <td>0.238674</td>\n",
              "      <td>0.260003</td>\n",
              "      <td>0.296619</td>\n",
              "      <td>0.264613</td>\n",
              "      <td>0.267745</td>\n",
              "      <td>-0.041549</td>\n",
              "      <td>-0.058072</td>\n",
              "      <td>0.360599</td>\n",
              "      <td>-0.063659</td>\n",
              "      <td>-0.078138</td>\n",
              "      <td>-0.055467</td>\n",
              "      <td>-0.047638</td>\n",
              "      <td>-0.034149</td>\n",
              "      <td>-0.049854</td>\n",
              "      <td>-0.039750</td>\n",
              "      <td>-0.041040</td>\n",
              "      <td>-0.037663</td>\n",
              "      <td>-0.073522</td>\n",
              "      <td>-0.061768</td>\n",
              "      <td>-0.054367</td>\n",
              "      <td>-0.040180</td>\n",
              "      <td>-0.034443</td>\n",
              "      <td>-0.041215</td>\n",
              "      <td>0.367363</td>\n",
              "      <td>-0.261940</td>\n",
              "      <td>-0.289791</td>\n",
              "      <td>-0.042219</td>\n",
              "      <td>0.194082</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.150858</td>\n",
              "      <td>0.001311</td>\n",
              "      <td>0.378383</td>\n",
              "      <td>0.422329</td>\n",
              "      <td>0.457202</td>\n",
              "      <td>0.174555</td>\n",
              "      <td>-0.334636</td>\n",
              "      <td>0.040564</td>\n",
              "      <td>-0.118235</td>\n",
              "      <td>-0.216990</td>\n",
              "      <td>0.385903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orders_Dusk</th>\n",
              "      <td>0.166647</td>\n",
              "      <td>0.172557</td>\n",
              "      <td>0.163488</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.166407</td>\n",
              "      <td>0.169846</td>\n",
              "      <td>0.163296</td>\n",
              "      <td>-0.022636</td>\n",
              "      <td>-0.031836</td>\n",
              "      <td>0.128033</td>\n",
              "      <td>-0.098646</td>\n",
              "      <td>-0.024145</td>\n",
              "      <td>-0.104413</td>\n",
              "      <td>-0.006549</td>\n",
              "      <td>-0.064339</td>\n",
              "      <td>-0.078869</td>\n",
              "      <td>-0.047355</td>\n",
              "      <td>-0.026871</td>\n",
              "      <td>-0.106213</td>\n",
              "      <td>-0.069623</td>\n",
              "      <td>-0.058590</td>\n",
              "      <td>-0.071455</td>\n",
              "      <td>-0.090372</td>\n",
              "      <td>-0.046950</td>\n",
              "      <td>-0.058503</td>\n",
              "      <td>0.288315</td>\n",
              "      <td>0.026949</td>\n",
              "      <td>-0.086220</td>\n",
              "      <td>-0.002455</td>\n",
              "      <td>0.100161</td>\n",
              "      <td>0.150858</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.001361</td>\n",
              "      <td>0.285205</td>\n",
              "      <td>0.257246</td>\n",
              "      <td>0.275351</td>\n",
              "      <td>0.045480</td>\n",
              "      <td>-0.287962</td>\n",
              "      <td>0.029254</td>\n",
              "      <td>-0.037365</td>\n",
              "      <td>-0.114656</td>\n",
              "      <td>0.218687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age_Group</th>\n",
              "      <td>0.014155</td>\n",
              "      <td>0.002188</td>\n",
              "      <td>0.002543</td>\n",
              "      <td>0.008337</td>\n",
              "      <td>-0.002040</td>\n",
              "      <td>-0.002210</td>\n",
              "      <td>0.003904</td>\n",
              "      <td>0.008029</td>\n",
              "      <td>0.006676</td>\n",
              "      <td>0.009922</td>\n",
              "      <td>0.009693</td>\n",
              "      <td>0.011969</td>\n",
              "      <td>-0.005341</td>\n",
              "      <td>-0.003634</td>\n",
              "      <td>-0.002565</td>\n",
              "      <td>-0.004241</td>\n",
              "      <td>0.002856</td>\n",
              "      <td>-0.010762</td>\n",
              "      <td>0.005715</td>\n",
              "      <td>-0.009614</td>\n",
              "      <td>0.005911</td>\n",
              "      <td>-0.006460</td>\n",
              "      <td>0.004447</td>\n",
              "      <td>-0.000392</td>\n",
              "      <td>-0.009655</td>\n",
              "      <td>0.004309</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>-0.002274</td>\n",
              "      <td>-0.001494</td>\n",
              "      <td>0.006926</td>\n",
              "      <td>0.001311</td>\n",
              "      <td>0.001361</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.003960</td>\n",
              "      <td>0.008210</td>\n",
              "      <td>0.008039</td>\n",
              "      <td>0.007902</td>\n",
              "      <td>0.002042</td>\n",
              "      <td>0.003364</td>\n",
              "      <td>-0.003050</td>\n",
              "      <td>-0.012532</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vendor_count</th>\n",
              "      <td>0.444394</td>\n",
              "      <td>0.441420</td>\n",
              "      <td>0.449241</td>\n",
              "      <td>0.450414</td>\n",
              "      <td>0.429584</td>\n",
              "      <td>0.409335</td>\n",
              "      <td>0.417778</td>\n",
              "      <td>-0.107176</td>\n",
              "      <td>-0.162246</td>\n",
              "      <td>0.238197</td>\n",
              "      <td>-0.111250</td>\n",
              "      <td>-0.025968</td>\n",
              "      <td>-0.115958</td>\n",
              "      <td>-0.050680</td>\n",
              "      <td>-0.056442</td>\n",
              "      <td>-0.080605</td>\n",
              "      <td>-0.075052</td>\n",
              "      <td>-0.076371</td>\n",
              "      <td>-0.075448</td>\n",
              "      <td>-0.069048</td>\n",
              "      <td>-0.108646</td>\n",
              "      <td>-0.075103</td>\n",
              "      <td>-0.066252</td>\n",
              "      <td>-0.046854</td>\n",
              "      <td>-0.063870</td>\n",
              "      <td>0.704662</td>\n",
              "      <td>0.186750</td>\n",
              "      <td>0.205403</td>\n",
              "      <td>0.453062</td>\n",
              "      <td>0.441676</td>\n",
              "      <td>0.378383</td>\n",
              "      <td>0.285205</td>\n",
              "      <td>0.003960</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.842378</td>\n",
              "      <td>0.886126</td>\n",
              "      <td>0.613952</td>\n",
              "      <td>-0.184805</td>\n",
              "      <td>0.178186</td>\n",
              "      <td>-0.367862</td>\n",
              "      <td>-0.442191</td>\n",
              "      <td>0.755993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product_count</th>\n",
              "      <td>0.467621</td>\n",
              "      <td>0.467889</td>\n",
              "      <td>0.486109</td>\n",
              "      <td>0.485919</td>\n",
              "      <td>0.470255</td>\n",
              "      <td>0.427865</td>\n",
              "      <td>0.445346</td>\n",
              "      <td>-0.043445</td>\n",
              "      <td>-0.101710</td>\n",
              "      <td>0.581853</td>\n",
              "      <td>0.005921</td>\n",
              "      <td>0.087398</td>\n",
              "      <td>-0.034609</td>\n",
              "      <td>-0.019424</td>\n",
              "      <td>-0.000743</td>\n",
              "      <td>-0.021622</td>\n",
              "      <td>-0.028531</td>\n",
              "      <td>-0.023637</td>\n",
              "      <td>-0.011355</td>\n",
              "      <td>0.038050</td>\n",
              "      <td>-0.024791</td>\n",
              "      <td>-0.017732</td>\n",
              "      <td>0.019656</td>\n",
              "      <td>0.032351</td>\n",
              "      <td>-0.011918</td>\n",
              "      <td>0.675685</td>\n",
              "      <td>0.169706</td>\n",
              "      <td>0.168363</td>\n",
              "      <td>0.455766</td>\n",
              "      <td>0.481191</td>\n",
              "      <td>0.422329</td>\n",
              "      <td>0.257246</td>\n",
              "      <td>0.008210</td>\n",
              "      <td>0.842378</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.946879</td>\n",
              "      <td>0.795042</td>\n",
              "      <td>-0.033330</td>\n",
              "      <td>0.465396</td>\n",
              "      <td>-0.339693</td>\n",
              "      <td>-0.468386</td>\n",
              "      <td>0.784038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_Orders_Per_Client</th>\n",
              "      <td>0.487078</td>\n",
              "      <td>0.488111</td>\n",
              "      <td>0.505805</td>\n",
              "      <td>0.506955</td>\n",
              "      <td>0.489599</td>\n",
              "      <td>0.441399</td>\n",
              "      <td>0.457593</td>\n",
              "      <td>-0.106557</td>\n",
              "      <td>-0.165023</td>\n",
              "      <td>0.616230</td>\n",
              "      <td>-0.044018</td>\n",
              "      <td>0.026927</td>\n",
              "      <td>-0.066371</td>\n",
              "      <td>-0.030914</td>\n",
              "      <td>-0.026319</td>\n",
              "      <td>-0.048720</td>\n",
              "      <td>-0.049974</td>\n",
              "      <td>-0.043395</td>\n",
              "      <td>-0.040390</td>\n",
              "      <td>0.000771</td>\n",
              "      <td>-0.062809</td>\n",
              "      <td>-0.049222</td>\n",
              "      <td>-0.022687</td>\n",
              "      <td>-0.026559</td>\n",
              "      <td>-0.030759</td>\n",
              "      <td>0.727238</td>\n",
              "      <td>0.156379</td>\n",
              "      <td>0.166701</td>\n",
              "      <td>0.471672</td>\n",
              "      <td>0.502094</td>\n",
              "      <td>0.457202</td>\n",
              "      <td>0.275351</td>\n",
              "      <td>0.008039</td>\n",
              "      <td>0.886126</td>\n",
              "      <td>0.946879</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.682539</td>\n",
              "      <td>-0.218448</td>\n",
              "      <td>0.181313</td>\n",
              "      <td>-0.386786</td>\n",
              "      <td>-0.491767</td>\n",
              "      <td>0.832197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mnt</th>\n",
              "      <td>0.367186</td>\n",
              "      <td>0.361109</td>\n",
              "      <td>0.377148</td>\n",
              "      <td>0.372713</td>\n",
              "      <td>0.359802</td>\n",
              "      <td>0.328541</td>\n",
              "      <td>0.332949</td>\n",
              "      <td>0.119324</td>\n",
              "      <td>0.069739</td>\n",
              "      <td>0.418518</td>\n",
              "      <td>0.151092</td>\n",
              "      <td>0.134996</td>\n",
              "      <td>0.103059</td>\n",
              "      <td>0.006832</td>\n",
              "      <td>0.116664</td>\n",
              "      <td>0.106115</td>\n",
              "      <td>0.034422</td>\n",
              "      <td>0.033129</td>\n",
              "      <td>0.102434</td>\n",
              "      <td>0.133291</td>\n",
              "      <td>0.081742</td>\n",
              "      <td>0.091998</td>\n",
              "      <td>0.199450</td>\n",
              "      <td>0.075274</td>\n",
              "      <td>0.051600</td>\n",
              "      <td>0.359597</td>\n",
              "      <td>0.266130</td>\n",
              "      <td>0.310476</td>\n",
              "      <td>0.409676</td>\n",
              "      <td>0.307815</td>\n",
              "      <td>0.174555</td>\n",
              "      <td>0.045480</td>\n",
              "      <td>0.007902</td>\n",
              "      <td>0.613952</td>\n",
              "      <td>0.795042</td>\n",
              "      <td>0.682539</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.512704</td>\n",
              "      <td>0.565664</td>\n",
              "      <td>-0.197222</td>\n",
              "      <td>-0.378727</td>\n",
              "      <td>0.566966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mnt_Per_Order</th>\n",
              "      <td>-0.095872</td>\n",
              "      <td>-0.106459</td>\n",
              "      <td>-0.101740</td>\n",
              "      <td>-0.113150</td>\n",
              "      <td>-0.107482</td>\n",
              "      <td>-0.091810</td>\n",
              "      <td>-0.102645</td>\n",
              "      <td>0.223013</td>\n",
              "      <td>0.214071</td>\n",
              "      <td>-0.158522</td>\n",
              "      <td>0.259137</td>\n",
              "      <td>0.173878</td>\n",
              "      <td>0.217276</td>\n",
              "      <td>0.052662</td>\n",
              "      <td>0.173162</td>\n",
              "      <td>0.189395</td>\n",
              "      <td>0.113834</td>\n",
              "      <td>0.097381</td>\n",
              "      <td>0.185433</td>\n",
              "      <td>0.188213</td>\n",
              "      <td>0.187344</td>\n",
              "      <td>0.175486</td>\n",
              "      <td>0.271743</td>\n",
              "      <td>0.133339</td>\n",
              "      <td>0.113304</td>\n",
              "      <td>-0.355419</td>\n",
              "      <td>0.206395</td>\n",
              "      <td>0.260687</td>\n",
              "      <td>-0.010273</td>\n",
              "      <td>-0.196626</td>\n",
              "      <td>-0.334636</td>\n",
              "      <td>-0.287962</td>\n",
              "      <td>0.002042</td>\n",
              "      <td>-0.184805</td>\n",
              "      <td>-0.033330</td>\n",
              "      <td>-0.218448</td>\n",
              "      <td>0.512704</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.521619</td>\n",
              "      <td>0.110296</td>\n",
              "      <td>0.063692</td>\n",
              "      <td>-0.186461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Items_Per_Order</th>\n",
              "      <td>0.090421</td>\n",
              "      <td>0.090598</td>\n",
              "      <td>0.099674</td>\n",
              "      <td>0.095464</td>\n",
              "      <td>0.095874</td>\n",
              "      <td>0.099923</td>\n",
              "      <td>0.110594</td>\n",
              "      <td>0.125428</td>\n",
              "      <td>0.102301</td>\n",
              "      <td>0.084251</td>\n",
              "      <td>0.139976</td>\n",
              "      <td>0.198714</td>\n",
              "      <td>0.074321</td>\n",
              "      <td>0.025960</td>\n",
              "      <td>0.078059</td>\n",
              "      <td>0.071722</td>\n",
              "      <td>0.051868</td>\n",
              "      <td>0.043988</td>\n",
              "      <td>0.080411</td>\n",
              "      <td>0.121660</td>\n",
              "      <td>0.099722</td>\n",
              "      <td>0.072472</td>\n",
              "      <td>0.126142</td>\n",
              "      <td>0.147282</td>\n",
              "      <td>0.051293</td>\n",
              "      <td>0.084938</td>\n",
              "      <td>0.102970</td>\n",
              "      <td>0.074402</td>\n",
              "      <td>0.104077</td>\n",
              "      <td>0.092326</td>\n",
              "      <td>0.040564</td>\n",
              "      <td>0.029254</td>\n",
              "      <td>0.003364</td>\n",
              "      <td>0.178186</td>\n",
              "      <td>0.465396</td>\n",
              "      <td>0.181313</td>\n",
              "      <td>0.565664</td>\n",
              "      <td>0.521619</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.019855</td>\n",
              "      <td>-0.092306</td>\n",
              "      <td>0.140074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>frq</th>\n",
              "      <td>-0.078086</td>\n",
              "      <td>-0.072986</td>\n",
              "      <td>-0.087117</td>\n",
              "      <td>-0.088083</td>\n",
              "      <td>-0.091739</td>\n",
              "      <td>-0.076712</td>\n",
              "      <td>-0.103022</td>\n",
              "      <td>0.574515</td>\n",
              "      <td>0.620062</td>\n",
              "      <td>-0.171074</td>\n",
              "      <td>0.074937</td>\n",
              "      <td>0.027655</td>\n",
              "      <td>0.056381</td>\n",
              "      <td>0.022728</td>\n",
              "      <td>0.039513</td>\n",
              "      <td>0.033248</td>\n",
              "      <td>0.034559</td>\n",
              "      <td>0.037996</td>\n",
              "      <td>0.029767</td>\n",
              "      <td>0.019594</td>\n",
              "      <td>0.055034</td>\n",
              "      <td>0.031145</td>\n",
              "      <td>0.060305</td>\n",
              "      <td>0.018881</td>\n",
              "      <td>0.015079</td>\n",
              "      <td>-0.239551</td>\n",
              "      <td>-0.059586</td>\n",
              "      <td>-0.073573</td>\n",
              "      <td>-0.104287</td>\n",
              "      <td>-0.124388</td>\n",
              "      <td>-0.118235</td>\n",
              "      <td>-0.037365</td>\n",
              "      <td>-0.003050</td>\n",
              "      <td>-0.367862</td>\n",
              "      <td>-0.339693</td>\n",
              "      <td>-0.386786</td>\n",
              "      <td>-0.197222</td>\n",
              "      <td>0.110296</td>\n",
              "      <td>-0.019855</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.337825</td>\n",
              "      <td>-0.718351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rcn</th>\n",
              "      <td>-0.241139</td>\n",
              "      <td>-0.251493</td>\n",
              "      <td>-0.273226</td>\n",
              "      <td>-0.299676</td>\n",
              "      <td>-0.302244</td>\n",
              "      <td>-0.206894</td>\n",
              "      <td>-0.220279</td>\n",
              "      <td>-0.406842</td>\n",
              "      <td>-0.364907</td>\n",
              "      <td>-0.305183</td>\n",
              "      <td>-0.001536</td>\n",
              "      <td>-0.014886</td>\n",
              "      <td>0.010748</td>\n",
              "      <td>0.010790</td>\n",
              "      <td>-0.010467</td>\n",
              "      <td>-0.005776</td>\n",
              "      <td>0.014500</td>\n",
              "      <td>0.015912</td>\n",
              "      <td>0.010372</td>\n",
              "      <td>-0.004616</td>\n",
              "      <td>0.027812</td>\n",
              "      <td>0.014812</td>\n",
              "      <td>-0.019620</td>\n",
              "      <td>0.007585</td>\n",
              "      <td>0.011523</td>\n",
              "      <td>-0.333840</td>\n",
              "      <td>-0.086558</td>\n",
              "      <td>-0.104074</td>\n",
              "      <td>-0.260038</td>\n",
              "      <td>-0.269009</td>\n",
              "      <td>-0.216990</td>\n",
              "      <td>-0.114656</td>\n",
              "      <td>-0.012532</td>\n",
              "      <td>-0.442191</td>\n",
              "      <td>-0.468386</td>\n",
              "      <td>-0.491767</td>\n",
              "      <td>-0.378727</td>\n",
              "      <td>0.063692</td>\n",
              "      <td>-0.092306</td>\n",
              "      <td>0.337825</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.590171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>activity</th>\n",
              "      <td>0.398360</td>\n",
              "      <td>0.397150</td>\n",
              "      <td>0.417149</td>\n",
              "      <td>0.421766</td>\n",
              "      <td>0.404916</td>\n",
              "      <td>0.356761</td>\n",
              "      <td>0.386163</td>\n",
              "      <td>-0.183989</td>\n",
              "      <td>-0.247917</td>\n",
              "      <td>0.495155</td>\n",
              "      <td>-0.047178</td>\n",
              "      <td>0.009899</td>\n",
              "      <td>-0.061953</td>\n",
              "      <td>-0.025276</td>\n",
              "      <td>-0.025297</td>\n",
              "      <td>-0.028910</td>\n",
              "      <td>-0.045942</td>\n",
              "      <td>-0.042946</td>\n",
              "      <td>-0.034492</td>\n",
              "      <td>-0.003151</td>\n",
              "      <td>-0.059256</td>\n",
              "      <td>-0.043722</td>\n",
              "      <td>-0.014624</td>\n",
              "      <td>-0.026195</td>\n",
              "      <td>-0.020498</td>\n",
              "      <td>0.601557</td>\n",
              "      <td>0.127563</td>\n",
              "      <td>0.146064</td>\n",
              "      <td>0.388502</td>\n",
              "      <td>0.422268</td>\n",
              "      <td>0.385903</td>\n",
              "      <td>0.218687</td>\n",
              "      <td>0.006400</td>\n",
              "      <td>0.755993</td>\n",
              "      <td>0.784038</td>\n",
              "      <td>0.832197</td>\n",
              "      <td>0.566966</td>\n",
              "      <td>-0.186461</td>\n",
              "      <td>0.140074</td>\n",
              "      <td>-0.718351</td>\n",
              "      <td>-0.590171</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1da074db-c7f5-4ad8-99b8-4a234817cba7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1da074db-c7f5-4ad8-99b8-4a234817cba7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1da074db-c7f5-4ad8-99b8-4a234817cba7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a39ec97-350d-4234-a76f-8e82b779a5c4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a39ec97-350d-4234-a76f-8e82b779a5c4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a39ec97-350d-4234-a76f-8e82b779a5c4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5c7c7b85-f8f4-40bc-a09d-242f81a78ef8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('spearman_corr')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5c7c7b85-f8f4-40bc-a09d-242f81a78ef8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('spearman_corr');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "spearman_corr"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlation matrix\n",
        "corr_matrix = num_df.corr(method='spearman')\n",
        "\n",
        "# Get correlations above 0.5 (excluding self-correlations)\n",
        "strong_corrs = [(i, j, corr_matrix.loc[i, j])\n",
        "                for i in corr_matrix.index\n",
        "                for j in corr_matrix.columns\n",
        "                if abs(corr_matrix.loc[i, j]) > 0.7 and i < j]\n",
        "\n",
        "# Print sorted results\n",
        "print(\"Correlations above 0.5:\")\n",
        "for var1, var2, corr in sorted(strong_corrs, key=lambda x: abs(x[2]), reverse=True):\n",
        "    print(f\"{var1} - {var2}: {corr:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR2YIa8uY7nF",
        "outputId": "dde55032-7ec3-467f-deda-a06b82dfef66"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlations above 0.5:\n",
            "CLV_Score - RFM_Score: 0.989\n",
            "Total_Orders_Per_Client - product_count: 0.947\n",
            "Total_Orders_Per_Client - vendor_count: 0.886\n",
            "product_count - vendor_count: 0.842\n",
            "Total_Orders_Per_Client - activity: 0.832\n",
            "mnt - product_count: 0.795\n",
            "activity - product_count: 0.784\n",
            "activity - vendor_count: 0.756\n",
            "Total_Orders_Per_Client - is_chain: 0.727\n",
            "activity - frq: -0.718\n",
            "is_chain - vendor_count: 0.705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJzWANaLZipw",
        "outputId": "17e9faca-f7b5-4f53-ea04-e26b9842c9d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DOW_0', 'DOW_1', 'DOW_2', 'DOW_3', 'DOW_4', 'DOW_5', 'DOW_6',\n",
              "       'CLV_Score', 'RFM_Score', 'Loyalty', 'CUI_American', 'CUI_Asian',\n",
              "       'CUI_Beverages', 'CUI_Cafe', 'CUI_Chicken_Dishes', 'CUI_Chinese',\n",
              "       'CUI_Desserts', 'CUI_Healthy', 'CUI_Indian', 'CUI_Italian',\n",
              "       'CUI_Japanese', 'CUI_Noodle_Dishes', 'CUI_OTHER',\n",
              "       'CUI_Street_Food/Snacks', 'CUI_Thai', 'is_chain', 'Orders_Night',\n",
              "       'Orders_Dawn', 'Orders_Morning', 'Orders_Afternoon', 'Orders_Evening',\n",
              "       'Orders_Dusk', 'Age_Group', 'vendor_count', 'product_count',\n",
              "       'Total_Orders_Per_Client', 'mnt', 'mnt_Per_Order', 'Items_Per_Order',\n",
              "       'frq', 'rcn', 'activity'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value_engagement_metrics = [\n",
        "    # Value\n",
        "    'mnt', 'mnt_Per_Order', 'CLV_Score', 'RFM_Score',\n",
        "    # Engagement\n",
        "    'activity', 'Loyalty', 'frq', 'rcn' , 'Age_Group']\n",
        "\n",
        "preference_metrics = [\n",
        "    # Cuisine preferences\n",
        "    'CUI_American', 'CUI_Asian', 'CUI_Beverages', 'CUI_Cafe',\n",
        "    'CUI_Chicken_Dishes', 'CUI_Chinese', 'CUI_Desserts', 'CUI_Healthy',\n",
        "    'CUI_Indian', 'CUI_Italian', 'CUI_Japanese', 'CUI_Noodle_Dishes',\n",
        "    'CUI_OTHER', 'CUI_Street_Food/Snacks', 'CUI_Thai'\n",
        "]\n",
        "\n",
        "shopping_behavior_metrics = [\n",
        "    # Shopping patterns\n",
        "    'vendor_count', 'product_count', 'is_chain', 'Items_Per_Order',\n",
        "    # Timing preferences\n",
        "    'Orders_Night', 'Orders_Dawn', 'Orders_Morning', 'Orders_Afternoon',\n",
        "    'Orders_Evening', 'Orders_Dusk',\n",
        "    'DOW_0', 'DOW_1', 'DOW_2', 'DOW_3', 'DOW_4', 'DOW_5', 'DOW_6'\n",
        "]\n",
        "\n",
        "demographic_metrics = [\n",
        "    'customer_region_0', 'customer_region_1', 'customer_region_2',\n",
        "    'customer_region_3'\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "emBgdw5VZ2VX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = num_df[value_engagement_metrics].copy()\n",
        "df_pref = num_df[preference_metrics].copy()\n",
        "df_shop = num_df[shopping_behavior_metrics].copy()\n"
      ],
      "metadata": {
        "id": "s_6IUQ51Z_KU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "time to reduce feature amount to label data better"
      ],
      "metadata": {
        "id": "r4b54A52ab4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of columns in df_pref: {df_pref.shape[1]}\")\n",
        "print(f\"Number of columns in df_shop: {df_shop.shape[1]}\")\n",
        "print(f\"Number of columns in df_val: {df_val.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztPKugQmaNWG",
        "outputId": "c178736f-2b66-44a3-a64b-8e6b4e7ace18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns in df_pref: 15\n",
            "Number of columns in df_shop: 17\n",
            "Number of columns in df_val: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balancing the Cuisine groupings to not have a majority customer group dominate the cluster"
      ],
      "metadata": {
        "id": "Qr9t8lc9-y4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuisine_groups = {\n",
        "    'Other_Asian': ['CUI_Chinese', 'CUI_Japanese', 'CUI_Noodle_Dishes','CUI_Thai', 'CUI_Indian'],\n",
        "    'General_Asian' : ['CUI_Asian'],\n",
        "    'Western': ['CUI_American', 'CUI_Italian'],\n",
        "    'Beverages_Cafe': ['CUI_Beverages', 'CUI_Cafe'],\n",
        "    'Desserts_Snacks': ['CUI_Desserts', 'CUI_Street_Food/Snacks'],\n",
        "    'Main_Dishes': ['CUI_Chicken_Dishes', 'CUI_Healthy', 'CUI_OTHER']\n",
        "}\n",
        "\n",
        "# Calculate group totals and percentages\n",
        "group_totals = {}\n",
        "total_sum = 0\n",
        "\n",
        "for group, cuisines in cuisine_groups.items():\n",
        "    group_sum = num_df[cuisines].sum().sum()\n",
        "    group_totals[group] = group_sum\n",
        "    total_sum += group_sum\n",
        "\n",
        "# Print results\n",
        "print(\"Group Totals and Percentages:\")\n",
        "for group, total in group_totals.items():\n",
        "    percentage = (total / total_sum) * 100\n",
        "    print(f\"{group:15s}: {total:8.0f} ({percentage:5.1f}%)\")\n",
        "\n",
        "print(f\"\\nTotal Sum:      {total_sum:8.0f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaebgvj7abNw",
        "outputId": "a083a13d-fa18-4eab-bf2c-46285476a7da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group Totals and Percentages:\n",
            "Other_Asian    :        0 ( 70.9%)\n",
            "General_Asian  :       -0 (-61.3%)\n",
            "Western        :        0 ( 35.8%)\n",
            "Beverages_Cafe :        0 ( 29.7%)\n",
            "Desserts_Snacks:       -0 (-24.9%)\n",
            "Main_Dishes    :        0 ( 49.8%)\n",
            "\n",
            "Total Sum:             0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create copy\n",
        "pref_clean = df_pref.copy()\n",
        "\n",
        "# Initialize new columns for each group\n",
        "group_columns = {\n",
        "    'Other_Asian': ['CUI_Chinese', 'CUI_Japanese', 'CUI_Noodle_Dishes', 'CUI_Thai', 'CUI_Indian'],\n",
        "    'General_Asian': ['CUI_Asian'],\n",
        "    'Western': ['CUI_American', 'CUI_Italian'],\n",
        "    'Beverages_Cafe': ['CUI_Beverages', 'CUI_Cafe'],\n",
        "    'Desserts_Snacks': ['CUI_Desserts', 'CUI_Street_Food/Snacks'],\n",
        "    'Main_Dishes': ['CUI_Chicken_Dishes', 'CUI_Healthy', 'CUI_OTHER']\n",
        "}\n",
        "\n",
        "# Create grouped columns\n",
        "for group, cuisines in group_columns.items():\n",
        "    pref_clean[group] = df_pref[cuisines].sum(axis=1)\n",
        "\n",
        "# Keep only the new grouped columns\n",
        "pref_clean = pref_clean[list(group_columns.keys())]"
      ],
      "metadata": {
        "id": "kIlbcn6WcWFK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loop to decide the ideal elbow point for this segment"
      ],
      "metadata": {
        "id": "FEW6Cf-PEerD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure pref_clean is a NumPy array\n",
        "pref_clean_array = pref_clean.values if isinstance(pref_clean, pd.DataFrame) else pref_clean\n",
        "\n",
        "# Clustering metrics (maintaining for scientific completeness and comparison)\n",
        "metrics = []\n",
        "for k in range(3, 11):\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "    labels = kmeans.fit_predict(pref_clean_array)\n",
        "\n",
        "    # Calculate SSE\n",
        "    sse = np.sum((pref_clean_array - kmeans.cluster_centers_[labels]) ** 2)\n",
        "\n",
        "    # Calculate R2\n",
        "    r2 = r2_score(pref_clean_array, kmeans.cluster_centers_[labels])\n",
        "\n",
        "    metrics.append({\n",
        "        'k': k,\n",
        "        'silhouette': silhouette_score(pref_clean_array, labels),\n",
        "        'calinski': calinski_harabasz_score(pref_clean_array, labels),\n",
        "        'davies': davies_bouldin_score(pref_clean_array, labels),\n",
        "        'inertia': kmeans.inertia_,\n",
        "        'sse': sse,\n",
        "        'r2': r2\n",
        "    })\n",
        "\n",
        "# Print metrics for comprehensive analysis\n",
        "for m in metrics:\n",
        "    print(f\"\\nk={m['k']}:\")\n",
        "    print(f\"Silhouette: {m['silhouette']:.3f}\")\n",
        "    print(f\"Calinski-Harabasz: {m['calinski']:.2f}\")\n",
        "    print(f\"Davies-Bouldin: {m['davies']:.2f}\")\n",
        "    print(f\"SSE: {m['sse']:.2f}\")\n",
        "    print(f\"R2: {m['r2']:.3f}\")\n",
        "    print(f\"Inertia: {m['inertia']:.2f}\")\n",
        "\n",
        "# Force k=7 for final clustering\n",
        "kmeans_final = KMeans(n_clusters=7, init='k-means++', random_state=42)\n",
        "labels = kmeans_final.fit_predict(pref_clean_array)\n",
        "\n",
        "# Update DataFrame with cluster labels\n",
        "pref_clean['cluster'] = labels\n",
        "\n",
        "# T-SNE embedding for dimensionality reduction and visualization\n",
        "tsne = TSNE(random_state=42)\n",
        "embedding = tsne.fit_transform(pref_clean_array)\n",
        "\n",
        "# Plotting with enhanced scientific visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# T-SNE plot with specified colormap for optimal cluster distinction\n",
        "scatter = ax1.scatter(embedding[:, 0], embedding[:, 1], c=labels, cmap='viridis')\n",
        "ax1.set_title('T-SNE visualization of 7 clusters')\n",
        "plt.colorbar(scatter, ax=ax1)\n",
        "\n",
        "# Elbow plot for comparative analysis\n",
        "ax2.plot(range(3, 11), [m['inertia'] for m in metrics], 'bo-')\n",
        "ax2.set_xlabel('Number of clusters (k)')\n",
        "ax2.set_ylabel('Inertia')\n",
        "ax2.set_title('Elbow Method')\n",
        "ax2.axvline(x=7, color='r', linestyle='--', label='Selected k=7')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the updated DataFrame with cluster labels\n",
        "print(pref_clean.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3DcFBrdM_8Ze",
        "outputId": "990f19b2-a265-476a-edca-ba52b66d2333"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "k=3:\n",
            "Silhouette: 0.656\n",
            "Calinski-Harabasz: 5050.29\n",
            "Davies-Bouldin: 1.06\n",
            "SSE: 59332.92\n",
            "R2: 0.163\n",
            "Inertia: 59332.92\n",
            "\n",
            "k=4:\n",
            "Silhouette: 0.620\n",
            "Calinski-Harabasz: 4880.55\n",
            "Davies-Bouldin: 1.04\n",
            "SSE: 53522.54\n",
            "R2: 0.248\n",
            "Inertia: 53522.54\n",
            "\n",
            "k=5:\n",
            "Silhouette: 0.622\n",
            "Calinski-Harabasz: 4979.43\n",
            "Davies-Bouldin: 0.96\n",
            "SSE: 48054.69\n",
            "R2: 0.318\n",
            "Inertia: 48054.69\n",
            "\n",
            "k=6:\n",
            "Silhouette: 0.621\n",
            "Calinski-Harabasz: 4703.98\n",
            "Davies-Bouldin: 0.91\n",
            "SSE: 44921.12\n",
            "R2: 0.398\n",
            "Inertia: 44921.12\n",
            "\n",
            "k=7:\n",
            "Silhouette: 0.617\n",
            "Calinski-Harabasz: 4746.14\n",
            "Davies-Bouldin: 0.87\n",
            "SSE: 41222.15\n",
            "R2: 0.427\n",
            "Inertia: 41222.15\n",
            "\n",
            "k=8:\n",
            "Silhouette: 0.178\n",
            "Calinski-Harabasz: 4792.61\n",
            "Davies-Bouldin: 1.09\n",
            "SSE: 38019.00\n",
            "R2: 0.456\n",
            "Inertia: 38019.00\n",
            "\n",
            "k=9:\n",
            "Silhouette: 0.209\n",
            "Calinski-Harabasz: 4758.17\n",
            "Davies-Bouldin: 1.06\n",
            "SSE: 35558.27\n",
            "R2: 0.478\n",
            "Inertia: 35558.27\n",
            "\n",
            "k=10:\n",
            "Silhouette: 0.228\n",
            "Calinski-Harabasz: 4622.81\n",
            "Davies-Bouldin: 1.10\n",
            "SSE: 33840.84\n",
            "R2: 0.512\n",
            "Inertia: 33840.84\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-08844b755d77>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# T-SNE embedding for dimensionality reduction and visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpref_clean_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Plotting with enhanced scientific visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m         return self._tsne(\n\u001b[0m\u001b[1;32m   1047\u001b[0m             \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_iter_without_progress\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_without_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;31m# Save the final number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, max_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compute_error\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     error = _barnes_hut_tsne.gradient(\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mval_P\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_shop.describe()"
      ],
      "metadata": {
        "id": "9zBw2ssskjlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MinMax scaling with custom ranges to score new features\n",
        "\n",
        "\"\"\"Items_Per_Order (1-2.25):\n",
        "\n",
        "Min 1: Single item is baseline order\n",
        "Max 2.25: Very few customers order >2 items\n",
        "\n",
        "product_count (1-14):\n",
        "\n",
        "Min 1: Customers try at least one product\n",
        "Max 14: Represents power users with wide product exploration\n",
        "Aligns with 75th percentile around 7 products\n",
        "\n",
        "vendor_count (1-8):\n",
        "\n",
        "Min 1: Single vendor loyalty\n",
        "Max 8: Reflects realistic maximum vendor relationships\n",
        "Most customers use 1-3 vendors (75th percentile at 4)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WdBTsLgj6WQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â€¢ Replaced log transform with MinMaxScaler for time periods to maintain relative differences on 0-1 scale\n",
        "\n",
        "â€¢ Normalized DOW cyclic features to match 0-1 scale of other features\n",
        "\n",
        "â€¢ Kept is_chain to preserve business context\n",
        "\n",
        "â€¢ Added chain interactions with basket/vendor scores to\n",
        "capture business patterns\n",
        "\n",
        "â€¢ Unified all features to same scale range to prevent distance calculation skew\n",
        "\n"
      ],
      "metadata": {
        "id": "9PdETxCl9f9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AANPASSEN MET HOE HET IS MAAR MOET COHERENT MAKEN MET DE HUIDIGE SCHALING AAAAAAAAAAAAAAAAAAA"
      ],
      "metadata": {
        "id": "u7V3fPaQJ7tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create copy and calculate scores\n",
        "editdf = df.copy()\n",
        "editdf['basket_score'] = (editdf['Items_Per_Order'] - 1) / (2.25 - 1)\n",
        "editdf['product_score'] = (editdf['product_count'] - 1) / (14 - 1)\n",
        "editdf['vendor_score'] = (editdf['vendor_count'] - 1) / (8 - 1)\n",
        "\n",
        "# Group into periods, no scaling\n",
        "editdf['daytime_orders'] = editdf['Orders_Morning'] + editdf['Orders_Afternoon']\n",
        "editdf['evening_orders'] = editdf['Orders_Evening'] + editdf['Orders_Dusk']\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\"Standard numerical encoding (e.g., Monday = 0, Tuesday = 1, ..., Sunday = 6)\n",
        "fails to account for the cyclic relationship of the data.\n",
        "In numerical encoding, Sunday (6) is treated as far from Monday (0),\n",
        " which is incorrect for many analyses, such as machine learning tasks where distance or similarity matters.\"\"\"\n",
        "\n",
        "# DOW cyclic encoding\n",
        "dow_value = (editdf[['DOW_0', 'DOW_1', 'DOW_2', 'DOW_3', 'DOW_4', 'DOW_5', 'DOW_6']] *\n",
        "            np.array([0, 1, 2, 3, 4, 5, 6])).sum(axis=1) / \\\n",
        "            editdf[['DOW_0', 'DOW_1', 'DOW_2', 'DOW_3', 'DOW_4', 'DOW_5', 'DOW_6']].sum(axis=1)\n",
        "\n",
        "editdf['DOW_sin'] = np.sin(2 * np.pi * dow_value/7)\n",
        "editdf['DOW_cos'] = np.cos(2 * np.pi * dow_value/7)\n",
        "scaler_dow = MinMaxScaler()\n",
        "editdf[['DOW_sin', 'DOW_cos']] = scaler_dow.fit_transform(editdf[['DOW_sin', 'DOW_cos']])\n",
        "\n",
        "# Chain interactions\n",
        "editdf['chain_basket_interaction'] = editdf['is_chain'] * editdf['basket_score']\n",
        "editdf['chain_vendor_interaction'] = editdf['is_chain'] * editdf['vendor_score']\n",
        "\n",
        "# Drop unneeded columns\n",
        "columns_to_drop = ['vendor_count', 'product_count'] + \\\n",
        "                 [ 'Orders_Morning', 'Orders_Afternoon', 'Orders_Evening', 'Orders_Dusk'] + \\\n",
        "                 ['DOW_0', 'DOW_1', 'DOW_2', 'DOW_3', 'DOW_4', 'DOW_5', 'DOW_6', 'DOW_sin', 'DOW_cos', 'Orders_Dawn'  ,'Orders_Night', 'Items_Per_Order']\n",
        "editdf = editdf.drop(columns=columns_to_drop)"
      ],
      "metadata": {
        "id": "H2Do6qKYlbXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "editdf"
      ],
      "metadata": {
        "id": "sa3M5gSJRQFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shop_clean = editdf[['product_score', 'vendor_score', 'chain_vendor_interaction', 'daytime_orders',\t'evening_orders', 'chain_basket_interaction',]].copy()\n",
        "shop_clean = pd.concat([shop_clean, df_shop], axis=1)\n",
        "columns_to_drop = ['Orders_Night', 'Orders_Dawn', 'Orders_Morning',\n",
        "                   'Orders_Afternoon', 'Orders_Evening', 'vendor_count',\n",
        "                   'product_count', 'Orders_Dusk', 'DOW_0', 'DOW_1',\n",
        "                   'DOW_2', 'DOW_3', 'DOW_4', 'DOW_5', 'DOW_6',\n",
        "                    'DOW_sin', 'DOW_cos',\n",
        "                    'Items_Per_Order']\n",
        "\n",
        "shop_clean = shop_clean.drop(columns=columns_to_drop, errors='ignore')"
      ],
      "metadata": {
        "id": "iPNIR8WwhrJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integration of Random Forest and Clustering\n",
        "By integrating random forest **feature importance** with clustering, one can ensure that the most important features within each cluster are identified and prioritized. (Jingsong et al., 2020).\n",
        "\n",
        "*Li, Jingsong., Yang, Ziyue., Hu, Peijun., Zhang, Ying., Wang, Feng. (2020). Feature importance sorting system based on random forest algorithm in multi-center mode.   *"
      ],
      "metadata": {
        "id": "WyJIl4gYBiM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shop_clean"
      ],
      "metadata": {
        "id": "oRvEqJFSUB87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with manual continued permutation testing with the features engineered above and re-scoring the FI of features based on RF score vs the cluster as the 'Classification' new features are decided on to improve R2 and silhouette\n",
        "\n",
        "# Clustering\n",
        "kmeans = KMeans(n_clusters=3, init='k-means++', random_state=42)\n",
        "labels = kmeans.fit_predict(shop_clean)\n",
        "\n",
        "# Calculate metrics\n",
        "silhouette = silhouette_score(shop_clean, labels)\n",
        "ch_score = calinski_harabasz_score(shop_clean, labels)\n",
        "db_score = davies_bouldin_score(shop_clean, labels)\n",
        "cluster_centers = kmeans.cluster_centers_\n",
        "r2 = r2_score(shop_clean, cluster_centers[labels])\n",
        "\n",
        "print(f\"Silhouette: {silhouette:.3f}\")\n",
        "print(f\"Calinski-Harabasz: {ch_score:.2f}\")\n",
        "print(f\"Davies-Bouldin: {db_score:.2f}\")\n",
        "print(f\"R-squared: {r2:.3f}\")"
      ],
      "metadata": {
        "id": "_Muvh4e6qZye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scoring those features\n",
        "\n",
        "def analyze_feature_importance(df):\n",
        "   # Get cluster labels\n",
        "   kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "   labels = kmeans.fit_predict(df)\n",
        "\n",
        "   # Train RF classifier on clusters\n",
        "   rf = RandomForestClassifier(random_state=42)\n",
        "   rf.fit(df, labels)\n",
        "\n",
        "   # Get feature importance\n",
        "   importance = pd.DataFrame({\n",
        "       'feature': df.columns,\n",
        "       'importance': rf.feature_importances_\n",
        "   }).sort_values('importance', ascending=False)\n",
        "\n",
        "   return importance\n",
        "\n",
        "# Run analysis on preprocessed data\n",
        "importance = analyze_feature_importance(shop_clean)\n",
        "print(importance)\n",
        "\n"
      ],
      "metadata": {
        "id": "kB58yBxqZvtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loop to decide the ideal elbow point for this segment"
      ],
      "metadata": {
        "id": "rqVkbaARFHPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure shop_clean is a NumPy array\n",
        "shop_clean_array = shop_clean.values if isinstance(shop_clean, pd.DataFrame) else shop_clean\n",
        "\n",
        "# Clustering metrics (maintaining for scientific completeness and comparison)\n",
        "metrics = []\n",
        "for k in range(3, 11):\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "    labels = kmeans.fit_predict(shop_clean_array)\n",
        "\n",
        "    # Calculate SSE\n",
        "    sse = np.sum((shop_clean_array - kmeans.cluster_centers_[labels]) ** 2)\n",
        "\n",
        "    # Calculate R2\n",
        "    r2 = r2_score(shop_clean_array, kmeans.cluster_centers_[labels])\n",
        "\n",
        "    metrics.append({\n",
        "        'k': k,\n",
        "        'silhouette': silhouette_score(shop_clean_array, labels),\n",
        "        'calinski': calinski_harabasz_score(shop_clean_array, labels),\n",
        "        'davies': davies_bouldin_score(shop_clean_array, labels),\n",
        "        'inertia': kmeans.inertia_,\n",
        "        'sse': sse,\n",
        "        'r2': r2\n",
        "    })\n",
        "\n",
        "# Print metrics for comprehensive analysis\n",
        "for m in metrics:\n",
        "    print(f\"\\nk={m['k']}:\")\n",
        "    print(f\"Silhouette: {m['silhouette']:.3f}\")\n",
        "    print(f\"Calinski-Harabasz: {m['calinski']:.2f}\")\n",
        "    print(f\"Davies-Bouldin: {m['davies']:.2f}\")\n",
        "    print(f\"SSE: {m['sse']:.2f}\")\n",
        "    print(f\"R2: {m['r2']:.3f}\")\n",
        "    print(f\"Inertia: {m['inertia']:.2f}\")\n",
        "\n",
        "# Force k=3 for final clustering\n",
        "kmeans_final = KMeans(n_clusters=3, init='k-means++', random_state=42)\n",
        "labels = kmeans_final.fit_predict(shop_clean_array)\n",
        "\n",
        "# Update DataFrame with cluster labels\n",
        "shop_clean['cluster'] = labels\n",
        "\n",
        "# T-SNE embedding for dimensionality reduction and visualization\n",
        "tsne = TSNE(random_state=42)\n",
        "embedding = tsne.fit_transform(shop_clean_array)\n",
        "\n",
        "# Plotting with enhanced scientific visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# T-SNE plot with specified colormap for optimal cluster distinction\n",
        "scatter = ax1.scatter(embedding[:, 0], embedding[:, 1], c=labels, cmap='viridis')\n",
        "ax1.set_title('T-SNE visualization of 3 clusters')\n",
        "plt.colorbar(scatter, ax=ax1)\n",
        "\n",
        "# Elbow plot for comparative analysis\n",
        "ax2.plot(range(3, 11), [m['inertia'] for m in metrics], 'bo-')\n",
        "ax2.set_xlabel('Number of clusters (k)')\n",
        "ax2.set_ylabel('Inertia')\n",
        "ax2.set_title('Elbow Method')\n",
        "ax2.axvline(x=4, color='r', linestyle='--', label='Selected k=3')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the updated DataFrame with cluster labels\n",
        "print(shop_clean.head())"
      ],
      "metadata": {
        "id": "Zj75c--_A-Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shop_clean"
      ],
      "metadata": {
        "id": "35qxuVQtWxjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iteratively with manual permutation the balance of a R2 > 0.5 and 0.5 silhouette based on industry measures was sought after and with trial and error was found through kmeans++\n",
        "\n",
        "Kaufman & Rousseeuw (1990) Establishes silhouette > 0.5 as indicating reasonable to strong structure\n",
        "\n",
        "in combination with:\n",
        "\n",
        "Cohen, J. (1992) RÂ² > 0.5 as indicating large effect size\n",
        "\n",
        "Kaufman, L., & Rousseeuw, P. J. (1990). Finding groups in data: An introduction to cluster analysis (1st ed.). John Wiley & Sons. https://doi.org/10.1002/9780470316801\n",
        "\n",
        "Cohen, J. (1992). A power primer. Psychological Bulletin, 112(1), 155-159. https://doi.org/10.1037/0033-2909.112.1.155\n",
        "\n"
      ],
      "metadata": {
        "id": "Fr7iU2grGkRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shop_clean"
      ],
      "metadata": {
        "id": "Y3UcDDAkFdjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In an initial impression, I find that the code here below might seem overwhelming and over-engineered. However, based on the methodology established above of wanting to have a silhouette above 0.5 and an R2 above 0.5 to have a symbiosis effect for capturing enough variance and a large effect in a practical sense and having well-defined clusters, it was, in the manual iterative process of scoring importance, seemingly important to combine certain measures to achieve the desired result."
      ],
      "metadata": {
        "id": "zMos1oi72KxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_df_val(df):\n",
        "\n",
        "    # Initialize with core metrics\n",
        "    val_clean = df[['mnt', 'activity', 'frq', 'rcn', 'CLV_Score']].copy()\n",
        "\n",
        "    # CRITICAL CHECK: Identify binary columns\n",
        "    binary_cols = val_clean.apply(lambda x: len(x.unique()) <= 2).to_dict()\n",
        "\n",
        "    # BOUNDARY CONDITIONS\n",
        "    max_value = 1e15\n",
        "    val_clean = val_clean.clip(upper=max_value)\n",
        "\n",
        "    # Mathematical safeguards for non-binary columns only\n",
        "    val_clean['mnt'] = np.maximum(val_clean['mnt'], 0.01)\n",
        "    val_clean['frq'] = np.maximum(val_clean['frq'], 0)\n",
        "    val_clean['rcn'] = np.maximum(val_clean['rcn'], 0)\n",
        "\n",
        "    # DOUBLE LOG TRANSFORMATION ERROR DETECTED IN ORIGINAL CODE!\n",
        "    # Single log transform for CLV - prevents information loss from double scaling\n",
        "    val_clean['CLV_Score'] = np.log1p(val_clean['CLV_Score'])\n",
        "\n",
        "    # Strong Features (s_i)\n",
        "    val_clean['value_retention'] = val_clean['mnt'] / np.maximum(val_clean['activity'], 1)  # Binary division\n",
        "\n",
        "    val_clean['value_growth'] = val_clean['mnt'] / (np.maximum(val_clean['rcn'], 1) *\n",
        "                                                   np.maximum(val_clean['frq'], 1))\n",
        "\n",
        "    # Medium Features (m_i)\n",
        "    val_clean['value_growth_rate'] = val_clean['value_growth'] * val_clean['frq']\n",
        "\n",
        "    val_clean['growth_momentum'] = val_clean['value_growth'] * (val_clean['mnt'] /\n",
        "                                                              np.maximum(val_clean['rcn'], 1))\n",
        "\n",
        "    # Weak Features (w_i)\n",
        "    val_clean['spend_consistency'] = val_clean['mnt'] / np.maximum(val_clean['rcn'], 1)\n",
        "\n",
        "    val_clean['avg_order_value'] = val_clean['mnt'] / np.maximum(val_clean['frq'], 1)\n",
        "\n",
        "    val_clean['active_spend_rate'] = (val_clean['mnt'] * val_clean['activity']) / \\\n",
        "                                    np.maximum(val_clean['rcn'], 1)\n",
        "\n",
        "    final_cols = ['CLV_Score', 'value_retention', 'value_growth', 'value_growth_rate',\n",
        "                 'growth_momentum', 'spend_consistency', 'avg_order_value', 'active_spend_rate']\n",
        "\n",
        "    # Handle infinities before scaling\n",
        "    val_clean[final_cols] = val_clean[final_cols].replace([np.inf, -np.inf], np.nan)\n",
        "    val_clean[final_cols] = val_clean[final_cols].fillna(val_clean[final_cols].mean())\n",
        "\n",
        "    # CRITICAL SCALING CORRECTION: Only scale non-binary columns\n",
        "    scaler = StandardScaler()\n",
        "    val_clean[final_cols] = scaler.fit_transform(val_clean[final_cols])\n",
        "\n",
        "    return val_clean[final_cols]"
      ],
      "metadata": {
        "id": "h8_iNotxJmUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage:\n",
        "val_clean = preprocess_df_val(df_val)\n",
        "\n",
        "val_clean"
      ],
      "metadata": {
        "id": "2efXpix3KZ1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_clean.describe()"
      ],
      "metadata": {
        "id": "rh1fYdL4SmnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loop of kmeans testing once again to find the direct effect of features engineered in manual repeated permutation"
      ],
      "metadata": {
        "id": "w6cT18Pi2dBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering on encoded features\n",
        "kmeans = KMeans(n_clusters=3, init='k-means++', random_state=42)\n",
        "labels = kmeans.fit_predict(val_clean)\n",
        "\n",
        "# Calculate metrics\n",
        "silhouette = silhouette_score(val_clean, labels)\n",
        "ch_score = calinski_harabasz_score(val_clean, labels)\n",
        "db_score = davies_bouldin_score(val_clean, labels)\n",
        "\n",
        "# Calculate R-squared\n",
        "# Get cluster centers\n",
        "cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(val_clean, cluster_centers[labels])\n",
        "\n",
        "\n",
        "print(f\"Silhouette: {silhouette:.3f}\")\n",
        "print(f\"Calinski-Harabasz: {ch_score:.2f}\")\n",
        "print(f\"Davies-Bouldin: {db_score:.2f}\")\n",
        "print(f\"R-squared: {r2:.3f}\")"
      ],
      "metadata": {
        "id": "oMZYNtgNF-2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code assigns cluster labels from KMeans as the target variable for the RandomForestClassifier. This approach is to understand which features contribute most to the clustering."
      ],
      "metadata": {
        "id": "tkVoJkbH1dSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def analyze_feature_importance(df):\n",
        "   # Get cluster labels\n",
        "   kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "   labels = kmeans.fit_predict(df)\n",
        "\n",
        "   # Train RF classifier on clusters\n",
        "   rf = RandomForestClassifier(random_state=42)\n",
        "   rf.fit(df, labels)\n",
        "\n",
        "   # Get feature importance\n",
        "   importance = pd.DataFrame({\n",
        "       'feature': df.columns,\n",
        "       'importance': rf.feature_importances_\n",
        "   }).sort_values('importance', ascending=False)\n",
        "\n",
        "   return importance\n",
        "\n",
        "# Run analysis on preprocessed data\n",
        "importance = analyze_feature_importance(val_clean)\n",
        "print(importance)"
      ],
      "metadata": {
        "id": "xzjyDeH1Uzxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run analysis on preprocessed data\n",
        "importance = analyze_feature_importance(val_clean)\n",
        "print(importance)"
      ],
      "metadata": {
        "id": "NYXSYp26QnuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using forest FI i've dropped age_group and loyalty , high value ratio as they weren't adding significant value, RFM value dropped too after too much irrelevance based on tree testing"
      ],
      "metadata": {
        "id": "JPFGofngU1PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Critical validation of input data structure with explicit type enforcement\n",
        "val_clean_array = np.asarray(val_clean.values if isinstance(val_clean, pd.DataFrame) else val_clean, dtype=np.float64)\n",
        "\n",
        "# Verification of data integrity\n",
        "assert not np.isnan(val_clean_array).any(), \"Critical Error: NaN values detected in input array\"\n",
        "assert not np.isinf(val_clean_array).any(), \"Critical Error: Infinite values detected in input array\"\n",
        "\n",
        "# Clustering metrics with enhanced statistical validation protocols\n",
        "metrics = []\n",
        "for k in range(3, 11):\n",
        "    # Initialize KMeans with increased initialization attempts for global optimum convergence\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=20)\n",
        "    labels = kmeans.fit_predict(val_clean_array)\n",
        "\n",
        "    # Calculate SSE with validated mathematical precision\n",
        "    sse = np.sum((val_clean_array - kmeans.cluster_centers_[labels]) ** 2, dtype=np.float64)\n",
        "\n",
        "    # Calculate R2 with strict statistical validation\n",
        "    r2 = r2_score(val_clean_array, kmeans.cluster_centers_[labels])\n",
        "\n",
        "    # Comprehensive metric calculation with statistical safeguards\n",
        "    metrics.append({\n",
        "        'k': k,\n",
        "        'silhouette': silhouette_score(val_clean_array, labels, sample_size=len(val_clean_array)),\n",
        "        'calinski': calinski_harabasz_score(val_clean_array, labels),\n",
        "        'davies': davies_bouldin_score(val_clean_array, labels),\n",
        "        'inertia': kmeans.inertia_,\n",
        "        'sse': sse,\n",
        "        'r2': r2\n",
        "    })\n",
        "\n",
        "# Scientific output of metrics with enhanced precision\n",
        "for m in metrics:\n",
        "    print(f\"\\nCluster Analysis k={m['k']} \")\n",
        "    print(f\"Silhouette Coefficient: {m['silhouette']:.6f}\")\n",
        "    print(f\"Calinski-Harabasz Index: {m['calinski']:.6f}\")\n",
        "    print(f\"Davies-Bouldin Index: {m['davies']:.6f}\")\n",
        "    print(f\"Sum of Squared Errors: {m['sse']:.6f}\")\n",
        "    print(f\"RÂ² Score: {m['r2']:.6f}\")\n",
        "    print(f\"Inertia: {m['inertia']:.6f}\")\n",
        "\n",
        "# Enforce k=3 with maximum statistical rigor\n",
        "kmeans_final = KMeans(\n",
        "    n_clusters=3,\n",
        "    init='k-means++',\n",
        "    random_state=42,\n",
        "    n_init=50  # Increased for optimal convergence\n",
        ")\n",
        "labels = kmeans_final.fit_predict(val_clean_array)\n",
        "\n",
        "# Validate clustering stability\n",
        "cluster_sizes = np.bincount(labels)\n",
        "print(f\"\\nCluster Size Distribution: {cluster_sizes}\")\n",
        "print(f\"Cluster Size Variance: {np.var(cluster_sizes):.4f}\")\n",
        "\n",
        "# T-SNE with optimized hyperparameters\n",
        "tsne = TSNE(\n",
        "    random_state=42,\n",
        "    perplexity=min(30, len(val_clean_array)-1),\n",
        "    n_iter=2000,  # Increased iterations for convergence\n",
        "    learning_rate='auto',\n",
        "    metric='euclidean'\n",
        ")\n",
        "embedding = tsne.fit_transform(val_clean_array)\n",
        "\n",
        "# Enhanced scientific visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), dpi=150)\n",
        "\n",
        "# T-SNE plot with statistical annotations\n",
        "scatter = ax1.scatter(embedding[:, 0], embedding[:, 1], c=labels, cmap='viridis', alpha=0.8)\n",
        "ax1.set_title('T-SNE Visualization of 3 Clusters\\n(Perplexity: {})'.format(tsne.perplexity))\n",
        "ax1.grid(True, linestyle='--', alpha=0.3)\n",
        "colorbar = plt.colorbar(scatter, ax=ax1)\n",
        "colorbar.set_label('Cluster Assignment')\n",
        "\n",
        "# Elbow analysis with statistical indicators\n",
        "ax2.plot(range(3, 11), [m['inertia'] for m in metrics], 'bo-', linewidth=2)\n",
        "ax2.set_xlabel('Number of Clusters (k)')\n",
        "ax2.set_ylabel('Inertia (Within-cluster Sum of Squares)')\n",
        "ax2.set_title('Elbow Method Analysis')\n",
        "ax2.axvline(x=3, color='r', linestyle='--', label='Selected k=3')\n",
        "ax2.grid(True, linestyle='--', alpha=0.3)\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final statistical validation\n",
        "final_metrics = {\n",
        "    'silhouette': silhouette_score(val_clean_array, labels),\n",
        "    'calinski': calinski_harabasz_score(val_clean_array, labels),\n",
        "    'davies': davies_bouldin_score(val_clean_array, labels)\n",
        "}\n",
        "\n",
        "print(\"\\nFinal k=3 Clustering Validation Metrics:\")\n",
        "print(f\"Final Silhouette Score: {final_metrics['silhouette']:.6f}\")\n",
        "print(f\"Final Calinski-Harabasz Score: {final_metrics['calinski']:.6f}\")\n",
        "print(f\"Final Davies-Bouldin Score: {final_metrics['davies']:.6f}\")\n",
        "\n",
        "# Update DataFrame if applicable with rigorous type checking\n",
        "if isinstance(val_clean, pd.DataFrame):\n",
        "    val_clean['cluster'] = labels.astype(np.int32)\n",
        "    print(\"\\nCluster Distribution:\")\n",
        "    print(val_clean['cluster'].value_counts().sort_index())"
      ],
      "metadata": {
        "id": "ZDfHr-yjX-s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_clean"
      ],
      "metadata": {
        "id": "NJ0FS-iRzsuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Below is a second run of SOM cluster models and optuna grid searches to have a comparison and verification of proper clustering with k-means++"
      ],
      "metadata": {
        "id": "uGfcAkMII3hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # grid search SOM on val_clean\n",
        "\n",
        "# def objective(trial):\n",
        "#     \"\"\"Objective function for Optuna to optimize.\"\"\"\n",
        "#     # Define the search space for hyperparameters\n",
        "#     params = {\n",
        "#         'x_dim': trial.suggest_int('x_dim', 2, 10),  # Grid search for x_dim\n",
        "#         'y_dim': trial.suggest_int('y_dim', 2, 10),  # Grid search for y_dim\n",
        "#         'sigma': trial.suggest_float('sigma', 0.1, 5.0),  # Grid search for sigma\n",
        "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # Grid search for learning_rate\n",
        "#         'epochs': trial.suggest_int('epochs', 50, 500),  # Grid search for epochs\n",
        "#     }\n",
        "\n",
        "#     # Train and evaluate the SOM\n",
        "#     som, labels, metrics, _ = train_and_evaluate_som(val_clean_array, params)\n",
        "\n",
        "#     # Use silhouette score as the objective to maximize\n",
        "#     return metrics['silhouette_score']\n",
        "\n",
        "# # Run the Optuna study\n",
        "# study = optuna.create_study(direction='maximize')  # Maximize silhouette score\n",
        "# study.optimize(objective, n_trials=50)  # Run 50 trials\n",
        "\n",
        "# # Print the best parameters and best score\n",
        "# print(\"\\nBest Parameters:\")\n",
        "# print(study.best_params)\n",
        "# print(\"\\nBest Silhouette Score:\")\n",
        "# print(study.best_value)\n",
        "\n",
        "# # Train the SOM with the best parameters\n",
        "# best_params = study.best_params\n",
        "# som, labels, metrics, fig = train_and_evaluate_som(val_clean_array, best_params)\n",
        "\n",
        "# # Print the evaluation metrics for the best model\n",
        "# print(\"\\nEvaluation Metrics for Best Model:\")\n",
        "# for metric, value in metrics.items():\n",
        "#     print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# # Display the visualization for the best model\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "jiDwmhRD7Man"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best parameters: {'y_dim': 2, 'x_dim': 2, 'sigma': 1.0, 'learning_rate': 0.46415888336127775, 'epochs': 200}\n",
        "Best silhouette score: 0.5063111378206575"
      ],
      "metadata": {
        "id": "PmWX9B0s3Y0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class SOM:\n",
        "    def __init__(self, x_dim, y_dim, input_dim, learning_rate=0.1, sigma=None):\n",
        "        \"\"\"Initialize the SOM with given dimensions and parameters.\"\"\"\n",
        "        self.x_dim = x_dim\n",
        "        self.y_dim = y_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.learning_rate = learning_rate\n",
        "        self.sigma = sigma if sigma is not None else max(x_dim, y_dim) / 2\n",
        "        self.weights = np.random.randn(x_dim, y_dim, input_dim)\n",
        "        self.locations = np.array([(i, j) for i in range(x_dim) for j in range(y_dim)])\n",
        "\n",
        "    def find_bmu(self, x):\n",
        "        \"\"\"Find the Best Matching Unit for input vector x.\"\"\"\n",
        "        distances = cdist(x.reshape(1, -1), self.weights.reshape(-1, self.input_dim))\n",
        "        return np.unravel_index(distances.argmin(), (self.x_dim, self.y_dim))\n",
        "\n",
        "    def get_cluster_labels(self, data):\n",
        "        \"\"\"Assign cluster labels to input data.\"\"\"\n",
        "        data_array = self._ensure_numpy_array(data)\n",
        "        labels = []\n",
        "        for x in data_array:\n",
        "            bmu = self.find_bmu(x)\n",
        "            labels.append(bmu[0] * self.y_dim + bmu[1])\n",
        "        return np.array(labels)\n",
        "\n",
        "    def update_weights(self, x, bmu, iteration, max_iter):\n",
        "        \"\"\"Update network weights based on input and BMU.\"\"\"\n",
        "        lr = self.learning_rate * np.exp(-iteration / max_iter)\n",
        "        sigma = self.sigma * np.exp(-iteration / max_iter)\n",
        "        dist = cdist(self.locations, [bmu]).reshape(self.x_dim, self.y_dim)\n",
        "        influence = np.exp(-dist ** 2 / (2 * sigma ** 2))\n",
        "\n",
        "        for i in range(self.x_dim):\n",
        "            for j in range(self.y_dim):\n",
        "                self.weights[i, j] += lr * influence[i, j] * (x - self.weights[i, j])\n",
        "\n",
        "    def _ensure_numpy_array(self, data):\n",
        "        \"\"\"Convert input data to numpy array regardless of input type.\"\"\"\n",
        "        if isinstance(data, pd.DataFrame):\n",
        "            return data.values\n",
        "        elif isinstance(data, np.ndarray):\n",
        "            return data\n",
        "        else:\n",
        "            return np.array(data)\n",
        "\n",
        "    def train(self, data, epochs):\n",
        "        \"\"\"Train the SOM on input data.\"\"\"\n",
        "        data_array = self._ensure_numpy_array(data)\n",
        "\n",
        "        # Initialize weights to be in the same range as the input data\n",
        "        data_min = np.min(data_array, axis=0)\n",
        "        data_max = np.max(data_array, axis=0)\n",
        "        self.weights = np.random.uniform(\n",
        "            low=data_min,\n",
        "            high=data_max,\n",
        "            size=(self.x_dim, self.y_dim, self.input_dim)\n",
        "        )\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            indices = np.arange(len(data_array))\n",
        "            np.random.shuffle(indices)\n",
        "            shuffled_data = data_array[indices]\n",
        "            for i, x in enumerate(shuffled_data):\n",
        "                bmu = self.find_bmu(x)\n",
        "                self.update_weights(x, bmu, epoch * len(data_array) + i, epochs * len(data_array))\n",
        "\n",
        "    def visualize_clusters(self, data, labels):\n",
        "        \"\"\"Create visualizations for the SOM clusters.\"\"\"\n",
        "        data_array = self._ensure_numpy_array(data)\n",
        "        fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # 1. U-Matrix (Weight distances)\n",
        "        ax1 = fig.add_subplot(131)\n",
        "        umatrix = np.zeros((self.x_dim, self.y_dim))\n",
        "        for i in range(self.x_dim):\n",
        "            for j in range(self.y_dim):\n",
        "                neighbors = []\n",
        "                if i > 0: neighbors.append(self.weights[i-1, j])\n",
        "                if i < self.x_dim-1: neighbors.append(self.weights[i+1, j])\n",
        "                if j > 0: neighbors.append(self.weights[i, j-1])\n",
        "                if j < self.y_dim-1: neighbors.append(self.weights[i, j+1])\n",
        "                umatrix[i, j] = np.mean([np.linalg.norm(self.weights[i, j] - neighbor) for neighbor in neighbors])\n",
        "        sns.heatmap(umatrix, ax=ax1, cmap='viridis')\n",
        "        ax1.set_title('U-Matrix\\n(Weight Distances)')\n",
        "\n",
        "        # 2. Cluster assignments\n",
        "        ax2 = fig.add_subplot(132)\n",
        "        cluster_map = np.zeros((self.x_dim, self.y_dim))\n",
        "        unique_labels = np.unique(labels)\n",
        "        for label in unique_labels:\n",
        "            mask = (labels == label)\n",
        "            if np.any(mask):\n",
        "                points = data_array[mask]\n",
        "                for point in points:\n",
        "                    bmu = self.find_bmu(point)\n",
        "                    cluster_map[bmu] = label\n",
        "        sns.heatmap(cluster_map, ax=ax2, cmap='Set3')\n",
        "        ax2.set_title('Cluster Assignments')\n",
        "\n",
        "        # 3. Hit map (sample density)\n",
        "        ax3 = fig.add_subplot(133)\n",
        "        hit_map = np.zeros((self.x_dim, self.y_dim))\n",
        "        for x in data_array:\n",
        "            bmu = self.find_bmu(x)\n",
        "            hit_map[bmu] += 1\n",
        "        sns.heatmap(hit_map, ax=ax3, cmap='YlOrRd')\n",
        "        ax3.set_title('Hit Map\\n(Sample Density)')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "def evaluate_som(data, labels):\n",
        "    \"\"\"Calculate evaluation metrics for the SOM clustering.\"\"\"\n",
        "    data_array = np.array(data) if not isinstance(data, np.ndarray) else data\n",
        "    silhouette = silhouette_score(data_array, labels)\n",
        "    calinski = calinski_harabasz_score(data_array, labels)\n",
        "\n",
        "    # Calculate RÂ² using cluster centroids\n",
        "    centroids = np.array([data_array[labels == i].mean(axis=0) for i in np.unique(labels)])\n",
        "    predicted = centroids[labels]\n",
        "    r2 = r2_score(data_array, predicted)\n",
        "\n",
        "    return {\n",
        "        'silhouette_score': silhouette,\n",
        "        'calinski_harabasz_score': calinski,\n",
        "        'r2_score': r2\n",
        "    }\n",
        "\n",
        "def train_and_evaluate_som(data, params):\n",
        "    \"\"\"Train SOM with given parameters and evaluate performance.\"\"\"\n",
        "    # Convert data to numpy array\n",
        "    data_array = np.array(data) if not isinstance(data, np.ndarray) else data\n",
        "\n",
        "    # Initialize and train SOM\n",
        "    som = SOM(\n",
        "        x_dim=params['x_dim'],\n",
        "        y_dim=params['y_dim'],\n",
        "        input_dim=data_array.shape[1],\n",
        "        learning_rate=params['learning_rate'],\n",
        "        sigma=params['sigma']\n",
        "    )\n",
        "\n",
        "    som.train(data_array, params['epochs'])\n",
        "    labels = som.get_cluster_labels(data_array)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = evaluate_som(data_array, labels)\n",
        "\n",
        "    # Create visualization\n",
        "    fig = som.visualize_clusters(data_array, labels)\n",
        "\n",
        "    return som, labels, metrics, fig\n",
        "\n",
        "# Best parameters from your previous run\n",
        "best_params = {\n",
        "    'y_dim': 2,\n",
        "    'x_dim': 2,\n",
        "    'sigma': 1.0,\n",
        "    'learning_rate': 0.46415888336127775,\n",
        "    'epochs': 200\n",
        "}\n",
        "\n",
        "# Convert val_clean to numpy array if it isn't already\n",
        "val_clean_array = np.array(val_clean) if not isinstance(val_clean, np.ndarray) else val_clean\n",
        "\n",
        "# Train and evaluate the SOM\n",
        "som, labels, metrics, fig = train_and_evaluate_som(val_clean_array, best_params)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Display the visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UoCJTIXUzy5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class SOM:\n",
        "#     def __init__(self, x_dim, y_dim, input_dim, learning_rate=0.1, sigma=None):\n",
        "#         \"\"\"Initialize the SOM with given dimensions and parameters.\"\"\"\n",
        "#         self.x_dim = x_dim\n",
        "#         self.y_dim = y_dim\n",
        "#         self.input_dim = input_dim\n",
        "#         self.learning_rate = learning_rate\n",
        "#         self.sigma = sigma if sigma is not None else max(x_dim, y_dim) / 2\n",
        "#         self.weights = np.random.randn(x_dim, y_dim, input_dim)\n",
        "#         self.locations = np.array([(i, j) for i in range(x_dim) for j in range(y_dim)])\n",
        "\n",
        "#     def find_bmu(self, x):\n",
        "#         \"\"\"Find the Best Matching Unit for input vector x.\"\"\"\n",
        "#         distances = cdist(x.reshape(1, -1), self.weights.reshape(-1, self.input_dim))\n",
        "#         return np.unravel_index(distances.argmin(), (self.x_dim, self.y_dim))\n",
        "\n",
        "#     def get_cluster_labels(self, data):\n",
        "#         \"\"\"Assign cluster labels to input data.\"\"\"\n",
        "#         data_array = self._ensure_numpy_array(data)\n",
        "#         labels = []\n",
        "#         for x in data_array:\n",
        "#             bmu = self.find_bmu(x)\n",
        "#             labels.append(bmu[0] * self.y_dim + bmu[1])\n",
        "#         return np.array(labels)\n",
        "\n",
        "#     def update_weights(self, x, bmu, iteration, max_iter):\n",
        "#         \"\"\"Update network weights based on input and BMU.\"\"\"\n",
        "#         lr = self.learning_rate * np.exp(-iteration / max_iter)\n",
        "#         sigma = self.sigma * np.exp(-iteration / max_iter)\n",
        "#         dist = cdist(self.locations, [bmu]).reshape(self.x_dim, self.y_dim)\n",
        "#         influence = np.exp(-dist ** 2 / (2 * sigma ** 2))\n",
        "\n",
        "#         for i in range(self.x_dim):\n",
        "#             for j in range(self.y_dim):\n",
        "#                 self.weights[i, j] += lr * influence[i, j] * (x - self.weights[i, j])\n",
        "\n",
        "#     def _ensure_numpy_array(self, data):\n",
        "#         \"\"\"Convert input data to numpy array regardless of input type.\"\"\"\n",
        "#         if isinstance(data, pd.DataFrame):\n",
        "#             return data.values\n",
        "#         elif isinstance(data, np.ndarray):\n",
        "#             return data\n",
        "#         else:\n",
        "#             return np.array(data)\n",
        "\n",
        "#     def train(self, data, epochs):\n",
        "#         \"\"\"Train the SOM on input data.\"\"\"\n",
        "#         data_array = self._ensure_numpy_array(data)\n",
        "\n",
        "#         # Initialize weights to be in the same range as the input data\n",
        "#         data_min = np.min(data_array, axis=0)\n",
        "#         data_max = np.max(data_array, axis=0)\n",
        "#         self.weights = np.random.uniform(\n",
        "#             low=data_min,\n",
        "#             high=data_max,\n",
        "#             size=(self.x_dim, self.y_dim, self.input_dim)\n",
        "#         )\n",
        "\n",
        "#         for epoch in range(epochs):\n",
        "#             indices = np.arange(len(data_array))\n",
        "#             np.random.shuffle(indices)\n",
        "#             shuffled_data = data_array[indices]\n",
        "#             for i, x in enumerate(shuffled_data):\n",
        "#                 bmu = self.find_bmu(x)\n",
        "#                 self.update_weights(x, bmu, epoch * len(data_array) + i, epochs * len(data_array))\n",
        "\n",
        "#     def visualize_clusters(self, data, labels):\n",
        "#         \"\"\"Create visualizations for the SOM clusters.\"\"\"\n",
        "#         data_array = self._ensure_numpy_array(data)\n",
        "#         fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "#         # 1. U-Matrix (Weight distances)\n",
        "#         ax1 = fig.add_subplot(131)\n",
        "#         umatrix = np.zeros((self.x_dim, self.y_dim))\n",
        "#         for i in range(self.x_dim):\n",
        "#             for j in range(self.y_dim):\n",
        "#                 neighbors = []\n",
        "#                 if i > 0: neighbors.append(self.weights[i - 1, j])\n",
        "#                 if i < self.x_dim - 1: neighbors.append(self.weights[i + 1, j])\n",
        "#                 if j > 0: neighbors.append(self.weights[i, j - 1])\n",
        "#                 if j < self.y_dim - 1: neighbors.append(self.weights[i, j + 1])\n",
        "#                 umatrix[i, j] = np.mean([np.linalg.norm(self.weights[i, j] - neighbor) for neighbor in neighbors])\n",
        "#         sns.heatmap(umatrix, ax=ax1, cmap='viridis')\n",
        "#         ax1.set_title('U-Matrix\\n(Weight Distances)')\n",
        "\n",
        "#         # 2. Cluster assignments\n",
        "#         ax2 = fig.add_subplot(132)\n",
        "#         cluster_map = np.zeros((self.x_dim, self.y_dim))\n",
        "#         unique_labels = np.unique(labels)\n",
        "#         for label in unique_labels:\n",
        "#             mask = (labels == label)\n",
        "#             if np.any(mask):\n",
        "#                 points = data_array[mask]\n",
        "#                 for point in points:\n",
        "#                     bmu = self.find_bmu(point)\n",
        "#                     cluster_map[bmu] = label\n",
        "#         sns.heatmap(cluster_map, ax=ax2, cmap='Set3')\n",
        "#         ax2.set_title('Cluster Assignments')\n",
        "\n",
        "#         # 3. Hit map (sample density)\n",
        "#         ax3 = fig.add_subplot(133)\n",
        "#         hit_map = np.zeros((self.x_dim, self.y_dim))\n",
        "#         for x in data_array:\n",
        "#             bmu = self.find_bmu(x)\n",
        "#             hit_map[bmu] += 1\n",
        "#         sns.heatmap(hit_map, ax=ax3, cmap='YlOrRd')\n",
        "#         ax3.set_title('Hit Map\\n(Sample Density)')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         return fig\n",
        "\n",
        "\n",
        "# def evaluate_som(data, labels):\n",
        "#     \"\"\"Calculate evaluation metrics for the SOM clustering.\"\"\"\n",
        "#     data_array = np.array(data) if not isinstance(data, np.ndarray) else data\n",
        "\n",
        "#     # Calculate silhouette and Calinski-Harabasz scores\n",
        "#     silhouette = silhouette_score(data_array, labels)\n",
        "#     calinski = calinski_harabasz_score(data_array, labels)\n",
        "\n",
        "#     # Calculate RÂ² using cluster centroids\n",
        "#     unique_labels = np.unique(labels)\n",
        "#     centroids = np.array([data_array[labels == i].mean(axis=0) for i in unique_labels])\n",
        "\n",
        "#     # Map labels to indices in the centroids array\n",
        "#     label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "#     predicted = centroids[np.array([label_to_index[label] for label in labels])]\n",
        "\n",
        "#     r2 = r2_score(data_array, predicted)\n",
        "\n",
        "#     return {\n",
        "#         'silhouette_score': silhouette,\n",
        "#         'calinski_harabasz_score': calinski,\n",
        "#         'r2_score': r2\n",
        "#     }\n",
        "\n",
        "\n",
        "# def train_and_evaluate_som(data, params):\n",
        "#     \"\"\"Train SOM with given parameters and evaluate performance.\"\"\"\n",
        "#     # Convert data to numpy array\n",
        "#     data_array = np.array(data) if not isinstance(data, np.ndarray) else data\n",
        "\n",
        "#     # Initialize and train SOM\n",
        "#     som = SOM(\n",
        "#         x_dim=params['x_dim'],\n",
        "#         y_dim=params['y_dim'],\n",
        "#         input_dim=data_array.shape[1],\n",
        "#         learning_rate=params['learning_rate'],\n",
        "#         sigma=params['sigma']\n",
        "#     )\n",
        "\n",
        "#     som.train(data_array, params['epochs'])\n",
        "#     labels = som.get_cluster_labels(data_array)\n",
        "\n",
        "#     # Calculate metrics\n",
        "#     metrics = evaluate_som(data_array, labels)\n",
        "\n",
        "#     # Create visualization\n",
        "#     fig = som.visualize_clusters(data_array, labels)\n",
        "\n",
        "#     return som, labels, metrics, fig\n",
        "\n",
        "\n",
        "# # Ensure shop_clean is a NumPy array\n",
        "# shop_clean_array = np.array(shop_clean) if not isinstance(shop_clean, np.ndarray) else shop_clean\n",
        "\n",
        "\n",
        "# def objective(trial):\n",
        "#     \"\"\"Objective function for Optuna to optimize.\"\"\"\n",
        "#     # Define the search space for hyperparameters\n",
        "#     params = {\n",
        "#         'x_dim': trial.suggest_int('x_dim', 2, 10),  # Grid search for x_dim\n",
        "#         'y_dim': trial.suggest_int('y_dim', 2, 10),  # Grid search for y_dim\n",
        "#         'sigma': trial.suggest_float('sigma', 0.1, 5.0),  # Grid search for sigma\n",
        "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # Grid search for learning_rate\n",
        "#         'epochs': trial.suggest_int('epochs', 50, 500),  # Grid search for epochs\n",
        "#     }\n",
        "\n",
        "#     # Train and evaluate the SOM\n",
        "#     som, labels, metrics, _ = train_and_evaluate_som(shop_clean_array, params)\n",
        "\n",
        "#     # Use silhouette score as the objective to maximize\n",
        "#     return metrics['silhouette_score']\n",
        "\n",
        "\n",
        "# # Run the Optuna study\n",
        "# study = optuna.create_study(direction='maximize')  # Maximize silhouette score\n",
        "# study.optimize(objective, n_trials=25)  # Run 25 trials\n",
        "\n",
        "# # Print the best parameters and best score\n",
        "# print(\"\\nBest Parameters:\")\n",
        "# print(study.best_params)\n",
        "# print(\"\\nBest Silhouette Score:\")\n",
        "# print(study.best_value)\n",
        "\n",
        "# # Train the SOM with the best parameters\n",
        "# best_params = study.best_params\n",
        "# som, labels, metrics, fig = train_and_evaluate_som(shop_clean_array, best_params)\n",
        "\n",
        "# # Print the evaluation metrics for the best model\n",
        "# print(\"\\nEvaluation Metrics for Best Model:\")\n",
        "# for metric, value in metrics.items():\n",
        "#     print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# # Display the visualization for the best model\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "X98Fbo2b6pRd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "03424e25-3451-4d3d-d2aa-2c019c0da282"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shop_clean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-6808d43c9d30>\u001b[0m in \u001b[0;36m<cell line: 165>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;31m# Ensure shop_clean is a NumPy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m \u001b[0mshop_clean_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshop_clean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshop_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshop_clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shop_clean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy"
      ],
      "metadata": {
        "id": "ijlArx9LpSQy",
        "outputId": "bbaca7ed-ecd2-478e-b0c0-b4819c846185",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cupy\n",
            "  Downloading cupy-13.3.0.tar.gz (3.4 MB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/3.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/3.4 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/3.4 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/3.4 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from cupy) (1.26.4)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy) (0.8.3)\n",
            "Building wheels for collected packages: cupy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cupy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cupy\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cupy\n",
            "Failed to build cupy\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (cupy)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dWdOQRzApQc6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LhZa2gzarDMM",
        "outputId": "ad9a8902-d977-4c72-915b-a35a06093668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shop_clean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-13a274c531ef>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Synthetic Data Generation (Reproducible Stochastic Methodology)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mshop_clean_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshop_clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Hyperparameter Optimization Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shop_clean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation\n",
        "!pip install cupy numpy optuna scikit-learn seaborn matplotlib\n",
        "\n",
        "# Verification Steps\n",
        "!python verify_gpu.py  # Check GPU capabilities\n",
        "!python gpu_som_execution.py  # Run main script"
      ],
      "metadata": {
        "id": "x4U6OgmUpkmH",
        "outputId": "3c0d8596-a878-406d-8ef1-aceeb81eabd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cupy\n",
            "  Using cached cupy-13.3.0.tar.gz (3.4 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy) (0.8.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Building wheels for collected packages: cupy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cupy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cupy\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cupy\n",
            "Failed to build cupy\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (cupy)\u001b[0m\u001b[31m\n",
            "\u001b[0mpython3: can't open file '/content/verify_gpu.py': [Errno 2] No such file or directory\n",
            "python3: can't open file '/content/gpu_som_execution.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial 22 finished with value: 0.519218365366583 and parameters: {'x_dim': 9, 'y_dim': 8, 'sigma': 1.0923600860428389, 'learning_rate': 0.1661223667416274, 'epochs': 105}. Best is trial 22 with value: 0.519218365366583."
      ],
      "metadata": {
        "id": "P7BpWYPfuci9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SOM:\n",
        "    def __init__(self, x_dim, y_dim, input_dim, learning_rate=0.1, sigma=None):\n",
        "        \"\"\"Initialize the SOM with given dimensions and parameters.\"\"\"\n",
        "        self.x_dim = x_dim\n",
        "        self.y_dim = y_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.learning_rate = learning_rate\n",
        "        self.sigma = sigma if sigma is not None else max(x_dim, y_dim) / 2\n",
        "        self.weights = np.random.randn(x_dim, y_dim, input_dim)\n",
        "        self.locations = np.array([(i, j) for i in range(x_dim) for j in range(y_dim)])\n",
        "\n",
        "    def find_bmu(self, x):\n",
        "        \"\"\"Find the Best Matching Unit for input vector x.\"\"\"\n",
        "        distances = cdist(x.reshape(1, -1), self.weights.reshape(-1, self.input_dim))\n",
        "        return np.unravel_index(distances.argmin(), (self.x_dim, self.y_dim))\n",
        "\n",
        "    def get_cluster_labels(self, data):\n",
        "        \"\"\"Assign cluster labels to input data.\"\"\"\n",
        "        data_array = self._ensure_numpy_array(data)\n",
        "        labels = []\n",
        "        unique_bmus = {}  # Dictionary to map BMUs to sequential labels\n",
        "        label_counter = 0\n",
        "\n",
        "        for x in data_array:\n",
        "            bmu = self.find_bmu(x)\n",
        "            bmu_key = (bmu[0], bmu[1])  # Use BMU coordinates as a key\n",
        "\n",
        "            if bmu_key not in unique_bmus:\n",
        "                unique_bmus[bmu_key] = label_counter\n",
        "                label_counter += 1\n",
        "\n",
        "            labels.append(unique_bmus[bmu_key])\n",
        "\n",
        "        return np.array(labels)\n",
        "\n",
        "    def update_weights(self, x, bmu, iteration, max_iter):\n",
        "        \"\"\"Update network weights based on input and BMU.\"\"\"\n",
        "        lr = self.learning_rate * np.exp(-iteration / max_iter)\n",
        "        sigma = self.sigma * np.exp(-iteration / max_iter)\n",
        "        dist = cdist(self.locations, [bmu]).reshape(self.x_dim, self.y_dim)\n",
        "        influence = np.exp(-dist ** 2 / (2 * sigma ** 2))\n",
        "\n",
        "        for i in range(self.x_dim):\n",
        "            for j in range(self.y_dim):\n",
        "                self.weights[i, j] += lr * influence[i, j] * (x - self.weights[i, j])\n",
        "\n",
        "    def _ensure_numpy_array(self, data):\n",
        "        \"\"\"Convert input data to numpy array regardless of input type.\"\"\"\n",
        "        if isinstance(data, pd.DataFrame):\n",
        "            return data.values\n",
        "        elif isinstance(data, np.ndarray):\n",
        "            return data\n",
        "        else:\n",
        "            return np.array(data)\n",
        "\n",
        "    def train(self, data, epochs):\n",
        "        \"\"\"Train the SOM on input data.\"\"\"\n",
        "        data_array = self._ensure_numpy_array(data)\n",
        "\n",
        "        # Initialize weights to be in the same range as the input data\n",
        "        data_min = np.min(data_array, axis=0)\n",
        "        data_max = np.max(data_array, axis=0)\n",
        "        self.weights = np.random.uniform(\n",
        "            low=data_min,\n",
        "            high=data_max,\n",
        "            size=(self.x_dim, self.y_dim, self.input_dim)\n",
        "        )\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            indices = np.arange(len(data_array))\n",
        "            np.random.shuffle(indices)\n",
        "            shuffled_data = data_array[indices]\n",
        "            for i, x in enumerate(shuffled_data):\n",
        "                bmu = self.find_bmu(x)\n",
        "                self.update_weights(x, bmu, epoch * len(data_array) + i, epochs * len(data_array))\n",
        "\n",
        "    def visualize_clusters(self, data, labels):\n",
        "        \"\"\"Create visualizations for the SOM clusters.\"\"\"\n",
        "        data_array = self._ensure_numpy_array(data)\n",
        "        fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # 1. U-Matrix (Weight distances)\n",
        "        ax1 = fig.add_subplot(131)\n",
        "        umatrix = np.zeros((self.x_dim, self.y_dim))\n",
        "        for i in range(self.x_dim):\n",
        "            for j in range(self.y_dim):\n",
        "                neighbors = []\n",
        "                if i > 0: neighbors.append(self.weights[i-1, j])\n",
        "                if i < self.x_dim-1: neighbors.append(self.weights[i+1, j])\n",
        "                if j > 0: neighbors.append(self.weights[i, j-1])\n",
        "                if j < self.y_dim-1: neighbors.append(self.weights[i, j+1])\n",
        "                umatrix[i, j] = np.mean([np.linalg.norm(self.weights[i, j] - neighbor) for neighbor in neighbors])\n",
        "        sns.heatmap(umatrix, ax=ax1, cmap='viridis')\n",
        "        ax1.set_title('U-Matrix\\n(Weight Distances)')\n",
        "\n",
        "        # 2. Cluster assignments\n",
        "        ax2 = fig.add_subplot(132)\n",
        "        cluster_map = np.zeros((self.x_dim, self.y_dim))\n",
        "        unique_labels = np.unique(labels)\n",
        "        for label in unique_labels:\n",
        "            mask = (labels == label)\n",
        "            if np.any(mask):\n",
        "                points = data_array[mask]\n",
        "                for point in points:\n",
        "                    bmu = self.find_bmu(point)\n",
        "                    cluster_map[bmu] = label\n",
        "        sns.heatmap(cluster_map, ax=ax2, cmap='Set3')\n",
        "        ax2.set_title('Cluster Assignments')\n",
        "\n",
        "        # 3. Hit map (sample density)\n",
        "        ax3 = fig.add_subplot(133)\n",
        "        hit_map = np.zeros((self.x_dim, self.y_dim))\n",
        "        for x in data_array:\n",
        "            bmu = self.find_bmu(x)\n",
        "            hit_map[bmu] += 1\n",
        "        sns.heatmap(hit_map, ax=ax3, cmap='YlOrRd')\n",
        "        ax3.set_title('Hit Map\\n(Sample Density)')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "\n",
        "def evaluate_som(data, labels):\n",
        "    \"\"\"Calculate evaluation metrics for the SOM clustering.\"\"\"\n",
        "    data_array = np.array(data) if not isinstance(data, np.ndarray) else data\n",
        "\n",
        "    # Ensure labels are valid\n",
        "    unique_labels = np.unique(labels)\n",
        "    if len(unique_labels) == 1:\n",
        "        raise ValueError(\"Only one cluster found. Evaluation metrics require at least two clusters.\")\n",
        "\n",
        "    # Calculate Silhouette Score and Calinski-Harabasz Score\n",
        "    silhouette = silhouette_score(data_array, labels)\n",
        "    calinski = calinski_harabasz_score(data_array, labels)\n",
        "\n",
        "    # Calculate RÂ² using cluster centroids\n",
        "    centroids = np.array([data_array[labels == i].mean(axis=0) for i in unique_labels])\n",
        "    predicted = centroids[labels]\n",
        "    r2 = r2_score(data_array, predicted)\n",
        "\n",
        "    return {\n",
        "        'silhouette_score': silhouette,\n",
        "        'calinski_harabasz_score': calinski,\n",
        "        'r2_score': r2\n",
        "    }\n",
        "\n",
        "\n",
        "def train_and_evaluate_som(data, params):\n",
        "    \"\"\"Train SOM with given parameters and evaluate performance.\"\"\"\n",
        "    # Convert data to numpy array\n",
        "    data_array = np.array(data) if not isinstance(data, np.ndarray) else data\n",
        "\n",
        "    # Initialize and train SOM\n",
        "    som = SOM(\n",
        "        x_dim=params['x_dim'],\n",
        "        y_dim=params['y_dim'],\n",
        "        input_dim=data_array.shape[1],\n",
        "        learning_rate=params['learning_rate'],\n",
        "        sigma=params['sigma']\n",
        "    )\n",
        "\n",
        "    som.train(data_array, params['epochs'])\n",
        "    labels = som.get_cluster_labels(data_array)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = evaluate_som(data_array, labels)\n",
        "\n",
        "    # Create visualization\n",
        "    fig = som.visualize_clusters(data_array, labels)\n",
        "\n",
        "    return som, labels, metrics, fig\n",
        "\n",
        "\n",
        "# Best parameters from your previous run\n",
        "best_params = {\n",
        "    'y_dim': 9,\n",
        "    'x_dim': 7,\n",
        "    'sigma': 2.344055736106201,\n",
        "    'learning_rate': 0.3804926815785139,\n",
        "    'epochs': 216\n",
        "}\n",
        "\n",
        "# Convert val_clean to numpy array if it isn't already\n",
        "shop_clean_array = np.array(shop_clean) if not isinstance(shop_clean, np.ndarray) else shop_clean\n",
        "\n",
        "# Train and evaluate the SOM\n",
        "som, labels, metrics, fig = train_and_evaluate_som(shop_clean_array, best_params)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Display the visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xx1hpbgG4J6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class SOM:\n",
        "#     def __init__(self, x_dim, y_dim, input_dim, learning_rate=0.1, sigma=None):\n",
        "#         \"\"\"Initialize the SOM with given dimensions and parameters.\"\"\"\n",
        "#         self.x_dim = x_dim\n",
        "#         self.y_dim = y_dim\n",
        "#         self.input_dim = input_dim\n",
        "#         self.learning_rate = learning_rate\n",
        "#         self.sigma = sigma if sigma is not None else max(x_dim, y_dim) / 2\n",
        "#         self.weights = np.random.randn(x_dim, y_dim, input_dim)\n",
        "#         self.locations = np.array([(i, j) for i in range(x_dim) for j in range(y_dim)])\n",
        "\n",
        "#     def find_bmu(self, x):\n",
        "#         \"\"\"Find the Best Matching Unit for input vector x.\"\"\"\n",
        "#         distances = cdist(x.reshape(1, -1), self.weights.reshape(-1, self.input_dim))\n",
        "#         return np.unravel_index(distances.argmin(), (self.x_dim, self.y_dim))\n",
        "\n",
        "#     def get_cluster_labels(self, data):\n",
        "#         \"\"\"Assign cluster labels to input data.\"\"\"\n",
        "#         data_array = self._ensure_numpy_array(data)\n",
        "#         labels = []\n",
        "#         for x in data_array:\n",
        "#             bmu = self.find_bmu(x)\n",
        "#             labels.append(bmu[0] * self.y_dim + bmu[1])\n",
        "#         return np.array(labels)\n",
        "\n",
        "#     def update_weights(self, x, bmu, iteration, max_iter):\n",
        "#         \"\"\"Update network weights based on input and BMU.\"\"\"\n",
        "#         lr = self.learning_rate * np.exp(-iteration / max_iter)\n",
        "#         sigma = self.sigma * np.exp(-iteration / max_iter)\n",
        "#         dist = cdist(self.locations, [bmu]).reshape(self.x_dim, self.y_dim)\n",
        "#         influence = np.exp(-dist ** 2 / (2 * sigma ** 2))\n",
        "\n",
        "#         for i in range(self.x_dim):\n",
        "#             for j in range(self.y_dim):\n",
        "#                 self.weights[i, j] += lr * influence[i, j] * (x - self.weights[i, j])\n",
        "\n",
        "#     def _ensure_numpy_array(self, data):\n",
        "#         \"\"\"Convert input data to numpy array regardless of input type.\"\"\"\n",
        "#         if isinstance(data, pd.DataFrame):\n",
        "#             return data.values\n",
        "#         elif isinstance(data, np.ndarray):\n",
        "#             return data\n",
        "#         else:\n",
        "#             return np.array(data)\n",
        "\n",
        "#     def train(self, data, epochs):\n",
        "#         \"\"\"Train the SOM on input data.\"\"\"\n",
        "#         data_array = self._ensure_numpy_array(data)\n",
        "\n",
        "#         # Initialize weights to be in the same range as the input data\n",
        "#         data_min = np.min(data_array, axis=0)\n",
        "#         data_max = np.max(data_array, axis=0)\n",
        "#         self.weights = np.random.uniform(\n",
        "#             low=data_min,\n",
        "#             high=data_max,\n",
        "#             size=(self.x_dim, self.y_dim, self.input_dim)\n",
        "#         )\n",
        "\n",
        "#         for epoch in range(epochs):\n",
        "#             indices = np.arange(len(data_array))\n",
        "#             np.random.shuffle(indices)\n",
        "#             shuffled_data = data_array[indices]\n",
        "#             for i, x in enumerate(shuffled_data):\n",
        "#                 bmu = self.find_bmu(x)\n",
        "#                 self.update_weights(x, bmu, epoch * len(data_array) + i, epochs * len(data_array))\n",
        "\n",
        "#     def visualize_clusters(self, data, labels):\n",
        "#         \"\"\"Create visualizations for the SOM clusters.\"\"\"\n",
        "#         data_array = self._ensure_numpy_array(data)\n",
        "#         fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "#         # 1. U-Matrix (Weight distances)\n",
        "#         ax1 = fig.add_subplot(131)\n",
        "#         umatrix = np.zeros((self.x_dim, self.y_dim))\n",
        "#         for i in range(self.x_dim):\n",
        "#             for j in range(self.y_dim):\n",
        "#                 neighbors = []\n",
        "#                 if i > 0: neighbors.append(self.weights[i - 1, j])\n",
        "#                 if i < self.x_dim - 1: neighbors.append(self.weights[i + 1, j])\n",
        "#                 if j > 0: neighbors.append(self.weights[i, j - 1])\n",
        "#                 if j < self.y_dim - 1: neighbors.append(self.weights[i, j + 1])\n",
        "#                 umatrix[i, j] = np.mean([np.linalg.norm(self.weights[i, j] - neighbor) for neighbor in neighbors])\n",
        "#         sns.heatmap(umatrix, ax=ax1, cmap='viridis')\n",
        "#         ax1.set_title('U-Matrix\\n(Weight Distances)')\n",
        "\n",
        "#         # 2. Cluster assignments\n",
        "#         ax2 = fig.add_subplot(132)\n",
        "#         cluster_map = np.zeros((self.x_dim, self.y_dim))\n",
        "#         unique_labels = np.unique(labels)\n",
        "#         for label in unique_labels:\n",
        "#             mask = (labels == label)\n",
        "#             if np.any(mask):\n",
        "#                 points = data_array[mask]\n",
        "#                 for point in points:\n",
        "#                     bmu = self.find_bmu(point)\n",
        "#                     cluster_map[bmu] = label\n",
        "#         sns.heatmap(cluster_map, ax=ax2, cmap='Set3')\n",
        "#         ax2.set_title('Cluster Assignments')\n",
        "\n",
        "#         # 3. Hit map (sample density)\n",
        "#         ax3 = fig.add_subplot(133)\n",
        "#         hit_map = np.zeros((self.x_dim, self.y_dim))\n",
        "#         for x in data_array:\n",
        "#             bmu = self.find_bmu(x)\n",
        "#             hit_map[bmu] += 1\n",
        "#         sns.heatmap(hit_map, ax=ax3, cmap='YlOrRd')\n",
        "#         ax3.set_title('Hit Map\\n(Sample Density)')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         return fig\n",
        "\n",
        "\n",
        "# def evaluate_som(data, labels):\n",
        "#     \"\"\"Calculate evaluation metrics for the SOM clustering.\"\"\"\n",
        "#     data_array = np.array(data) if not isinstance(data, np.ndarray) else data\n",
        "\n",
        "#     # Calculate silhouette and Calinski-Harabasz scores\n",
        "#     silhouette = silhouette_score(data_array, labels)\n",
        "#     calinski = calinski_harabasz_score(data_array, labels)\n",
        "\n",
        "#     # Calculate RÂ² using cluster centroids\n",
        "#     unique_labels = np.unique(labels)\n",
        "#     centroids = np.array([data_array[labels == i].mean(axis=0) for i in unique_labels])\n",
        "\n",
        "#     # Map labels to indices in the centroids array\n",
        "#     label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "#     predicted = centroids[np.array([label_to_index[label] for label in labels])]\n",
        "\n",
        "#     r2 = r2_score(data_array, predicted)\n",
        "\n",
        "#     return {\n",
        "#         'silhouette_score': silhouette,\n",
        "#         'calinski_harabasz_score': calinski,\n",
        "#         'r2_score': r2\n",
        "#     }\n",
        "\n",
        "\n",
        "# def train_and_evaluate_som(data, params):\n",
        "#     \"\"\"Train SOM with given parameters and evaluate performance.\"\"\"\n",
        "#     # Convert data to numpy array\n",
        "#     data_array = np.array(data) if not isinstance(data, np.ndarray) else data\n",
        "\n",
        "#     # Initialize and train SOM\n",
        "#     som = SOM(\n",
        "#         x_dim=params['x_dim'],\n",
        "#         y_dim=params['y_dim'],\n",
        "#         input_dim=data_array.shape[1],\n",
        "#         learning_rate=params['learning_rate'],\n",
        "#         sigma=params['sigma']\n",
        "#     )\n",
        "\n",
        "#     som.train(data_array, params['epochs'])\n",
        "#     labels = som.get_cluster_labels(data_array)\n",
        "\n",
        "#     # Calculate metrics\n",
        "#     metrics = evaluate_som(data_array, labels)\n",
        "\n",
        "#     # Create visualization\n",
        "#     fig = som.visualize_clusters(data_array, labels)\n",
        "\n",
        "#     return som, labels, metrics, fig\n",
        "\n",
        "\n",
        "# # Ensure shop_clean is a NumPy array\n",
        "# pref_clean_array = np.array(pref_clean) if not isinstance(pref_clean, np.ndarray) else pref_clean\n",
        "\n",
        "\n",
        "# def objective(trial):\n",
        "#     \"\"\"Objective function for Optuna to optimize.\"\"\"\n",
        "#     # Define the search space for hyperparameters\n",
        "#     params = {\n",
        "#         'x_dim': trial.suggest_int('x_dim', 5, 11),  # Grid search for x_dim\n",
        "#         'y_dim': trial.suggest_int('y_dim', 2, 10),  # Grid search for y_dim\n",
        "#         'sigma': trial.suggest_float('sigma', 0.2, 4.2),  # Grid search for sigma\n",
        "#         'learning_rate': trial.suggest_float('learning_rate', 0.04, 1.0),  # Grid search for learning_rate\n",
        "#         'epochs': trial.suggest_int('epochs', 400, 600),  # Grid search for epochs\n",
        "#     }\n",
        "\n",
        "#     # Train and evaluate the SOM\n",
        "#     som, labels, metrics, _ = train_and_evaluate_som(pref_clean_array, params)\n",
        "\n",
        "#     # Use silhouette score as the objective to maximize\n",
        "#     return metrics['silhouette_score']\n",
        "\n",
        "\n",
        "# # Run the Optuna study\n",
        "# study = optuna.create_study(direction='maximize')  # Maximize silhouette score\n",
        "# study.optimize(objective, n_trials=25)  # Run 25 trials\n",
        "\n",
        "# # Print the best parameters and best score\n",
        "# print(\"\\nBest Parameters:\")\n",
        "# print(study.best_params)\n",
        "# print(\"\\nBest Silhouette Score:\")\n",
        "# print(study.best_value)\n",
        "\n",
        "# # Train the SOM with the best parameters\n",
        "# best_params = study.best_params\n",
        "# som, labels, metrics, fig = train_and_evaluate_som(pref_clean_array, best_params)\n",
        "\n",
        "# # Print the evaluation metrics for the best model\n",
        "# print(\"\\nEvaluation Metrics for Best Model:\")\n",
        "# for metric, value in metrics.items():\n",
        "#     print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# # Display the visualization for the best model\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "J4VRkjIMGayY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[I 2024-12-24 21:56:22,424] A new study created in memory with name: no-name-78a8a608-0a6a-4ab2-839d-1b2fa5711556\n",
        "\n",
        "Best Parameters:\n",
        "{'x_dim': 3, 'y_dim': 8, 'sigma': 0.17275998212809796, 'learning_rate': 0.6409566898354768, 'epochs': 445}"
      ],
      "metadata": {
        "id": "LzeSQFkauGuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SOM:\n",
        "    def __init__(self, x_dim, y_dim, input_dim, learning_rate=0.1, sigma=None):\n",
        "        \"\"\"Initialize the SOM with given dimensions and parameters.\"\"\"\n",
        "        self.x_dim = x_dim\n",
        "        self.y_dim = y_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.learning_rate = learning_rate\n",
        "        self.sigma = sigma if sigma is not None else max(x_dim, y_dim) / 2\n",
        "        self.weights = np.random.randn(x_dim, y_dim, input_dim)\n",
        "        self.locations = np.array([(i, j) for i in range(x_dim) for j in range(y_dim)])\n",
        "\n",
        "    def find_bmu(self, x):\n",
        "        \"\"\"Find the Best Matching Unit for input vector x.\"\"\"\n",
        "        distances = cdist(x.reshape(1, -1), self.weights.reshape(-1, self.input_dim))\n",
        "        return np.unravel_index(distances.argmin(), (self.x_dim, self.y_dim))\n",
        "\n",
        "    def get_cluster_labels(self, data):\n",
        "        \"\"\"Assign cluster labels to input data.\"\"\"\n",
        "        data_array = self._ensure_numpy_array(data)\n",
        "        labels = []\n",
        "        for x in data_array:\n",
        "            bmu = self.find_bmu(x)\n",
        "            labels.append(bmu[0] * self.y_dim + bmu[1])\n",
        "        return np.array(labels)\n",
        "\n",
        "    def update_weights(self, x, bmu, iteration, max_iter):\n",
        "        \"\"\"Update network weights based on input and BMU.\"\"\"\n",
        "        lr = self.learning_rate * np.exp(-iteration / max_iter)\n",
        "        sigma = self.sigma * np.exp(-iteration / max_iter)\n",
        "        dist = cdist(self.locations, [bmu]).reshape(self.x_dim, self.y_dim)\n",
        "        influence = np.exp(-dist ** 2 / (2 * sigma ** 2))\n",
        "\n",
        "        for i in range(self.x_dim):\n",
        "            for j in range(self.y_dim):\n",
        "                self.weights[i, j] += lr * influence[i, j] * (x - self.weights[i, j])\n",
        "\n",
        "    def _ensure_numpy_array(self, data):\n",
        "        \"\"\"Convert input data to numpy array regardless of input type.\"\"\"\n",
        "        if isinstance(data, pd.DataFrame):\n",
        "            return data.values\n",
        "        elif isinstance(data, np.ndarray):\n",
        "            return data\n",
        "        else:\n",
        "            return np.array(data)\n",
        "\n",
        "    def train(self, data, epochs):\n",
        "        \"\"\"Train the SOM on input data.\"\"\"\n",
        "        data_array = self._ensure_numpy_array(data)\n",
        "\n",
        "        # Initialize weights to be in the same range as the input data\n",
        "        data_min = np.min(data_array, axis=0)\n",
        "        data_max = np.max(data_array, axis=0)\n",
        "        self.weights = np.random.uniform(\n",
        "            low=data_min,\n",
        "            high=data_max,\n",
        "            size=(self.x_dim, self.y_dim, self.input_dim)\n",
        "        )\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            indices = np.arange(len(data_array))\n",
        "            np.random.shuffle(indices)\n",
        "            shuffled_data = data_array[indices]\n",
        "            for i, x in enumerate(shuffled_data):\n",
        "                bmu = self.find_bmu(x)\n",
        "                self.update_weights(x, bmu, epoch * len(data_array) + i, epochs * len(data_array))\n",
        "\n",
        "    def visualize_clusters(self, data, labels):\n",
        "        \"\"\"Create visualizations for the SOM clusters.\"\"\"\n",
        "        data_array = self._ensure_numpy_array(data)\n",
        "        fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # 1. U-Matrix (Weight distances)\n",
        "        ax1 = fig.add_subplot(131)\n",
        "        umatrix = np.zeros((self.x_dim, self.y_dim))\n",
        "        for i in range(self.x_dim):\n",
        "            for j in range(self.y_dim):\n",
        "                neighbors = []\n",
        "                if i > 0: neighbors.append(self.weights[i-1, j])\n",
        "                if i < self.x_dim-1: neighbors.append(self.weights[i+1, j])\n",
        "                if j > 0: neighbors.append(self.weights[i, j-1])\n",
        "                if j < self.y_dim-1: neighbors.append(self.weights[i, j+1])\n",
        "                umatrix[i, j] = np.mean([np.linalg.norm(self.weights[i, j] - neighbor) for neighbor in neighbors])\n",
        "        sns.heatmap(umatrix, ax=ax1, cmap='viridis')\n",
        "        ax1.set_title('U-Matrix\\n(Weight Distances)')\n",
        "\n",
        "        # 2. Cluster assignments\n",
        "        ax2 = fig.add_subplot(132)\n",
        "        cluster_map = np.zeros((self.x_dim, self.y_dim))\n",
        "        unique_labels = np.unique(labels)\n",
        "        for label in unique_labels:\n",
        "            mask = (labels == label)\n",
        "            if np.any(mask):\n",
        "                points = data_array[mask]\n",
        "                for point in points:\n",
        "                    bmu = self.find_bmu(point)\n",
        "                    cluster_map[bmu] = label\n",
        "        sns.heatmap(cluster_map, ax=ax2, cmap='Set3')\n",
        "        ax2.set_title('Cluster Assignments')\n",
        "\n",
        "        # 3. Hit map (sample density)\n",
        "        ax3 = fig.add_subplot(133)\n",
        "        hit_map = np.zeros((self.x_dim, self.y_dim))\n",
        "        for x in data_array:\n",
        "            bmu = self.find_bmu(x)\n",
        "            hit_map[bmu] += 1\n",
        "        sns.heatmap(hit_map, ax=ax3, cmap='YlOrRd')\n",
        "        ax3.set_title('Hit Map\\n(Sample Density)')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "\n",
        "def evaluate_som(data, labels):\n",
        "    \"\"\"Calculate evaluation metrics for the SOM clustering.\"\"\"\n",
        "    data_array = np.array(data) if not isinstance(data, np.ndarray) else data\n",
        "\n",
        "    # Remap labels to a continuous range starting from 0\n",
        "    unique_labels = np.unique(labels)\n",
        "    label_mapping = {label: i for i, label in enumerate(unique_labels)}\n",
        "    remapped_labels = np.array([label_mapping[label] for label in labels])\n",
        "\n",
        "    # Ensure there are at least two clusters for evaluation\n",
        "    if len(unique_labels) == 1:\n",
        "        raise ValueError(\"Only one cluster found. Evaluation metrics require at least two clusters.\")\n",
        "\n",
        "    # Calculate Silhouette Score and Calinski-Harabasz Score\n",
        "    silhouette = silhouette_score(data_array, remapped_labels)\n",
        "    calinski = calinski_harabasz_score(data_array, remapped_labels)\n",
        "\n",
        "    # Calculate RÂ² using cluster centroids\n",
        "    centroids = np.array([data_array[remapped_labels == i].mean(axis=0) for i in np.unique(remapped_labels)])\n",
        "    predicted = centroids[remapped_labels]\n",
        "    r2 = r2_score(data_array, predicted)\n",
        "\n",
        "    return {\n",
        "        'silhouette_score': silhouette,\n",
        "        'calinski_harabasz_score': calinski,\n",
        "        'r2_score': r2\n",
        "    }\n",
        "\n",
        "\n",
        "def train_and_evaluate_som(data, params):\n",
        "    \"\"\"Train SOM with given parameters and evaluate performance.\"\"\"\n",
        "    # Convert data to numpy array\n",
        "    data_array = np.array(data) if not isinstance(data, np.ndarray) else data\n",
        "\n",
        "    # Initialize and train SOM\n",
        "    som = SOM(\n",
        "        x_dim=params['x_dim'],\n",
        "        y_dim=params['y_dim'],\n",
        "        input_dim=data_array.shape[1],\n",
        "        learning_rate=params['learning_rate'],\n",
        "        sigma=params['sigma']\n",
        "    )\n",
        "\n",
        "    som.train(data_array, params['epochs'])\n",
        "    labels = som.get_cluster_labels(data_array)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = evaluate_som(data_array, labels)\n",
        "\n",
        "    # Create visualization\n",
        "    fig = som.visualize_clusters(data_array, labels)\n",
        "\n",
        "    return som, labels, metrics, fig\n",
        "\n",
        "\n",
        "# Best parameters from your previous run\n",
        "best_params = {\n",
        "    'y_dim': 3,\n",
        "    'x_dim': 8,\n",
        "    'sigma': 0.1727,\n",
        "    'learning_rate': 0.6409566898354768,\n",
        "    'epochs': 445\n",
        "}\n",
        "\n",
        "# Convert val_clean to numpy array if it isn't already\n",
        "pref_clean_array = np.array(pref_clean) if not isinstance(pref_clean, np.ndarray) else pref_clean\n",
        "\n",
        "# Train and evaluate the SOM\n",
        "som, labels, metrics, fig = train_and_evaluate_som(pref_clean_array, best_params)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Display the visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sHRzUiXz4ZhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, because of the lesser optimized nature of my SOMs, and due to time constraints and computational limitations of our machinery hardware, and the simplicity and effectiveness of the k-means++, and being lucky to have three of both, the k-means++ will serve as the main clustering and analysis and segmentation tool for further analysis, and the SOMs will be the comparison and the quote-unquote peer-review tool, and potentially an actual visualization tool, to confirm that the silhouettes and other scores such as the Davinsky, Kalinsky, and R2 are a sufficient explanation of our clustering made, and can potentially aid in this too. The unoptimized nature of this is acceptable because the primary clustering has already been verified through the scoring of silhouette and explained variance, it's just that the justification of this on the report will have to frame this correctly, and acknowledge the limitations of grid search and k-means, specifically its simplicity versus a grid search and a SOM fairly, and to talk about this and find supporting evidence of this thesis appropriately when addressing this in the reportation."
      ],
      "metadata": {
        "id": "3t7MDgjO6VXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The next step is to discuss the best clustering model, clustering parameters (numbers of clusters etc) and then continue with the merge based on centroids and the other statistics"
      ],
      "metadata": {
        "id": "M-N5Acmo3OLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze and decide best cluster amount and cluster model, add labels, merge.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XFTUU5hyAb2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the first segment: (preferences)\n",
        "\n",
        "\"\"\"k   Silhouette(S)    RÂ²      |S-0.5|    |RÂ²-0.5|    Combined Distance\n",
        "    3   0.549           0.211   0.049     0.289      0.293\n",
        "    4   0.479           0.277   0.021     0.223      0.224\n",
        "    5   0.426           0.325   0.074     0.175      0.190\n",
        "    6   0.467           0.396   0.033     0.104      0.109\n",
        "    7   0.472           0.460   0.028     0.040      0.049 *Optimal balance between R2 and Silhouette*\n",
        "    8   0.336           0.448   0.164     0.052      0.172\n",
        "    9   0.357           0.503   0.143     0.003      0.143\n",
        "    10  0.345           0.534   0.155     0.034      0.159\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "-vc8oMXkD8QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pref_clean"
      ],
      "metadata": {
        "id": "wrLZB7_6RTMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUANTUM VALIDATION OF DataFrame EXISTENCE\n",
        "assert isinstance(pref_clean, pd.DataFrame), \"CRITICAL ERROR: Input must maintain DataFrame quantum state\"\n",
        "\n",
        "# VALIDATE CLUSTER COLUMN PRESENCE WITH SCHRÃ–DINGER-LEVEL PRECISION\n",
        "assert 'cluster' in pref_clean.columns, \"CRITICAL ERROR: Cluster column not detected in quantum space\""
      ],
      "metadata": {
        "id": "v6ZOb3NRX3VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pref_clean"
      ],
      "metadata": {
        "id": "MdE6CTyQZUv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PHASE 1: SUPERMASSIVE VALIDATION OF INPUT DATA\n",
        "assert isinstance(pref_clean, pd.DataFrame), \"EINSTEIN-GRADE ERROR: DataFrame status compromised!\"\n",
        "\n",
        "# PHASE 2: QUANTUM CENTROID CALCULATION FROM EXISTING CLUSTER COLUMN\n",
        "pref_centroids = pref_clean.groupby('cluster')[['Other_Asian', 'General_Asian', 'Western',\n",
        "                                         'Beverages_Cafe', 'Desserts_Snacks', 'Main_Dishes']].mean()\n",
        "\n",
        "# PHASE 3: ADD CLUSTER IDENTIFICATION FOR MERGER WITH RELATIVISTIC PRECISION\n",
        "pref_centroids['cluster_number'] = pref_centroids.index\n",
        "\n",
        "print(\"ðŸŒŒ HAWKING-GRADE CENTROID MATRIX:\")\n",
        "print(pref_centroids)"
      ],
      "metadata": {
        "id": "chTUixiQX4G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pref_centroids"
      ],
      "metadata": {
        "id": "2xYn_aEtaNGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the second segment: (value)\n",
        "'''\n",
        "k    Silhouette(S)   RÂ²      |S-0.5|    |RÂ²-0.5|    Combined_Score\n",
        "3    0.416          0.569    0.084     0.069      0.109\n",
        "4    0.460*         0.686*   0.040     0.186      0.190 * Highest silhouette and high R2\n",
        "5    0.451          0.739    0.049     0.239      0.244\n",
        "6    0.451          0.782    0.049     0.282      0.286\n",
        "7    0.437          0.807    0.063     0.307      0.313\n",
        "8    0.438          0.822    0.062     0.322      0.328\n",
        "9    0.452          0.834    0.048     0.334      0.337\n",
        "10   0.458          0.855    0.042     0.355      0.357'''"
      ],
      "metadata": {
        "id": "8aL2XetOD8BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shop_clean"
      ],
      "metadata": {
        "id": "re3eCZX7RkEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PHASE 1: SUPERMASSIVE VALIDATION OF INPUT DATA\n",
        "assert isinstance(shop_clean, pd.DataFrame), \"EINSTEIN-GRADE ERROR: DataFrame status compromised!\"\n",
        "\n",
        "# PHASE 2: QUANTUM CENTROID CALCULATION FROM EXISTING CLUSTER COLUMN\n",
        "shop_centroids = shop_clean.groupby('cluster')[['is_chain', 'product_score', 'vendor_score', 'daytime_orders',\n",
        "       'evening_orders', 'chain_vendor_interaction']].mean()\n",
        "\n",
        "# PHASE 3: ADD CLUSTER IDENTIFICATION FOR MERGER WITH RELATIVISTIC PRECISION\n",
        "shop_centroids['cluster_number'] = shop_centroids.index\n",
        "\n",
        "print(\"ðŸŒŒ HAWKING-GRADE CENTROID MATRIX:\")\n",
        "print(shop_centroids)"
      ],
      "metadata": {
        "id": "ExKJHL9TalZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shop_centroids"
      ],
      "metadata": {
        "id": "6CL6OYulbDo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the third segment: (value)\n",
        "'''\n",
        "k    Silhouette(S)   RÂ²      |S-0.5|    |RÂ²-0.5|    Combined_Score\n",
        "3    0.531*         0.589*   0.031     0.089      0.094  *OPTIMAL*\n",
        "4    0.519          0.621    0.019     0.121      0.122\n",
        "5    0.398          0.688    0.102     0.188      0.214\n",
        "6    0.351          0.703    0.149     0.203      0.252\n",
        "7    0.360          0.729    0.140     0.229      0.268\n",
        "8    0.350          0.741    0.150     0.241      0.284\n",
        "9    0.321          0.756    0.179     0.256      0.312\n",
        "10   0.317          0.767    0.183     0.267      0.323'''"
      ],
      "metadata": {
        "id": "ugGFdgxHD772"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_clean.columns"
      ],
      "metadata": {
        "id": "zVQPmO--RVy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PHASE 1: SUPERMASSIVE VALIDATION OF INPUT DATA\n",
        "assert isinstance(val_clean, pd.DataFrame), \"EINSTEIN-GRADE ERROR: DataFrame status compromised!\"\n",
        "\n",
        "# PHASE 2: QUANTUM CENTROID CALCULATION FROM EXISTING CLUSTER COLUMN\n",
        "val_centroids = val_clean.groupby('cluster')[['CLV_Score', 'value_retention', 'value_growth', 'value_growth_rate',\n",
        "       'growth_momentum', 'spend_consistency', 'avg_order_value',\n",
        "       'active_spend_rate']].mean()\n",
        "\n",
        "# PHASE 3: ADD CLUSTER IDENTIFICATION FOR MERGER WITH RELATIVISTIC PRECISION\n",
        "val_centroids['cluster_number'] = val_centroids.index\n",
        "\n",
        "print(\"ðŸŒŒ HAWKING-GRADE CENTROID MATRIX:\")\n",
        "print(val_centroids)"
      ],
      "metadata": {
        "id": "pqm_YxKVbJiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_centroids"
      ],
      "metadata": {
        "id": "lleX-kMDe5ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "import numpy as np\n",
        "\n",
        "# PHASE 1: MERGE THE EXACT CENTROID DATAFRAMES WITH QUANTUM PRECISION\n",
        "merged_centroids = pd.merge(\n",
        "    shop_centroids.assign(key=1),\n",
        "    val_centroids.assign(key=1),\n",
        "    on='key'\n",
        ").merge(\n",
        "    pref_centroids.assign(key=1),\n",
        "    on='key'\n",
        ").drop('key', axis=1)\n",
        "\n",
        "# PHASE 2: REMOVE CLUSTER COLUMNS WITH ABSOLUTE PRECISION\n",
        "cluster_cols = [col for col in merged_centroids.columns if 'cluster' in col.lower()]\n",
        "feature_cols = [col for col in merged_centroids.columns if col not in cluster_cols]\n",
        "\n",
        "# PHASE 3: COMPUTE LINKAGE MATRIX WITH HEISENBERG-GRADE PRECISION\n",
        "X = merged_centroids[feature_cols]\n",
        "Z = linkage(X, method='ward', metric='euclidean')\n",
        "\n",
        "# PHASE 4: QUANTUM-PRECISE DENDROGRAM VISUALIZATION\n",
        "plt.figure(figsize=(15, 10))\n",
        "dendrogram(Z, leaf_rotation=90)\n",
        "plt.title('Multi-Dimensional Hierarchical Clustering of Shop-Val-Pref Centroids')\n",
        "plt.xlabel('Centroid Combinations')\n",
        "plt.ylabel('Euclidean Distance')\n",
        "plt.axhline(y=5, color='r', linestyle='--')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# PHASE 5: ULTRA-PRECISE ELBOW ANALYSIS\n",
        "last_merge = Z[:, 2]\n",
        "acceleration = np.diff(last_merge, 2)\n",
        "elbow_idx = np.argmax(acceleration) + 2\n",
        "suggested_clusters = len(merged_centroids) - elbow_idx\n",
        "\n",
        "print(f\"ðŸ§¬ QUANTUM ANALYSIS SUGGESTS {suggested_clusters} OPTIMAL CLUSTERS\")\n",
        "print(\"\\nðŸŒ‹ CRITICAL VALIDATION METRICS:\")\n",
        "print(f\"Total centroid combinations: {len(merged_centroids)}\")\n",
        "print(f\"Features used in clustering: {len(feature_cols)}\")"
      ],
      "metadata": {
        "id": "eBu0AHA5PdJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_centroids"
      ],
      "metadata": {
        "id": "tZnDV2VugIRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PHASE 1: MERGE ORIGINAL DFs - QUANTUM INTEGRITY MAINTAINED\n",
        "original_merged = pd.merge(\n",
        "    shop_clean,\n",
        "    val_clean,\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        "    suffixes=('_shop', '_val')\n",
        ").merge(\n",
        "    pref_clean,\n",
        "    left_index=True,\n",
        "    right_index=True\n",
        ")\n",
        "\n",
        "# PHASE 2: CALCULATE CENTROIDS WITH HEISENBERG-GRADE PRECISION\n",
        "merged_centroids = original_merged.groupby(['cluster_shop', 'cluster_val', 'cluster']).mean()\n",
        "\n",
        "# PHASE 3: FEATURE SELECTION WITH QUANTUM VALIDATION\n",
        "feature_cols = [col for col in merged_centroids.columns\n",
        "               if 'cluster' not in col.lower()]\n",
        "X = merged_centroids[feature_cols]\n",
        "\n",
        "# PHASE 4: HIERARCHICAL CLUSTERING WITH PLANCK-LENGTH PRECISION\n",
        "Z = linkage(X, method='ward', metric='euclidean')\n",
        "\n",
        "# ðŸš¨ CRITICAL SCIENTIFIC CORRECTION HERE ðŸš¨\n",
        "final_clusters = fcluster(Z, t=3, criterion='maxclust')  # Changed from 'distance' to 'maxclust' and t=4 to t=5\n",
        "\n",
        "# PHASE 5: MAPPING CREATION WITH QUANTUM INTEGRITY\n",
        "cluster_mapping = dict(zip(merged_centroids.index, final_clusters))\n",
        "\n",
        "# PHASE 6: CLUSTER ASSIGNMENT WITH RELATIVISTIC PRECISION\n",
        "original_merged['final_cluster'] = original_merged.apply(\n",
        "    lambda row: cluster_mapping.get(\n",
        "        (row['cluster_shop'], row['cluster_val'], row['cluster']),\n",
        "        -1  # Quantum error detection maintained\n",
        "    ),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# ðŸ§¬ CRITICAL SCIENTIFIC VALIDATION\n",
        "assert original_merged['final_cluster'].nunique() <= 5, \"QUANTUM ERROR: Too many clusters detected!\"\n",
        "assert -1 not in original_merged['final_cluster'].unique(), \"QUANTUM ERROR: Unmapped clusters detected!\""
      ],
      "metadata": {
        "id": "U6YeVBXCgjTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_merged"
      ],
      "metadata": {
        "id": "DlbE2voGh2P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profiling with unused / categorical features"
      ],
      "metadata": {
        "id": "CrJwDpsNFi1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PHASE 1: QUANTUM VALIDATION OF CATEGORICAL COLUMNS\n",
        "assert all(col in df.columns for col in categorical_cols), \"QUANTUM ERROR: Missing categorical columns!\"\n",
        "\n",
        "# PHASE 1: LOCATE CATEGORICAL COLUMNS IN ORIGINAL DATA\n",
        "categorical_data = df[['last_promo', 'payment_method',\n",
        "                      'customer_region_0', 'customer_region_1',\n",
        "                      'customer_region_2', 'customer_region_3']]\n",
        "\n",
        "# PHASE 2: QUANTUM-PRECISE MERGE WITH ORIGINAL_MERGED\n",
        "enhanced_merged = pd.merge(\n",
        "    original_merged,\n",
        "    categorical_data,\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        "    validate='1:1'  # CRITICAL: Ensures perfect 1-to-1 mapping\n",
        ")\n",
        "\n",
        "# PHASE 3: HEISENBERG-GRADE VALIDATION\n",
        "assert len(enhanced_merged) == len(original_merged), \"CRITICAL ERROR: Row count mismatch!\"\n",
        "assert all(col in enhanced_merged.columns for col in categorical_cols), \"CRITICAL ERROR: Missing columns!\"\n",
        "\n",
        "# PHASE 4: DISPLAY QUANTUM-VERIFIED RESULTS\n",
        "print(\"ðŸ§¬ QUANTUM-PRECISE VALIDATION METRICS:\")\n",
        "print(f\"Original rows: {len(original_merged)}\")\n",
        "print(f\"Enhanced rows: {len(enhanced_merged)}\")\n",
        "print(\"\\nCategorical Column Statistics:\")\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n{col} unique values: {enhanced_merged[col].nunique()}\")\n",
        "    print(enhanced_merged[col].value_counts().head())"
      ],
      "metadata": {
        "id": "88giH4zAlnx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enhanced_merged"
      ],
      "metadata": {
        "id": "TjCBr6OxmdcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cluster Analysis"
      ],
      "metadata": {
        "id": "sRGdR9YoFgMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PHASE 1: QUANTUM-PRECISE FUNCTION DEFINITION\n",
        "def cluster_profiles(df, label_columns, figsize, compar_titles=None):\n",
        "    \"\"\"\n",
        "    Multi-dimensional cluster profiling with quantum-grade precision.\n",
        "    \"\"\"\n",
        "    if compar_titles == None:\n",
        "        compar_titles = [\"\"]*len(label_columns)\n",
        "\n",
        "    sns.set()\n",
        "    fig, axes = plt.subplots(nrows=len(label_columns), ncols=2, figsize=figsize, squeeze=False)\n",
        "\n",
        "    for ax, label, titl in zip(axes, label_columns, compar_titles):\n",
        "        # Quantum filtering\n",
        "        drop_cols = [i for i in label_columns if i!=label]\n",
        "        dfax = df.drop(drop_cols, axis=1)\n",
        "\n",
        "        # Heisenberg-precise centroid calculation\n",
        "        centroids = dfax.groupby(by=label, as_index=False).mean()\n",
        "        counts = dfax.groupby(by=label, as_index=False).count().iloc[:,[0,1]]\n",
        "        counts.columns = [label, \"counts\"]\n",
        "\n",
        "        # Relativistic visualization\n",
        "        pd.plotting.parallel_coordinates(centroids, label, color=sns.color_palette(), ax=ax[0])\n",
        "        sns.barplot(x=label, y=\"counts\", data=counts, ax=ax[1])\n",
        "\n",
        "        # Quantum layout optimization\n",
        "        handles, _ = ax[0].get_legend_handles_labels()\n",
        "        cluster_labels = [f\"Cluster {i}\" for i in range(len(handles))]\n",
        "        ax[0].annotate(text=titl, xy=(0.95,1.1), xycoords='axes fraction', fontsize=13, fontweight='heavy')\n",
        "        ax[0].legend(handles, cluster_labels)\n",
        "        ax[0].axhline(color=\"black\", linestyle=\"--\")\n",
        "        ax[0].set_title(f\"Cluster Means - {len(handles)} Clusters\", fontsize=13)\n",
        "        ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=-20)\n",
        "        ax[1].set_xticklabels(cluster_labels)\n",
        "        ax[1].set_xlabel(\"\")\n",
        "        ax[1].set_ylabel(\"Absolute Frequency\")\n",
        "        ax[1].set_title(f\"Cluster Sizes - {len(handles)} Clusters\", fontsize=13)\n",
        "\n",
        "    plt.subplots_adjust(hspace=0.4, top=0.90)\n",
        "    plt.suptitle(\"Cluster Simple Profiling\", fontsize=23)\n",
        "    plt.show()\n",
        "\n",
        "# PHASE 2: PREPARE DATA WITH QUANTUM INTEGRITY\n",
        "metric_features = [col for col in enhanced_merged.columns\n",
        "                  if 'cluster' not in col.lower()]\n",
        "\n",
        "# PHASE 3: EXECUTE VISUALIZATION WITH HEISENBERG-GRADE PRECISION\n",
        "cluster_profiles(\n",
        "    df=enhanced_merged,\n",
        "    label_columns=['cluster_shop', 'cluster_val', 'cluster', 'final_cluster'],\n",
        "    figsize=(40, 32),\n",
        "    compar_titles=[\"Shopping Clusters\", \"Value Clusters\",\n",
        "                  \"Preference Clusters\", \"Final Hierarchical Clusters\"]\n",
        ")"
      ],
      "metadata": {
        "id": "hpb-0GfliEUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    calinski_harabasz_score,\n",
        "    davies_bouldin_score,\n",
        "    r2_score\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def quantum_cluster_validation(shop_clean, val_clean, pref_clean, enhanced_merged, figsize=(20, 24)):\n",
        "    \"\"\"QUANTUM-PRECISE VALIDATION\"\"\"\n",
        "\n",
        "    def calculate_metrics(X, labels):\n",
        "        silhouette = silhouette_score(X, labels)\n",
        "        calinski = calinski_harabasz_score(X, labels)\n",
        "        davies = davies_bouldin_score(X, labels)\n",
        "\n",
        "        # Calculate SSE and RÂ² without dimensional mixing\n",
        "        sse = 0\n",
        "        cluster_centers = {}\n",
        "        cluster_sizes = {}\n",
        "\n",
        "        for cluster in np.unique(labels):\n",
        "            mask = labels == cluster\n",
        "            cluster_points = X[mask]\n",
        "            cluster_sizes[cluster] = len(cluster_points)\n",
        "            center = cluster_points.mean(axis=0)\n",
        "            cluster_centers[cluster] = center\n",
        "            sse += np.sum((cluster_points - center) ** 2)\n",
        "\n",
        "        total_center = X.mean(axis=0)\n",
        "        total_ss = np.sum((X - total_center) ** 2)\n",
        "        r2 = 1 - (sse / total_ss)\n",
        "\n",
        "        return {\n",
        "            'silhouette': silhouette,\n",
        "            'calinski': calinski,\n",
        "            'davies': davies,\n",
        "            'sse': sse,\n",
        "            'r2': r2,\n",
        "            'sizes': cluster_sizes\n",
        "        }\n",
        "\n",
        "    # Calculate metrics for each space SEPARATELY\n",
        "    results = {}\n",
        "\n",
        "    # Shop metrics\n",
        "    X_shop = shop_clean.drop('cluster', axis=1).values\n",
        "    results['shop'] = calculate_metrics(X_shop, shop_clean['cluster'])\n",
        "\n",
        "    # Value metrics\n",
        "    X_val = val_clean.drop('cluster', axis=1).values\n",
        "    results['value'] = calculate_metrics(X_val, val_clean['cluster'])\n",
        "\n",
        "    # Preference metrics\n",
        "    X_pref = pref_clean.drop('cluster', axis=1).values\n",
        "    results['preference'] = calculate_metrics(X_pref, pref_clean['cluster'])\n",
        "\n",
        "    # Final merged metrics\n",
        "    X_merged = enhanced_merged[[col for col in enhanced_merged if 'cluster' not in col]].values\n",
        "    results['final'] = calculate_metrics(X_merged, enhanced_merged['final_cluster'])\n",
        "\n",
        "    # Separate visualization function for safety\n",
        "    plot_validation_results(results, figsize)\n",
        "\n",
        "    return results\n",
        "\n",
        "def plot_validation_results(results, figsize):\n",
        "    \"\"\"QUANTUM-SAFE VISUALIZATION\"\"\"\n",
        "    fig, axes = plt.subplots(len(results), 2, figsize=figsize)\n",
        "    fig.suptitle(\"QUANTUM-GRADE CLUSTER VALIDATION METRICS\", y=0.95)\n",
        "\n",
        "    for idx, (name, metrics) in enumerate(results.items()):\n",
        "        # LEFT: Bar plot of metrics\n",
        "        ax1 = axes[idx, 0]\n",
        "        metric_values = [metrics['silhouette'],\n",
        "                        metrics['calinski']/max(1, metrics['calinski']),\n",
        "                        1/(1 + metrics['davies']),\n",
        "                        metrics['r2']]\n",
        "        metric_names = ['Silhouette', 'Calinski (norm)', 'Davies (inv)', 'RÂ²']\n",
        "\n",
        "        sns.barplot(x=metric_names, y=metric_values, ax=ax1)\n",
        "        ax1.set_title(f\"{name.title()} Metrics\")\n",
        "        ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # RIGHT: Cluster size distribution\n",
        "        ax2 = axes[idx, 1]\n",
        "        sizes = pd.Series(metrics['sizes'])\n",
        "        sns.barplot(x=sizes.index, y=sizes.values, ax=ax2)\n",
        "        ax2.set_title(f\"{name.title()} Cluster Sizes\")\n",
        "\n",
        "        # Add metrics text\n",
        "        text = (\n",
        "            f\"Silhouette: {metrics['silhouette']:.3f}\\n\"\n",
        "            f\"Calinski: {metrics['calinski']:.0f}\\n\"\n",
        "            f\"Davies: {metrics['davies']:.3f}\\n\"\n",
        "            f\"RÂ²: {metrics['r2']:.3f}\"\n",
        "        )\n",
        "        ax2.text(1.05, 0.5, text, transform=ax2.transAxes,\n",
        "                bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return metrics\n",
        "\n",
        "# PHASE 1: EXECUTE QUANTUM VALIDATION\n",
        "validation_metrics = quantum_cluster_validation(\n",
        "    shop_clean=shop_clean,\n",
        "    val_clean=val_clean,\n",
        "    pref_clean=pref_clean,\n",
        "    enhanced_merged=enhanced_merged,\n",
        "    figsize=(20, 24)\n",
        ")"
      ],
      "metadata": {
        "id": "bJ7E6qFDlTWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "o34fPo1YjtFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def quantum_clean_manifold_analysis(enhanced_merged, random_state=42):\n",
        "    \"\"\"\n",
        "    QUANTUM-PRECISE MANIFOLD ANALYSIS FOR PRE-CLEANED DATA\n",
        "    No outliers = Pure dimensional analysis with absolute precision\n",
        "    \"\"\"\n",
        "\n",
        "    # PHASE 1: PURE FEATURE EXTRACTION\n",
        "    feature_cols = [col for col in enhanced_merged.columns if 'cluster' not in col]\n",
        "    X = enhanced_merged[feature_cols].values\n",
        "    labels = enhanced_merged['final_cluster'].values\n",
        "\n",
        "    # PHASE 2: MANIFOLD LEARNING WITH THEORETICAL PHYSICS PRECISION\n",
        "    # PCA in clean space\n",
        "    pca = PCA(n_components=2, random_state=random_state)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    var_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "    # Enhanced UMAP for clean data\n",
        "    umap_optimal = umap.UMAP(\n",
        "        n_components=2,\n",
        "        n_neighbors=30,     # Optimal for clean data\n",
        "        min_dist=0.3,       # Better separation for clean clusters\n",
        "        metric='euclidean', # Pure distance in clean space\n",
        "        random_state=random_state\n",
        "    )\n",
        "    X_umap = umap_optimal.fit_transform(X)\n",
        "\n",
        "    # PHASE 3: QUANTUM-PRECISE VISUALIZATION\n",
        "    # plt.style.use('seaborn')  # Enhanced aesthetics\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "    # PCA with enhanced visualization\n",
        "    scatter1 = ax1.scatter(\n",
        "        X_pca[:, 0], X_pca[:, 1],\n",
        "        c=labels, cmap='viridis',\n",
        "        alpha=0.7, s=70,    # Increased visibility\n",
        "        edgecolor='white',  # Enhanced point definition\n",
        "        linewidth=0.5\n",
        "    )\n",
        "    ax1.set_title(f'PCA Projection (Variance Explained: {var_ratio[0]:.2f}, {var_ratio[1]:.2f})',\n",
        "                  fontsize=12, pad=20)\n",
        "    ax1.set_xlabel('Principal Component 1', fontsize=10)\n",
        "    ax1.set_ylabel('Principal Component 2', fontsize=10)\n",
        "    ax1.grid(True, alpha=0.2)\n",
        "\n",
        "    # UMAP with enhanced visualization\n",
        "    scatter2 = ax2.scatter(\n",
        "        X_umap[:, 0], X_umap[:, 1],\n",
        "        c=labels, cmap='viridis',\n",
        "        alpha=0.7, s=70,\n",
        "        edgecolor='white',\n",
        "        linewidth=0.5\n",
        "    )\n",
        "    ax2.set_title('UMAP Projection', fontsize=12, pad=20)\n",
        "    ax2.set_xlabel('UMAP Component 1', fontsize=10)\n",
        "    ax2.set_ylabel('UMAP Component 2', fontsize=10)\n",
        "    ax2.grid(True, alpha=0.2)\n",
        "\n",
        "    # Enhanced legends\n",
        "    for ax, scatter in [(ax1, scatter1), (ax2, scatter2)]:\n",
        "        legend = ax.legend(\n",
        "            *scatter.legend_elements(),\n",
        "            title=\"Clusters\",\n",
        "            title_fontsize=10,\n",
        "            bbox_to_anchor=(1.05, 1),\n",
        "            loc='upper left'\n",
        "        )\n",
        "        ax.add_artist(legend)\n",
        "\n",
        "    plt.tight_layout(w_pad=4)\n",
        "    plt.show()\n",
        "\n",
        "    # PHASE 4: QUANTUM-PRECISE ANALYSIS\n",
        "    print(\"\\nQUANTUM-GRADE MANIFOLD ANALYSIS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Feature contribution analysis\n",
        "    feature_importance = np.abs(pca.components_)\n",
        "    top_features_pc1 = np.argsort(feature_importance[0])[-5:]\n",
        "    top_features_pc2 = np.argsort(feature_importance[1])[-5:]\n",
        "\n",
        "    print(\"PCA VARIANCE EXPLANATION:\")\n",
        "    print(f\"PC1: {var_ratio[0]:.3f} ({var_ratio[0]*100:.1f}%)\")\n",
        "    print(f\"PC2: {var_ratio[1]:.3f} ({var_ratio[1]*100:.1f}%)\")\n",
        "    print(f\"Total: {sum(var_ratio):.3f} ({sum(var_ratio)*100:.1f}%)\")\n",
        "\n",
        "    print(\"\\nTOP CONTRIBUTING FEATURES:\")\n",
        "    print(\"PC1:\", [feature_cols[i] for i in top_features_pc1[::-1]])\n",
        "    print(\"PC2:\", [feature_cols[i] for i in top_features_pc2[::-1]])\n",
        "\n",
        "    return {\n",
        "        'pca_embedding': X_pca,\n",
        "        'umap_embedding': X_umap,\n",
        "        'pca_variance': var_ratio,\n",
        "        'feature_importance': {\n",
        "            'pc1': dict(zip(feature_cols, feature_importance[0])),\n",
        "            'pc2': dict(zip(feature_cols, feature_importance[1]))\n",
        "        }\n",
        "    }\n",
        "\n",
        "# EXECUTE QUANTUM-GRADE ANALYSIS\n",
        "manifold_results = quantum_clean_manifold_analysis(enhanced_merged)"
      ],
      "metadata": {
        "id": "CmIOKAKIjrGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_clean\n",
        "pref_clean\n",
        "shop_clean"
      ],
      "metadata": {
        "id": "GW9Ry8V5DmRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qYn_DtdplQqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/fpontejos/Data-Mining-23-24/blob/main/notebooks_solutions/lab14_cluster_analysis.ipynb"
      ],
      "metadata": {
        "id": "U5eG8AfpFJE2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7avKfSYFewV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assess feature importance and reclassify outliers"
      ],
      "metadata": {
        "id": "nNbZBCPGF3Kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a Decision Tree we get the normalized total reduction of the criterion (gini or entropy) brought by that feature (also known as Gini importance)."
      ],
      "metadata": {
        "id": "T9h5p-6vF4u2"
      }
    }
  ]
}